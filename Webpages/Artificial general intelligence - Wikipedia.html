<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Artificial general intelligence - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRequestId":"Xk8fdgpAAEQAAGaTKsIAAAEW","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Artificial_general_intelligence","wgTitle":"Artificial general intelligence","wgCurRevisionId":941648935,"wgRevisionId":941648935,"wgArticleId":586357,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Webarchive template wayback links","All articles with dead external links","Articles with dead external links from October 2019","CS1 errors: missing periodical",
"CS1 maint: archived copy as title","Articles with short description","Use British English from March 2019","Use dmy dates from December 2019","All articles with unsourced statements","Articles with unsourced statements from June 2011","Articles with unsourced statements from January 2017","Articles with unsourced statements from December 2017","Articles with unsourced statements from April 2011","All articles needing examples","Articles needing examples from September 2017","Articles to be expanded from February 2016","All articles to be expanded","Articles using small message boxes","Hypothetical technology","Artificial intelligence","Computational neuroscience"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Artificial_general_intelligence","wgRelevantArticleId":586357,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"Artificial_being","wgMediaViewerOnClick":!0,
"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgInternalRedirectTargetUrl":"/wiki/Artificial_general_intelligence","wgWikibaseItemId":"Q2264109","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","jquery.makeCollapsible.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles":"ready",
"wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["mediawiki.action.view.redirect","ext.cite.ux-enhancements","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.20"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Artificial_general_intelligence"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Artificial_general_intelligence rootpage-Artificial_general_intelligence skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Artificial general intelligence</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"><span class="mw-redirectedfrom">&#160;&#160;(Redirected from <a href="/w/index.php?title=Artificial_being&amp;redirect=no" class="mw-redirect" title="Artificial being">Artificial being</a>)</span></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Hypothetical human-level or stronger AI</div>
<p class="mw-empty-elt">

</p>
<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%;width: 16em;"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Outline_of_artificial_intelligence" title="Outline of artificial intelligence">Artificial intelligence</a></th></tr><tr><th style="padding:0.1em">
<a href="/wiki/Artificial_intelligence#Goals" title="Artificial intelligence">Major goals</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Knowledge_representation_and_reasoning" title="Knowledge representation and reasoning">Knowledge reasoning</a></li>
<li><a href="/wiki/Automated_planning_and_scheduling" title="Automated planning and scheduling">Planning</a></li>
<li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li>
<li><a href="/wiki/Natural_language_processing" title="Natural language processing">Natural language processing</a></li>
<li><a href="/wiki/Computer_vision" title="Computer vision">Computer vision</a></li>
<li><a href="/wiki/Robotics" title="Robotics">Robotics</a></li>
<li><a class="mw-selflink selflink">Artificial general intelligence</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Approaches</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Symbolic_artificial_intelligence" title="Symbolic artificial intelligence">Symbolic</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayesian networks</a></li>
<li><a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">Evolutionary algorithms</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
<a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">Ethics</a></li>
<li><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk</a></li>
<li><a href="/wiki/Turing_test" title="Turing test">Turing test</a></li>
<li><a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a></li>
<li><a href="/wiki/AI_control_problem" title="AI control problem">Control problem</a></li>
<li><a href="/wiki/Friendly_artificial_intelligence" title="Friendly artificial intelligence">Friendly AI</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
<a href="/wiki/History_of_artificial_intelligence" title="History of artificial intelligence">History</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Timeline_of_artificial_intelligence" title="Timeline of artificial intelligence">Timeline</a></li>
<li><a href="/wiki/Progress_in_artificial_intelligence" title="Progress in artificial intelligence">Progress</a></li>
<li><a href="/wiki/AI_winter" title="AI winter">AI winter</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Technology</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Applications_of_artificial_intelligence" title="Applications of artificial intelligence">Applications</a></li>
<li><a href="/wiki/List_of_artificial_intelligence_projects" title="List of artificial intelligence projects">Projects</a></li>
<li><a href="/wiki/List_of_programming_languages_for_artificial_intelligence" title="List of programming languages for artificial intelligence">Programming languages</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Glossary</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary</a></li></ul></td>
</tr><tr><td style="text-align:right;font-size:115%"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Artificial_intelligence" title="Template:Artificial intelligence"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Artificial_intelligence" title="Template talk:Artificial intelligence"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Artificial_intelligence&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p><b>Artificial general intelligence</b> (<b>AGI</b>) is the intelligence of a machine that has the capacity to understand or learn any intellectual task that a <a href="/wiki/Human_being" class="mw-redirect" title="Human being">human being</a> can. It is a primary goal of some <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> research and a common topic in <a href="/wiki/Science_fiction" title="Science fiction">science fiction</a> and <a href="/wiki/Futures_studies" title="Futures studies">futures studies</a>. AGI can also be referred to as <b>strong AI</b>,<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup><sup id="cite_ref-Kurzweil_2005-08-05_2-0" class="reference"><a href="#cite_note-Kurzweil_2005-08-05-2">&#91;2&#93;</a></sup><sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> <b>full AI</b>,<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup> or <b>general intelligent action</b>.<sup id="cite_ref-FOOTNOTENewellSimon1976_5-0" class="reference"><a href="#cite_note-FOOTNOTENewellSimon1976-5">&#91;5&#93;</a></sup> (Some academic sources reserve the term "strong AI" for machines that can experience <a href="/wiki/Chinese_room#Strong_AI" title="Chinese room">consciousness</a>.<sup id="cite_ref-FOOTNOTESearle1980_6-0" class="reference"><a href="#cite_note-FOOTNOTESearle1980-6">&#91;6&#93;</a></sup>)
</p><p>Some authorities emphasize a distinction between strong AI and applied AI<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup> (also called <i>narrow AI</i><sup id="cite_ref-Kurzweil_2005-08-05_2-1" class="reference"><a href="#cite_note-Kurzweil_2005-08-05-2">&#91;2&#93;</a></sup> or <i><a href="/wiki/Weak_AI" title="Weak AI">weak AI</a></i><sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup>): the use of software to study or accomplish specific <a href="/wiki/Problem_solving" title="Problem solving">problem solving</a> or <a href="/wiki/Reason" title="Reason">reasoning</a> tasks. Weak AI, in contrast to strong AI, does not attempt to perform the full range of human <a href="/wiki/Cognitive" class="mw-redirect" title="Cognitive">cognitive</a> abilities.
</p><p>As of 2017, over forty organizations were doing research on AGI.<sup id="cite_ref-baum_9-0" class="reference"><a href="#cite_note-baum-9">&#91;9&#93;</a></sup>
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Requirements"><span class="tocnumber">1</span> <span class="toctext">Requirements</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Tests_for_confirming_human-level_AGI"><span class="tocnumber">1.1</span> <span class="toctext">Tests for confirming human-level AGI</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#IQ-tests_AGI"><span class="tocnumber">1.2</span> <span class="toctext">IQ-tests AGI</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Problems_requiring_AGI_to_solve"><span class="tocnumber">1.3</span> <span class="toctext">Problems requiring AGI to solve</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-5"><a href="#AGI_research"><span class="tocnumber">2</span> <span class="toctext">AGI research</span></a>
<ul>
<li class="toclevel-2 tocsection-6"><a href="#Classical_AI"><span class="tocnumber">2.1</span> <span class="toctext">Classical AI</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Narrow_AI_research"><span class="tocnumber">2.2</span> <span class="toctext">Narrow AI research</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Modern_artificial_general_intelligence_research"><span class="tocnumber">2.3</span> <span class="toctext">Modern artificial general intelligence research</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="#Processing_power_needed_to_simulate_a_brain"><span class="tocnumber">3</span> <span class="toctext">Processing power needed to simulate a brain</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="#Whole_brain_emulation"><span class="tocnumber">3.1</span> <span class="toctext">Whole brain emulation</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Early_estimates"><span class="tocnumber">3.2</span> <span class="toctext">Early estimates</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Modelling_the_neurons_in_more_detail"><span class="tocnumber">3.3</span> <span class="toctext">Modelling the neurons in more detail</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Current_research"><span class="tocnumber">3.4</span> <span class="toctext">Current research</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Criticisms_of_simulation-based_approaches"><span class="tocnumber">3.5</span> <span class="toctext">Criticisms of simulation-based approaches</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-15"><a href="#Strong_AI_and_consciousness"><span class="tocnumber">4</span> <span class="toctext">Strong AI and consciousness</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Consciousness"><span class="tocnumber">4.1</span> <span class="toctext">Consciousness</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Artificial_consciousness_research"><span class="tocnumber">4.2</span> <span class="toctext">Artificial consciousness research</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-18"><a href="#Possible_explanations_for_the_slow_progress_of_AI_research"><span class="tocnumber">5</span> <span class="toctext">Possible explanations for the slow progress of AI research</span></a></li>
<li class="toclevel-1 tocsection-19"><a href="#Controversies_and_dangers"><span class="tocnumber">6</span> <span class="toctext">Controversies and dangers</span></a>
<ul>
<li class="toclevel-2 tocsection-20"><a href="#Feasibility"><span class="tocnumber">6.1</span> <span class="toctext">Feasibility</span></a></li>
<li class="toclevel-2 tocsection-21"><a href="#Potential_threat_to_human_existence"><span class="tocnumber">6.2</span> <span class="toctext">Potential threat to human existence</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-22"><a href="#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-23"><a href="#Notes"><span class="tocnumber">8</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-24"><a href="#References"><span class="tocnumber">9</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-25"><a href="#External_links"><span class="tocnumber">10</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Requirements">Requirements</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=1" title="Edit section: Requirements">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Cognitive_science" title="Cognitive science">Cognitive science</a></div>
<p>Various criteria for <a href="/wiki/Intelligence" title="Intelligence">intelligence</a> have been proposed (most famously the <a href="/wiki/Turing_test" title="Turing test">Turing test</a>) but to date, there is no definition that satisfies everyone.<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup> However, there <i>is</i> wide agreement among artificial intelligence researchers that intelligence is required to do the following:<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup>
</p>
<ul><li><a href="/wiki/Automated_reasoning" title="Automated reasoning">reason</a>, use strategy, solve puzzles, and make judgments under <a href="/wiki/Uncertainty" title="Uncertainty">uncertainty</a>;</li>
<li><a href="/wiki/Knowledge_representation" class="mw-redirect" title="Knowledge representation">represent knowledge</a>, including <a href="/wiki/Commonsense_knowledge_base" class="mw-redirect" title="Commonsense knowledge base">commonsense knowledge</a>;</li>
<li><a href="/wiki/Automated_planning_and_scheduling" title="Automated planning and scheduling">plan</a>;</li>
<li><a href="/wiki/Machine_learning" title="Machine learning">learn</a>;</li>
<li>communicate in <a href="/wiki/Natural_language_processing" title="Natural language processing">natural language</a>;</li>
<li>and <a href="/wiki/Artificial_intelligence_systems_integration" title="Artificial intelligence systems integration">integrate all these skills</a> towards common goals.</li></ul>
<p>Other important capabilities include the ability to <a href="/wiki/Machine_perception" title="Machine perception">sense</a> (e.g. <a href="/wiki/Computer_vision" title="Computer vision">see</a>) and the ability to act (e.g. <a href="/wiki/Robotics" title="Robotics">move and manipulate objects</a>) in the world where intelligent behaviour is to be observed.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup> This would include an ability to detect and respond to <a href="/wiki/Hazard" title="Hazard">hazard</a>.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup> Many interdisciplinary approaches to intelligence (e.g. <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive science</a>, <a href="/wiki/Computational_intelligence" title="Computational intelligence">computational intelligence</a> and <a href="/wiki/Decision_making" class="mw-redirect" title="Decision making">decision making</a>) tend to emphasise the need to consider additional traits such as <a href="/wiki/Imagination" title="Imagination">imagination</a> (taken as the ability to form mental images and concepts that were not programmed in)<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup> and <a href="/wiki/Self-determination_theory" title="Self-determination theory">autonomy</a>.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup>
Computer based systems that exhibit many of these capabilities do exist (e.g. see <a href="/wiki/Computational_creativity" title="Computational creativity">computational creativity</a>, <a href="/wiki/Automated_reasoning" title="Automated reasoning">automated reasoning</a>, <a href="/wiki/Decision_support_system" title="Decision support system">decision support system</a>, <a href="/wiki/Robot" title="Robot">robot</a>, <a href="/wiki/Evolutionary_computation" title="Evolutionary computation">evolutionary computation</a>, <a href="/wiki/Intelligent_agent" title="Intelligent agent">intelligent agent</a>), but not yet at human levels.
</p>
<h3><span class="mw-headline" id="Tests_for_confirming_human-level_AGI">Tests for confirming human-level AGI<span id="Tests_for_confirming_human-level_AGI"></span></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=2" title="Edit section: Tests for confirming human-level AGI">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The following tests to confirm human-level AGI have been considered:<sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup><sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup>
</p>
<dl><dt><a href="/wiki/Turing_test" title="Turing test">The Turing Test</a> (<a href="/wiki/Alan_Turing" title="Alan Turing"><i>Turing</i></a>)</dt>
<dd>A machine and a human both converse sight unseen with a second human, who must evaluate which of the two is the machine, which passes the test if it can fool the evaluator a significant fraction of the time. Note: Turing does not prescribe what should qualify as intelligence, only that knowing that it is a machine should disqualify it.</dd>
<dt>The Coffee Test (<a href="/wiki/Steve_Wozniak" title="Steve Wozniak"><i>Wozniak</i></a>)</dt>
<dd>A machine is required to enter an average American home and figure out how to make coffee: find the coffee machine, find the coffee, add water, find a mug, and brew the coffee by pushing the proper buttons.</dd>
<dt>The Robot College Student Test (<a href="/wiki/Ben_Goertzel" title="Ben Goertzel"><i>Goertzel</i></a>)</dt>
<dd>A machine enrolls in a university, taking and passing the same classes that humans would, and obtaining a degree.</dd>
<dt>The Employment Test (<a href="/wiki/Nils_John_Nilsson" title="Nils John Nilsson"><i>Nilsson</i></a>)</dt>
<dd>A machine works an economically important job, performing at least as well as humans in the same job.</dd></dl>
<h3><span class="mw-headline" id="IQ-tests_AGI">IQ-tests AGI<span id="IQ-Tests_AGI"></span></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=3" title="Edit section: IQ-tests AGI">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Chinese researchers Feng Liu, Yong Shi and Ying Liu conducted intelligence tests in the summer of 2017 with publicly available and freely accessible weak AI such as Google AI or Apple's Siri and others. At the maximum, these AI reached a value of about 47, which corresponds approximately to a six-year-old child in first grade. An adult comes to about 100 on average. In 2014, similar tests were carried out in which the AI reached a maximum value of 27.<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup><sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Problems_requiring_AGI_to_solve">Problems requiring AGI to solve</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=4" title="Edit section: Problems requiring AGI to solve">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/AI-complete" title="AI-complete">AI-complete</a></div>
<p>The most difficult problems for computers are informally known as "AI-complete" or "AI-hard", implying that solving them is equivalent to the general aptitude of human intelligence, or strong AI, beyond the capabilities of a purpose-specific algorithm.<sup id="cite_ref-Shapiro92_20-0" class="reference"><a href="#cite_note-Shapiro92-20">&#91;20&#93;</a></sup>
</p><p>AI-complete problems are hypothesised to include general <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a>, <a href="/wiki/Natural_language_understanding" class="mw-redirect" title="Natural language understanding">natural language understanding</a>, and dealing with unexpected circumstances while solving any real world problem.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup>
</p><p>AI-complete problems cannot be solved with current computer technology alone, and also require <a href="/wiki/Human_computation" class="mw-redirect" title="Human computation">human computation</a>.  This property could be useful, for example, to test for the presence of humans, as <a href="/wiki/CAPTCHA" title="CAPTCHA">CAPTCHAs</a> aim to do; and for <a href="/wiki/Computer_security" title="Computer security">computer security</a> to repel <a href="/wiki/Brute-force_attack" title="Brute-force attack">brute-force attacks</a>.<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;22&#93;</a></sup><sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="AGI_research">AGI research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=5" title="Edit section: AGI research">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Classical_AI">Classical AI</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=6" title="Edit section: Classical AI">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/History_of_artificial_intelligence" title="History of artificial intelligence">History of artificial intelligence</a></div>
<p>Modern AI research began in the mid 1950s.<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup> The first generation of AI researchers was convinced that artificial general intelligence was possible and that it would exist in just a few decades. As AI pioneer <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Herbert A. Simon</a> wrote in 1965: "machines will be capable, within twenty years, of doing any work a man can do."<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> Their predictions were the inspiration for <a href="/wiki/Stanley_Kubrick" title="Stanley Kubrick">Stanley Kubrick</a> and <a href="/wiki/Arthur_C._Clarke" title="Arthur C. Clarke">Arthur C. Clarke</a>'s character <a href="/wiki/HAL_9000" title="HAL 9000">HAL 9000</a>, who embodied what AI researchers believed they could create by the year 2001. AI pioneer <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a> was a consultant<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup> on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time; Crevier quotes him as having said on the subject in 1967, "Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved,"<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup> although Minsky states that he was misquoted.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (June 2011)">citation needed</span></a></i>&#93;</sup>
</p><p>However, in the early 1970s, it became obvious that researchers had grossly underestimated the difficulty of the project. Funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful "applied AI".<sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup> As the 1980s began, Japan's <a href="/wiki/Fifth_Generation_Computer" class="mw-redirect" title="Fifth Generation Computer">Fifth Generation Computer</a> Project revived interest in AGI, setting out a ten-year timeline that included AGI goals like "carry on a casual conversation".<sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup> In response to this and the success of <a href="/wiki/Expert_systems" class="mw-redirect" title="Expert systems">expert systems</a>, both industry and government pumped money back into the field.<sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup> However, confidence in AI spectacularly collapsed in the late 1980s, and the goals of the Fifth Generation Computer Project were never fulfilled.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup> For the second time in 20 years, AI researchers who had predicted the imminent achievement of AGI had been shown to be fundamentally mistaken. By the 1990s, AI researchers had gained a reputation for making vain promises. They became reluctant to make predictions at all<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup> and to avoid any mention of "human level" artificial intelligence for fear of being labeled "wild-eyed dreamer[s]."<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Narrow_AI_research">Narrow AI research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=7" title="Edit section: Narrow AI research">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">Artificial intelligence</a></div>
<p>In the 1990s and early 21st century, mainstream AI has achieved far greater commercial success and academic respectability by focusing on specific sub-problems where they can produce verifiable results and commercial applications, such as <a href="/wiki/Artificial_neural_networks" class="mw-redirect" title="Artificial neural networks">artificial neural networks</a>, <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a> or <a href="/wiki/Data_mining" title="Data mining">data mining</a>.<sup id="cite_ref-34" class="reference"><a href="#cite_note-34">&#91;34&#93;</a></sup> These "applied AI" systems are now used extensively throughout the technology industry, and research in this vein is very heavily funded in both academia and industry. Currently, the development on this field is considered an emerging trend, and a mature stage is expected to happen in more than 10 years.<sup id="cite_ref-35" class="reference"><a href="#cite_note-35">&#91;35&#93;</a></sup>
</p><p>
Most mainstream AI researchers hope that strong AI can be developed by combining the programs that solve various sub-problems using an integrated <a href="/wiki/Agent_architecture" title="Agent architecture">agent architecture</a>, <a href="/wiki/Cognitive_architecture" title="Cognitive architecture">cognitive architecture</a> or <a href="/wiki/Subsumption_architecture" title="Subsumption architecture">subsumption architecture</a>. <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> wrote in 1988: </p><blockquote><p>"I am confident that this bottom-up route to artificial intelligence will one day meet the traditional top-down route more than half way, ready to provide the real world competence and the <a href="/wiki/Commonsense_knowledge_base" class="mw-redirect" title="Commonsense knowledge base">commonsense knowledge</a> that has been so frustratingly elusive in reasoning programs. Fully intelligent machines will result when the metaphorical <a href="/wiki/Golden_spike" title="Golden spike">golden spike</a> is driven uniting the two efforts."<sup id="cite_ref-36" class="reference"><a href="#cite_note-36">&#91;36&#93;</a></sup></p></blockquote><p>
However, even this fundamental philosophy has been disputed; for example, Stevan Harnad of Princeton concluded his 1990 paper on the <a href="/wiki/Symbol_grounding_problem" title="Symbol grounding problem">Symbol Grounding Hypothesis</a> by stating: </p><blockquote><p>"The expectation has often been voiced that "top-down" (symbolic) approaches to modeling cognition will somehow meet "bottom-up" (sensory) approaches somewhere in between. If the grounding considerations in this paper are valid, then this expectation is hopelessly modular and there is really only one viable route from sense to symbols: from the ground up. A free-floating symbolic level like the software level of a computer will never be reached by this route (or vice versa) – nor is it clear why we should even try to reach such a level, since it looks as if getting there would just amount to uprooting our symbols from their intrinsic meanings (thereby merely reducing ourselves to the functional equivalent of a programmable computer)."<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">&#91;37&#93;</a></sup></p></blockquote>
<h3><span class="mw-headline" id="Modern_artificial_general_intelligence_research">Modern artificial general intelligence research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=8" title="Edit section: Modern artificial general intelligence research">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Artificial general intelligence<sup id="cite_ref-FOOTNOTEGoertzelPennachin2006_38-0" class="reference"><a href="#cite_note-FOOTNOTEGoertzelPennachin2006-38">&#91;38&#93;</a></sup> (AGI) describes research that aims to create machines capable of general intelligent action. The term was used as early as 1997, by Mark Gubrud<sup id="cite_ref-39" class="reference"><a href="#cite_note-39">&#91;39&#93;</a></sup> in a discussion of the implications of fully automated military production and operations. The term was re-introduced and popularized by <a href="/wiki/Shane_Legg" title="Shane Legg">Shane Legg</a> and <a href="/wiki/Ben_Goertzel" title="Ben Goertzel">Ben Goertzel</a> around 2002.<sup id="cite_ref-40" class="reference"><a href="#cite_note-40">&#91;40&#93;</a></sup> The research objective is much older, for example <a href="/wiki/Doug_Lenat" class="mw-redirect" title="Doug Lenat">Doug Lenat</a>'s <a href="/wiki/Cyc" title="Cyc">Cyc</a> project (that began in 1984), and <a href="/wiki/Allen_Newell" title="Allen Newell">Allen Newell</a>'s <a href="/wiki/Soar_(cognitive_architecture)" title="Soar (cognitive architecture)">Soar</a> project are regarded as within the scope of AGI. AGI research activity in 2006 was described by Pei Wang and Ben Goertzel<sup id="cite_ref-41" class="reference"><a href="#cite_note-41">&#91;41&#93;</a></sup> as "producing publications and preliminary results". The first summer school in AGI was organized in Xiamen, China in 2009 by the Xiamen university's Artificial Brain Laboratory and OpenCog. The first university course was given in 2010 and 2011 at Plovdiv University, Bulgaria by Todor Arnaudov. MIT presented a course in AGI in 2018, organized by Lex Fridman and featuring a number of guest lecturers. However, as yet, most AI researchers have devoted little attention to AGI, with some claiming that intelligence is too complex to be completely replicated in the near term. However, a small number of computer scientists are active in AGI research, and many of this group are contributing to a series of <a href="/wiki/Conference_on_Artificial_General_Intelligence" title="Conference on Artificial General Intelligence">AGI conferences</a>. The research is extremely diverse and often pioneering in nature. In the introduction to his book,<sup id="cite_ref-FOOTNOTEGoertzelPennachin2006_38-1" class="reference"><a href="#cite_note-FOOTNOTEGoertzelPennachin2006-38">&#91;38&#93;</a></sup> Goertzel says that estimates of the time needed before a truly flexible AGI is built vary from 10 years to over a century, but the consensus in the AGI research community seems to be that the timeline discussed by <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a> in <i><a href="/wiki/The_Singularity_is_Near" class="mw-redirect" title="The Singularity is Near">The Singularity is Near</a></i><sup id="cite_ref-K_42-0" class="reference"><a href="#cite_note-K-42">&#91;42&#93;</a></sup> (i.e. between 2015 and 2045) is plausible.<sup id="cite_ref-FOOTNOTEGoertzel2007_43-0" class="reference"><a href="#cite_note-FOOTNOTEGoertzel2007-43">&#91;43&#93;</a></sup>
</p><p>However, most mainstream AI researchers doubt that progress will be this rapid.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (January 2017)">citation needed</span></a></i>&#93;</sup> Organizations explicitly pursuing AGI include the Swiss AI lab <a href="/wiki/IDSIA" class="mw-redirect" title="IDSIA">IDSIA</a>,<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (December 2017)">citation needed</span></a></i>&#93;</sup> Nnaisense,<sup id="cite_ref-44" class="reference"><a href="#cite_note-44">&#91;44&#93;</a></sup> <a href="/wiki/Vicarious_(company)" title="Vicarious (company)">Vicarious</a>, <a href="/wiki/Maluuba" title="Maluuba">Maluuba</a>,<sup id="cite_ref-baum_9-1" class="reference"><a href="#cite_note-baum-9">&#91;9&#93;</a></sup> the <a href="/wiki/OpenCog" title="OpenCog">OpenCog Foundation</a>, Adaptive AI, <a href="/wiki/LIDA_(cognitive_architecture)" title="LIDA (cognitive architecture)">LIDA</a>, and <a href="/wiki/Numenta" title="Numenta">Numenta</a> and the associated <a href="/wiki/Redwood_Neuroscience_Institute" class="mw-redirect" title="Redwood Neuroscience Institute">Redwood Neuroscience Institute</a>.<sup id="cite_ref-45" class="reference"><a href="#cite_note-45">&#91;45&#93;</a></sup> In addition, organizations such as the <a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a><sup id="cite_ref-46" class="reference"><a href="#cite_note-46">&#91;46&#93;</a></sup> and <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a><sup id="cite_ref-47" class="reference"><a href="#cite_note-47">&#91;47&#93;</a></sup> have been founded to influence the development path of AGI. Finally, projects such as the <a href="/wiki/Human_Brain_Project" title="Human Brain Project">Human Brain Project</a><sup id="cite_ref-48" class="reference"><a href="#cite_note-48">&#91;48&#93;</a></sup> have the goal of building a functioning simulation of the human brain. A 2017 survey of AGI categorized forty-five known "active R&amp;D projects" that explicitly or implicitly (through published research) research AGI, with the largest three being <a href="/wiki/DeepMind" title="DeepMind">DeepMind</a>, the Human Brain Project, and <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a> (based on article<sup id="cite_ref-baum_9-2" class="reference"><a href="#cite_note-baum-9">&#91;9&#93;</a></sup>).
</p><p>In 2019, video game programmer and aerospace engineer <a href="/wiki/John_Carmack" title="John Carmack">John Carmack</a> announced plans to research AGI.
</p><p><a href="/wiki/DeepMind" title="DeepMind">DeepMind</a> with their success in Human Player Simulation for e.g. <a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a> made use of new concepts:
</p>
<ul><li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a> to improve already trained networks with new data or</li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a>, e.g. by <a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">Generative adversarial network</a> to get improved networks by competition.</li></ul>
<h2><span class="mw-headline" id="Processing_power_needed_to_simulate_a_brain">Processing power needed to simulate a brain</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=9" title="Edit section: Processing power needed to simulate a brain">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Whole_brain_emulation">Whole brain emulation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=10" title="Edit section: Whole brain emulation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Mind_uploading" title="Mind uploading">Mind uploading</a></div>
<p>A popular discussed approach to achieving general intelligent action is <a href="/wiki/Whole_brain_emulation" class="mw-redirect" title="Whole brain emulation">whole brain emulation</a>. A low-level brain model is built by <a href="/wiki/Brain_scanning" class="mw-redirect" title="Brain scanning">scanning</a> and <a href="/wiki/Brain_mapping" title="Brain mapping">mapping</a> a biological brain in detail and copying its state into a computer system or another computational device. The computer runs a <a href="/wiki/Computer_simulation" title="Computer simulation">simulation</a> model so faithful to the original that it will behave in essentially the same way as the original brain, or for all practical purposes, indistinguishably.<sup id="cite_ref-Roadmap_49-0" class="reference"><a href="#cite_note-Roadmap-49">&#91;49&#93;</a></sup> Whole brain emulation is discussed in <a href="/wiki/Computational_neuroscience" title="Computational neuroscience">computational neuroscience</a> and <a href="/wiki/Neuroinformatics" title="Neuroinformatics">neuroinformatics</a>, in the context of <a href="/wiki/Brain_simulation" title="Brain simulation">brain simulation</a> for medical research purposes. It is discussed in <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> research<sup id="cite_ref-FOOTNOTEGoertzel2007_43-1" class="reference"><a href="#cite_note-FOOTNOTEGoertzel2007-43">&#91;43&#93;</a></sup> as an approach to strong AI. <a href="/wiki/Neuroimaging" title="Neuroimaging">Neuroimaging</a> technologies that could deliver the necessary detailed understanding are improving rapidly, and <a href="/wiki/Futurist" title="Futurist">futurist</a> Ray Kurzweil in the book <i>The Singularity Is Near</i><sup id="cite_ref-K_42-1" class="reference"><a href="#cite_note-K-42">&#91;42&#93;</a></sup> predicts that a map of sufficient quality will become available on a similar timescale to the required computing power.
</p>
<h3><span class="mw-headline" id="Early_estimates">Early estimates</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=11" title="Edit section: Early estimates">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:402px;"><a href="/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Estimations_of_Human_Brain_Emulation_Required_Performance.svg/400px-Estimations_of_Human_Brain_Emulation_Required_Performance.svg.png" decoding="async" width="400" height="300" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Estimations_of_Human_Brain_Emulation_Required_Performance.svg/600px-Estimations_of_Human_Brain_Emulation_Required_Performance.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Estimations_of_Human_Brain_Emulation_Required_Performance.svg/800px-Estimations_of_Human_Brain_Emulation_Required_Performance.svg.png 2x" data-file-width="800" data-file-height="600" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg" class="internal" title="Enlarge"></a></div>Estimates of how much processing power is needed to emulate a human brain at various levels (from Ray Kurzweil, and <a href="/wiki/Anders_Sandberg" title="Anders Sandberg">Anders Sandberg</a> and <a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a>), along with the fastest supercomputer from <a href="/wiki/TOP500" title="TOP500">TOP500</a> mapped by year. Note the logarithmic scale and exponential trendline, which assumes the computational capacity doubles every 1.1 years. Kurzweil believes that mind uploading will be possible at neural simulation, while the Sandberg, Bostrom report is less certain about where <a href="/wiki/Consciousness" title="Consciousness">consciousness</a> arises.<sup id="cite_ref-FOOTNOTESandbergBoström2008_50-0" class="reference"><a href="#cite_note-FOOTNOTESandbergBoström2008-50">&#91;50&#93;</a></sup></div></div></div><p> For low-level brain simulation, an extremely powerful computer would be required. The <a href="/wiki/Human_brain" title="Human brain">human brain</a> has a huge number of <a href="/wiki/Synapses" class="mw-redirect" title="Synapses">synapses</a>. Each of the 10<sup>11</sup> (one hundred billion) <a href="/wiki/Neurons" class="mw-redirect" title="Neurons">neurons</a> has on average 7,000 synaptic connections (synapses) to other neurons. It has been estimated that the brain of a three-year-old child has about 10<sup>15</sup> synapses (1 quadrillion). This number declines with age, stabilizing by adulthood. Estimates vary for an adult, ranging from 10<sup>14</sup> to 5×10<sup>14</sup> synapses (100 to 500 trillion).<sup id="cite_ref-FOOTNOTEDrachman2005_51-0" class="reference"><a href="#cite_note-FOOTNOTEDrachman2005-51">&#91;51&#93;</a></sup> An estimate of the brain's processing power, based on a simple switch model for neuron activity, is around 10<sup>14</sup> (100 trillion) synaptic updates per second (<a href="/wiki/SUPS" title="SUPS">SUPS</a>).<sup id="cite_ref-FOOTNOTERussellNorvig2003_52-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003-52">&#91;52&#93;</a></sup> In 1997 Kurzweil looked at various estimates for the hardware required to equal the human brain and adopted a figure of 10<sup>16</sup> computations per second (cps).<sup id="cite_ref-53" class="reference"><a href="#cite_note-53">&#91;53&#93;</a></sup> (For comparison, if a "computation" was equivalent to one "<a href="/wiki/FLOPS" title="FLOPS">floating point operation</a>" –  a measure used to rate current <a href="/wiki/Supercomputer" title="Supercomputer">supercomputers</a> – then 10<sup>16</sup> "computations" would be equivalent to 10 <a href="/wiki/Peta-" title="Peta-">petaFLOPS</a>, <a href="/wiki/FLOPS#Performance_records" title="FLOPS">achieved in 2011</a>). He used this figure to predict the necessary hardware would be available sometime between 2015 and 2025, if the exponential growth in computer power at the time of writing continued.
</p><h3><span class="mw-headline" id="Modelling_the_neurons_in_more_detail">Modelling the neurons in more detail</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=12" title="Edit section: Modelling the neurons in more detail">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The <a href="/wiki/Artificial_neuron" title="Artificial neuron">artificial neuron</a> model assumed by Kurzweil and used in many current <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural network</a> implementations is simple compared with <a href="/wiki/Biological_neuron_model" title="Biological neuron model">biological neurons</a>. A brain simulation would likely have to capture the detailed cellular behaviour of biological <a href="/wiki/Neurons" class="mw-redirect" title="Neurons">neurons</a>, presently understood only in the broadest of outlines. The overhead introduced by full modeling of the biological, chemical, and physical details of neural behaviour (especially on a molecular scale) would require computational powers several orders of magnitude larger than Kurzweil's estimate.  In addition the estimates do not account for <a href="/wiki/Glial_cells" class="mw-redirect" title="Glial cells">glial cells</a>, which are at least as numerous as neurons, and which may outnumber neurons by as much as 10:1, and are now known to play a role in cognitive processes.<sup id="cite_ref-Discover2011JanFeb_54-0" class="reference"><a href="#cite_note-Discover2011JanFeb-54">&#91;54&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Current_research">Current research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=13" title="Edit section: Current research">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>There are some research projects that are investigating brain simulation using more sophisticated neural models, implemented on conventional computing architectures. The <a href="/wiki/Artificial_Intelligence_System" title="Artificial Intelligence System">Artificial Intelligence System</a> project implemented non-real time simulations of a "brain" (with 10<sup>11</sup> neurons) in 2005. It took 50 days on a cluster of 27 processors to simulate 1 second of a model.<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">&#91;55&#93;</a></sup> The <a href="/wiki/Blue_Brain" class="mw-redirect" title="Blue Brain">Blue Brain</a> project used one of the fastest supercomputer architectures in the world, <a href="/wiki/IBM" title="IBM">IBM</a>'s <a href="/wiki/Blue_Gene" class="mw-redirect" title="Blue Gene">Blue Gene</a> platform, to create a real time simulation of a single rat <a href="/wiki/Neocortex" title="Neocortex">neocortical column</a> consisting of approximately 10,000 neurons and 10<sup>8</sup> synapses in 2006.<sup id="cite_ref-56" class="reference"><a href="#cite_note-56">&#91;56&#93;</a></sup> A longer term goal is to build a detailed, functional simulation of the physiological processes in the human brain: "It is not impossible to build a human brain and we can do it in 10 years," <a href="/wiki/Henry_Markram" title="Henry Markram">Henry Markram</a>, director of the Blue Brain Project said in 2009 at the <a href="/wiki/TED_(conference)" title="TED (conference)">TED conference</a> in Oxford.<sup id="cite_ref-57" class="reference"><a href="#cite_note-57">&#91;57&#93;</a></sup> There have also been controversial claims to have simulated a <a href="/wiki/Cat_intelligence#Computer_simulation_of_the_cat_brain" title="Cat intelligence">cat brain</a>. Neuro-silicon interfaces have been proposed as an alternative implementation strategy that may scale better.<sup id="cite_ref-58" class="reference"><a href="#cite_note-58">&#91;58&#93;</a></sup>
</p><p><a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> addressed the above arguments ("brains are more complicated", "neurons have to be modeled in more detail") in his 1997 paper "When will computer hardware match the human brain?".<sup id="cite_ref-59" class="reference"><a href="#cite_note-59">&#91;59&#93;</a></sup> He measured the ability of existing software to simulate the functionality of neural tissue, specifically the retina.  His results do not depend on the number of glial cells, nor on what kinds of processing neurons perform where.
</p><p>The actual complexity of modeling biological neurons has been explored in <a href="/wiki/OpenWorm" title="OpenWorm">OpenWorm project</a> that was aimed on complete simulation of a worm that has only 302 neurons in its neural network (among about 1000 cells in total). The animal's neural network has been well documented before the start of the project. However, although the task seemed simple at the beginning, the models based on a generic neural network didn't work. Currently, the efforts are focused on precise emulation of biological neurons (partly on the molecular level), but the result can't be called a total success yet. Even if the number of issues to be solved in a human-brain-scale model is not proportional to the number of neurons, the amount of work along this path is obvious.
</p>
<h3><span class="mw-headline" id="Criticisms_of_simulation-based_approaches">Criticisms of simulation-based approaches</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=14" title="Edit section: Criticisms of simulation-based approaches">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A fundamental criticism of the simulated brain approach derives from <a href="/wiki/Embodied_cognition" title="Embodied cognition">embodied cognition</a> where human embodiment is taken as an essential aspect of human intelligence. Many researchers believe that embodiment is necessary to ground meaning.<sup id="cite_ref-60" class="reference"><a href="#cite_note-60">&#91;60&#93;</a></sup> If this view is correct, any fully functional brain model will need to encompass more than just the neurons (i.e., a robotic body). Goertzel<sup id="cite_ref-FOOTNOTEGoertzel2007_43-2" class="reference"><a href="#cite_note-FOOTNOTEGoertzel2007-43">&#91;43&#93;</a></sup> proposes virtual embodiment (like in <i><a href="/wiki/Second_Life" title="Second Life">Second Life</a></i>), but it is not yet known whether this would be sufficient.
</p><p>Desktop computers using microprocessors capable of more than 10<sup>9</sup> cps (Kurzweil's non-standard unit "computations per second", see above) have been available since 2005. According to the brain power estimates used by Kurzweil (and Moravec), this computer should be capable of supporting a simulation of a bee brain, but despite some interest<sup id="cite_ref-61" class="reference"><a href="#cite_note-61">&#91;61&#93;</a></sup> no such simulation exists<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2011)">citation needed</span></a></i>&#93;</sup>. There are at least three reasons for this:
</p>
<ol><li>The neuron model seems to be oversimplified (see next section).</li>
<li>There is insufficient understanding of higher cognitive processes<sup id="cite_ref-62" class="reference"><a href="#cite_note-62">&#91;62&#93;</a></sup> to establish accurately what the brain's neural activity, observed using techniques such as <a href="/wiki/Neuroimaging#Functional_magnetic_resonance_imaging" title="Neuroimaging">functional magnetic resonance imaging</a>, correlates with.</li>
<li>Even if our understanding of cognition advances sufficiently, early simulation programs are likely to be very inefficient and will, therefore, need considerably more hardware.</li>
<li>The brain of an organism, while critical, may not be an appropriate boundary for a cognitive model.  To simulate a bee brain, it may be necessary to simulate the body, and the environment. <a href="/wiki/The_Extended_Mind" title="The Extended Mind">The Extended Mind</a> thesis formalizes the philosophical concept, and research into <a href="/wiki/Cephalopoda" class="mw-redirect" title="Cephalopoda">cephalopods</a> has demonstrated clear examples of a decentralized system.<sup id="cite_ref-63" class="reference"><a href="#cite_note-63">&#91;63&#93;</a></sup></li></ol>
<p>In addition, the scale of the human brain is not currently well-constrained. One estimate puts the human brain at about 100 billion neurons and 100 trillion synapses.<sup id="cite_ref-64" class="reference"><a href="#cite_note-64">&#91;64&#93;</a></sup><sup id="cite_ref-65" class="reference"><a href="#cite_note-65">&#91;65&#93;</a></sup> Another estimate is 86 billion neurons of which 16.3 billion are in the <a href="/wiki/Cerebral_cortex" title="Cerebral cortex">cerebral cortex</a> and 69 billion in the <a href="/wiki/Cerebellum" title="Cerebellum">cerebellum</a>.<sup id="cite_ref-FOOTNOTEAzevedo_et_al.2009_66-0" class="reference"><a href="#cite_note-FOOTNOTEAzevedo_et_al.2009-66">&#91;66&#93;</a></sup> <a href="/wiki/Glial_cell" class="mw-redirect" title="Glial cell">Glial cell</a> synapses are currently unquantified but are known to be extremely numerous.
</p>
<h2><span class="mw-headline" id="Strong_AI_and_consciousness">Strong AI and consciousness</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=15" title="Edit section: Strong AI and consciousness">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy of artificial intelligence</a> and <a href="/wiki/Turing_test" title="Turing test">Turing test</a></div>
<p>In 1980, philosopher <a href="/wiki/John_Searle" title="John Searle">John Searle</a> coined the term "strong AI" as part of his <a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a> argument.<sup id="cite_ref-67" class="reference"><a href="#cite_note-67">&#91;67&#93;</a></sup> He wanted to distinguish between two different hypotheses about artificial intelligence:<sup id="cite_ref-68" class="reference"><a href="#cite_note-68">&#91;68&#93;</a></sup>
</p>
<ul><li>An artificial intelligence system can <i>think</i> and have a <i>mind</i>.  (The word "mind" has a specific meaning for philosophers, as used in "the <a href="/wiki/Mind_body_problem" class="mw-redirect" title="Mind body problem">mind body problem</a>" or "the <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">philosophy of mind</a>".)</li>
<li>An artificial intelligence system can (only) <i>act like</i> it thinks and has a mind.</li></ul>
<p>The first one is called "the <i>strong</i> AI hypothesis" and the second is "the <i>weak</i> AI hypothesis" because the first one makes the <i>stronger</i> statement: it assumes something special has happened to the machine that goes beyond all its abilities that we can test. Searle referred to the "strong AI hypothesis" as "strong AI". This usage is also common in academic AI research and textbooks.<sup id="cite_ref-69" class="reference"><a href="#cite_note-69">&#91;69&#93;</a></sup>
</p><p>The weak AI hypothesis is equivalent to the hypothesis that artificial general intelligence is possible. According to <a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig</a>, "Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis."<sup id="cite_ref-FOOTNOTERussellNorvig2003947_70-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003947-70">&#91;70&#93;</a></sup>
</p><p>In contrast to Searle, <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a> uses the term "strong AI" to describe any artificial intelligence system that acts like it has a mind,<sup id="cite_ref-K_42-2" class="reference"><a href="#cite_note-K-42">&#91;42&#93;</a></sup> regardless of whether a philosopher would be able to determine if it <i>actually</i> has a mind or not.
In science fiction, AGI is associated with traits such as <a href="/wiki/Consciousness" title="Consciousness">consciousness</a>, <a href="/wiki/Sentience" title="Sentience">sentience</a>, <a href="/wiki/Sapience" class="mw-redirect" title="Sapience">sapience</a>, and <a href="/wiki/Self-awareness" title="Self-awareness">self-awareness</a> observed in living beings. However, according to Searle, it is an open question whether general intelligence is sufficient for consciousness. "Strong AI" (as defined above by Kurzweil) should not be confused with Searle's "<a href="/wiki/Strong_AI_hypothesis" class="mw-redirect" title="Strong AI hypothesis">strong AI hypothesis</a>." The strong AI hypothesis is the claim that a computer which behaves as intelligently as a person must also necessarily have a <a href="/wiki/Mind" title="Mind">mind</a> and <a href="/wiki/Consciousness" title="Consciousness">consciousness</a>. AGI refers only to the amount of intelligence that the machine displays, with or without a mind.
</p>
<h3><span class="mw-headline" id="Consciousness">Consciousness</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=16" title="Edit section: Consciousness">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>There are other aspects of the human mind besides intelligence that are relevant to the concept of strong AI which play a major role in <a href="/wiki/Science_fiction" title="Science fiction">science fiction</a> and the <a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">ethics of artificial intelligence</a>:
</p>
<ul><li><a href="/wiki/Consciousness" title="Consciousness">consciousness</a>: To have <a href="/wiki/Qualia" title="Qualia">subjective experience</a> and <a href="/wiki/Thought" title="Thought">thought</a>.<sup id="cite_ref-71" class="reference"><a href="#cite_note-71">&#91;71&#93;</a></sup></li>
<li><a href="/wiki/Self-awareness" title="Self-awareness">self-awareness</a>: To be aware of oneself as a separate individual, especially to be aware of one's own thoughts.</li>
<li><a href="/wiki/Sentience" title="Sentience">sentience</a>: The ability to "feel" perceptions or emotions subjectively.</li>
<li><a href="/wiki/Sapience" class="mw-redirect" title="Sapience">sapience</a>: The capacity for wisdom.</li></ul>
<p>These traits have a moral dimension, because a machine with this form of strong AI may have legal rights, analogous to the <a href="/wiki/Animal_rights" title="Animal rights">rights of non-human animals</a>. Also, <a href="/wiki/Bill_Joy" title="Bill Joy">Bill Joy</a>, among others, argues a machine with these traits may be a threat to human life or dignity.<sup id="cite_ref-72" class="reference"><a href="#cite_note-72">&#91;72&#93;</a></sup> It remains to be shown whether any of these traits are <a href="/wiki/Necessary_and_sufficient_condition" class="mw-redirect" title="Necessary and sufficient condition">necessary</a> for strong AI. The role of <a href="/wiki/Consciousness" title="Consciousness">consciousness</a> is not clear, and currently there is no agreed test for its presence. If a machine is built with a device that simulates the <a href="/wiki/Neural_correlates_of_consciousness" title="Neural correlates of consciousness">neural correlates of consciousness</a>, would it automatically have self-awareness? It is also possible that some of these properties, such as sentience, <a href="/wiki/Emergence" title="Emergence">naturally emerge</a> from a fully intelligent machine, or that it becomes natural to <i>ascribe</i> these properties to machines once they begin to act in a way that is clearly intelligent. For example, intelligent action may be sufficient for sentience, rather than the other way around.
</p>
<h3><span class="mw-headline" id="Artificial_consciousness_research">Artificial consciousness research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=17" title="Edit section: Artificial consciousness research">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Artificial_consciousness" title="Artificial consciousness">Artificial consciousness</a></div>
<p>Although the role of consciousness in strong AI/AGI is debatable, many AGI researchers<sup id="cite_ref-FOOTNOTEYudkowsky2006_73-0" class="reference"><a href="#cite_note-FOOTNOTEYudkowsky2006-73">&#91;73&#93;</a></sup> regard research that investigates possibilities for implementing consciousness as vital. In an early effort <a href="/wiki/Igor_Aleksander" title="Igor Aleksander">Igor Aleksander</a><sup id="cite_ref-FOOTNOTEAleksander1996_74-0" class="reference"><a href="#cite_note-FOOTNOTEAleksander1996-74">&#91;74&#93;</a></sup> argued that the principles for creating a conscious machine already existed but that it would take forty years to train such a machine to understand <a href="/wiki/Language" title="Language">language</a>.
</p>
<h2><span class="mw-headline" id="Possible_explanations_for_the_slow_progress_of_AI_research">Possible explanations for the slow progress of AI research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=18" title="Edit section: Possible explanations for the slow progress of AI research">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/History_of_artificial_intelligence#The_problems" title="History of artificial intelligence">History of artificial intelligence §&#160;The problems</a></div>
<p>Since the launch of AI research in 1956, the growth of this field has slowed down over time and has stalled the aims of creating machines skilled with intelligent action at the human level.<sup id="cite_ref-FOOTNOTEClocksin2003_75-0" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> A possible explanation for this delay is that computers lack a sufficient scope of memory or processing power.<sup id="cite_ref-FOOTNOTEClocksin2003_75-1" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> In addition, the level of complexity that connects to the process of AI research may also limit the progress of AI research.<sup id="cite_ref-FOOTNOTEClocksin2003_75-2" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup>
</p><p>While most AI researchers believe strong AI can be achieved in the future, there are some individuals like <a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Hubert Dreyfus</a> and <a href="/wiki/Roger_Penrose" title="Roger Penrose">Roger Penrose</a> who deny the possibility of achieving strong AI.<sup id="cite_ref-FOOTNOTEClocksin2003_75-3" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> <a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">John McCarthy</a> was one of various computer scientists who believe human-level AI will be accomplished, but a date cannot accurately be predicted.<sup id="cite_ref-FOOTNOTEMcCarthy2003_76-0" class="reference"><a href="#cite_note-FOOTNOTEMcCarthy2003-76">&#91;76&#93;</a></sup>
</p><p>Conceptual limitations are another possible reason for the slowness in AI research.<sup id="cite_ref-FOOTNOTEClocksin2003_75-4" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> AI researchers may need to modify the conceptual framework of their discipline in order to provide a stronger base and contribution to the quest of achieving strong AI. As William Clocksin wrote in 2003: "the framework starts from Weizenbaum’s observation that intelligence manifests itself only relative to specific social and cultural contexts".<sup id="cite_ref-FOOTNOTEClocksin2003_75-5" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup>
</p><p>Furthermore, AI researchers have been able to create computers that can perform jobs that are complicated for people to do, but conversely they have struggled to develop a computer that is capable of carrying out tasks that are simple for humans to do (<a href="/wiki/Moravec%27s_paradox" title="Moravec&#39;s paradox">Moravec's paradox</a>).<sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:AUDIENCE" class="mw-redirect" title="Wikipedia:AUDIENCE"><span title="An editor has requested that an example be provided. (September 2017)">example  needed</span></a></i>&#93;</sup><sup id="cite_ref-FOOTNOTEClocksin2003_75-6" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> A problem described by David Gelernter is that some people assume thinking and reasoning are equivalent.<sup id="cite_ref-FOOTNOTEGelernter2010_77-0" class="reference"><a href="#cite_note-FOOTNOTEGelernter2010-77">&#91;77&#93;</a></sup> However, the idea of whether thoughts and the creator of those thoughts are isolated individually has intrigued AI researchers.<sup id="cite_ref-FOOTNOTEGelernter2010_77-1" class="reference"><a href="#cite_note-FOOTNOTEGelernter2010-77">&#91;77&#93;</a></sup>
</p><p>The problems that have been encountered in AI research over the past decades have further impeded the progress of AI. The failed predictions that have been promised by AI researchers and the lack of a complete understanding of human behaviors have helped diminish the primary idea of human-level AI.<sup id="cite_ref-FOOTNOTEGoertzel2007_43-3" class="reference"><a href="#cite_note-FOOTNOTEGoertzel2007-43">&#91;43&#93;</a></sup> Although the progress of AI research has brought both improvement and disappointment, most investigators have established optimism about potentially achieving the goal of AI in the 21st century.<sup id="cite_ref-FOOTNOTEGoertzel2007_43-4" class="reference"><a href="#cite_note-FOOTNOTEGoertzel2007-43">&#91;43&#93;</a></sup>
</p><p>Other possible reasons have been proposed for the lengthy research in the progress of strong AI. The intricacy of scientific problems and the need to fully understand the human brain through psychology and neurophysiology have limited many researchers from emulating the function of the human brain into a computer hardware.<sup id="cite_ref-FOOTNOTEMcCarthy2007_78-0" class="reference"><a href="#cite_note-FOOTNOTEMcCarthy2007-78">&#91;78&#93;</a></sup> Many researchers tend to underestimate any doubt that is involved with future predictions of AI, but without taking those issues seriously can people then overlook solutions to problematic questions.<sup id="cite_ref-FOOTNOTEGoertzel2007_43-5" class="reference"><a href="#cite_note-FOOTNOTEGoertzel2007-43">&#91;43&#93;</a></sup>
</p><p>Clocksin says that a conceptual limitation that may impede the progress of AI research is that people may be using the wrong techniques for computer programs and implementation of equipment.<sup id="cite_ref-FOOTNOTEClocksin2003_75-7" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> When AI researchers first began to aim for the goal of artificial intelligence, a main interest was human reasoning.<sup id="cite_ref-FOOTNOTEHolteChoueiry2003_79-0" class="reference"><a href="#cite_note-FOOTNOTEHolteChoueiry2003-79">&#91;79&#93;</a></sup> Researchers hoped to establish computational models of human knowledge through reasoning and to find out how to design a computer with a specific cognitive task.<sup id="cite_ref-FOOTNOTEHolteChoueiry2003_79-1" class="reference"><a href="#cite_note-FOOTNOTEHolteChoueiry2003-79">&#91;79&#93;</a></sup>
</p><p>The practice of abstraction, which people tend to redefine when working with a particular context in research, provides researchers with a concentration on just a few concepts.<sup id="cite_ref-FOOTNOTEHolteChoueiry2003_79-2" class="reference"><a href="#cite_note-FOOTNOTEHolteChoueiry2003-79">&#91;79&#93;</a></sup> The most productive use of abstraction in AI research comes from planning and problem solving.<sup id="cite_ref-FOOTNOTEHolteChoueiry2003_79-3" class="reference"><a href="#cite_note-FOOTNOTEHolteChoueiry2003-79">&#91;79&#93;</a></sup> Although the aim is to increase the speed of a computation, the role of abstraction has posed questions about the involvement of abstraction operators.<sup id="cite_ref-FOOTNOTEZucker2003_80-0" class="reference"><a href="#cite_note-FOOTNOTEZucker2003-80">&#91;80&#93;</a></sup>
</p><p>A possible reason for the slowness in AI relates to the acknowledgement by many AI researchers that heuristics is a section that contains a significant breach between computer performance and human performance.<sup id="cite_ref-FOOTNOTEMcCarthy2007_78-1" class="reference"><a href="#cite_note-FOOTNOTEMcCarthy2007-78">&#91;78&#93;</a></sup> The specific functions that are programmed to a computer may be able to account for many of the requirements that allow it to match human intelligence. These explanations are not necessarily guaranteed to be the fundamental causes for the delay in achieving strong AI, but they are widely agreed by numerous researchers.
</p><p>There have been many AI researchers that debate over the idea whether <a href="/wiki/Affective_computing" title="Affective computing">machines should be created with emotions</a>. There are no emotions in typical models of AI and some researchers say programming emotions into machines allows them to have a mind of their own.<sup id="cite_ref-FOOTNOTEClocksin2003_75-8" class="reference"><a href="#cite_note-FOOTNOTEClocksin2003-75">&#91;75&#93;</a></sup> Emotion sums up the experiences of humans because it allows them to remember those experiences.<sup id="cite_ref-FOOTNOTEGelernter2010_77-2" class="reference"><a href="#cite_note-FOOTNOTEGelernter2010-77">&#91;77&#93;</a></sup>  David Gelernter writes, "No computer will be creative unless it can simulate all the nuances of human emotion."<sup id="cite_ref-FOOTNOTEGelernter2010_77-3" class="reference"><a href="#cite_note-FOOTNOTEGelernter2010-77">&#91;77&#93;</a></sup> This concern about emotion has posed problems for AI researchers and it connects to the concept of strong AI as its research progresses into the future.<sup id="cite_ref-81" class="reference"><a href="#cite_note-81">&#91;81&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Controversies_and_dangers">Controversies and dangers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=19" title="Edit section: Controversies and dangers">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Feasibility">Feasibility</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=20" title="Edit section: Feasibility">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<table class="box-Expand_section plainlinks metadata ambox mbox-small-left ambox-content" role="presentation"><tbody><tr><td class="mbox-image"><a href="/wiki/File:Wiki_letter_w_cropped.svg" class="image"><img alt="[icon]" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png" decoding="async" width="20" height="14" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x" data-file-width="44" data-file-height="31" /></a></td><td class="mbox-text"><div class="mbox-text-span">This section <b>needs expansion</b>. <small>You can help by <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=">adding to it</a>.</small>  <small class="date-container"><i>(<span class="date">February 2016</span>)</i></small></div></td></tr></tbody></table>
<p>Opinions vary both on <i>whether</i> and <i>when</i> artificial general intelligence will arrive. At one extreme, AI pioneer <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Herbert A. Simon</a> wrote in 1965: "machines will be capable, within twenty years, of doing any work a man can do". However, this prediction failed to come true. Microsoft co-founder <a href="/wiki/Paul_Allen" title="Paul Allen">Paul Allen</a> believed that such intelligence is unlikely in the 21st century because it would require "unforeseeable and fundamentally unpredictable breakthroughs" and a "scientifically deep understanding of cognition".<sup id="cite_ref-82" class="reference"><a href="#cite_note-82">&#91;82&#93;</a></sup> Writing in <a href="/wiki/The_Guardian" title="The Guardian">The Guardian</a>, roboticist Alan Winfield claimed the gulf between modern computing and human-level artificial intelligence is as wide as the gulf between current space flight and practical faster-than-light spaceflight.<sup id="cite_ref-83" class="reference"><a href="#cite_note-83">&#91;83&#93;</a></sup> AI experts' views on the feasibility of AGI wax and wane, and may have seen a resurgence in the 2010s. Four polls conducted in 2012 and 2013 suggested that the median guess among experts for when they'd be 50% confident AGI would arrive was 2040 to 2050, depending on the poll, with the mean being 2081. It is also interesting to note 16.5% of the experts answered with "never" when asked the same question but with a 90% confidence instead.<sup id="cite_ref-new_yorker_doomsday_84-0" class="reference"><a href="#cite_note-new_yorker_doomsday-84">&#91;84&#93;</a></sup><sup id="cite_ref-85" class="reference"><a href="#cite_note-85">&#91;85&#93;</a></sup>
Further current AGI progress considerations can be found below <a href="#Tests_for_confirming_human-level_AGI"><i>Tests for confirming human-level AGI</i></a> and <a href="#IQ-Tests_AGI"><i>IQ-tests AGI</i></a>.
</p>
<h3><span class="mw-headline" id="Potential_threat_to_human_existence">Potential threat to human existence<span id="Risk_of_human_extinction"></span></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=21" title="Edit section: Potential threat to human existence">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk from artificial general intelligence</a></div>
<p>The thesis that AI poses an existential risk, and that this risk needs much more attention than it currently gets, has been endorsed by many public figures; perhaps the most famous are <a href="/wiki/Elon_Musk" title="Elon Musk">Elon Musk</a>, <a href="/wiki/Bill_Gates" title="Bill Gates">Bill Gates</a>, and <a href="/wiki/Stephen_Hawking" title="Stephen Hawking">Stephen Hawking</a>. The most notable AI researcher to endorse the thesis is <a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart J. Russell</a>. Endorsers of the thesis sometimes express bafflement at skeptics: Gates states he "can't understand why some people are not concerned",<sup id="cite_ref-BBC_News_86-0" class="reference"><a href="#cite_note-BBC_News-86">&#91;86&#93;</a></sup> and Hawking criticized widespread indifference in his 2014 editorial: 
</p>
<table class="cquote pullquote" role="presentation" style="margin:auto; border-collapse: collapse; border: none; background-color: transparent; width: auto;">
<tbody><tr>
<td style="width: 20px; vertical-align: top; border: none; color: #B2B7F2; font-size: 40px; font-family: &#39;Times New Roman&#39;, Times, serif; font-weight: bold; line-height: .6em; text-align: left; padding: 10px 10px;">“
</td>
<td style="vertical-align: top; border: none; padding: 4px 10px;">'So, facing possible futures of incalculable benefits and risks, the experts are surely doing everything possible to ensure the best outcome, right? Wrong. If a superior alien civilisation sent us a message saying, 'We'll arrive in a few decades,' would we just reply, 'OK, call us when you get here–we'll leave the lights on?' Probably not–but this is more or less what is happening with AI.'<sup id="cite_ref-hawking_editorial_87-0" class="reference"><a href="#cite_note-hawking_editorial-87">&#91;87&#93;</a></sup>
</td>
<td style="width: 20px; vertical-align: bottom; border: none; color: #B2B7F2; font-size: 40px; font-family: &#39;Times New Roman&#39;, Times, serif; font-weight: bold; line-height: .6em; text-align: right; padding: 10px 10px;">”
</td></tr>

</tbody></table>
<p>Many of the scholars who are concerned about existential risk believe that the best way forward would be to conduct (possibly massive) research into solving the difficult "<a href="/wiki/AI_control_problem" title="AI control problem">control problem</a>" to answer the question: what types of safeguards, algorithms, or architectures can programmers implement to maximize the probability that their recursively-improving AI would continue to behave in a friendly, rather than destructive, manner after it reaches superintelligence?<sup id="cite_ref-superintelligence_88-0" class="reference"><a href="#cite_note-superintelligence-88">&#91;88&#93;</a></sup><sup id="cite_ref-physica_scripta_89-0" class="reference"><a href="#cite_note-physica_scripta-89">&#91;89&#93;</a></sup>
</p><p>The thesis that AI can pose existential risk also has many strong detractors. Skeptics sometimes charge that the thesis is crypto-religious, with an irrational belief in the possibility of superintelligence replacing an irrational belief in an omnipotent God; at an extreme, <a href="/wiki/Jaron_Lanier" title="Jaron Lanier">Jaron Lanier</a> argues that the whole concept that current machines are in any way intelligent is "an illusion" and a "stupendous con" by the wealthy.<sup id="cite_ref-atlantic-but-what_90-0" class="reference"><a href="#cite_note-atlantic-but-what-90">&#91;90&#93;</a></sup>
</p><p>Much of existing criticism argues that AGI is unlikely in the short term: computer scientist <a href="/wiki/Gordon_Bell" title="Gordon Bell">Gordon Bell</a> argues that the human race will already destroy itself before it reaches the <a href="/wiki/Technological_singularity" title="Technological singularity">technological singularity</a>. <a href="/wiki/Gordon_Moore" title="Gordon Moore">Gordon Moore</a>, the original proponent of <a href="/wiki/Moore%27s_Law" class="mw-redirect" title="Moore&#39;s Law">Moore's Law</a>, declares that "I am a skeptic. I don't believe (a technological singularity) is likely to happen, at least for a long time. And I don't know why I feel that way." <a href="/wiki/Baidu" title="Baidu">Baidu</a> Vice President <a href="/wiki/Andrew_Ng" title="Andrew Ng">Andrew Ng</a> states AI existential risk is "like worrying about overpopulation on Mars when we have not even set foot on the planet yet."<sup id="cite_ref-shermer_91-0" class="reference"><a href="#cite_note-shermer-91">&#91;91&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=22" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="div-col columns column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em;">
<ul><li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">Automated machine learning</a></li>
<li><a href="/wiki/Machine_ethics" title="Machine ethics">Machine ethics</a></li>
<li><a href="/wiki/Multi-task_learning" title="Multi-task learning">Multi-task learning</a></li>
<li><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence</a></li>
<li><a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a></li>
<li><a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a></li>
<li><a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a></li>
<li><a href="/wiki/Outline_of_artificial_intelligence" title="Outline of artificial intelligence">Outline of artificial intelligence</a></li>
<li><a href="/wiki/Artificial_brain" title="Artificial brain">Artificial brain</a></li>
<li><a href="/wiki/Transfer_learning" title="Transfer learning">Transfer learning</a></li>
<li><a href="/wiki/Outline_of_transhumanism" title="Outline of transhumanism">Outline of transhumanism</a></li>
<li><a href="/wiki/General_game_playing" title="General game playing">General game playing</a></li>
<li><a href="/wiki/Synthetic_intelligence" title="Synthetic intelligence">Synthetic intelligence</a></li>
<li><a href="/wiki/Intelligence_amplification" title="Intelligence amplification">Intelligence amplification</a> (IA), the use of information technology in augmenting human intelligence instead of creating an external autonomous "AGI"</li></ul></div>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=23" title="Edit section: Notes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Kurzweil, <i>Singularity</i> (2005) p. 260</span>
</li>
<li id="cite_note-Kurzweil_2005-08-05-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kurzweil_2005-08-05_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kurzweil_2005-08-05_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFKurzweil2005" class="citation">Kurzweil, Ray (5 August 2005), <a rel="nofollow" class="external text" href="https://www.forbes.com/home/free_forbes/2005/0815/030.htmlhttps://www.forbes.com/home/free_forbes/2005/0815/030.html">"Long Live AI"</a>, <i><a href="/wiki/Forbes" title="Forbes">Forbes</a></i></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Forbes&amp;rft.atitle=Long+Live+AI&amp;rft.date=2005-08-05&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fhome%2Ffree_forbes%2F2005%2F0815%2F030.htmlhttps%3A%2F%2Fwww.forbes.com%2Fhome%2Ffree_forbes%2F2005%2F0815%2F030.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style>: Kurzweil describes strong AI as "machine intelligence with the full range of human intelligence."</span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite id="CITEREFTreder2005" class="citation">Treder, Mike (10 August 2005), <a rel="nofollow" class="external text" href="https://crnano.typepad.com/crnblog/2005/08/advanced_human_.html">"Advanced Human Intelligence"</a>, <i>Responsible Nanotechnology</i>, <a rel="nofollow" class="external text" href="https://web.archive.org/web/20191016214415/https://crnano.typepad.com/crnblog/2005/08/advanced_human_.html">archived</a> from the original on 16 October 2019</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Responsible+Nanotechnology&amp;rft.atitle=Advanced+Human+Intelligence&amp;rft.date=2005-08-10&amp;rft.aulast=Treder&amp;rft.aufirst=Mike&amp;rft_id=https%3A%2F%2Fcrnano.typepad.com%2Fcrnblog%2F2005%2F08%2Fadvanced_human_.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://tedxtalks.ted.com/video/The-Age-of-Artificial-Intellige">"The Age of Artificial Intelligence: George John at TEDxLondonBusinessSchool 2013"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140226123940/http://tedxtalks.ted.com/video/The-Age-of-Artificial-Intellige">Archived</a> from the original on 26 February 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">22 February</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Age+of+Artificial+Intelligence%3A+George+John+at+TEDxLondonBusinessSchool+2013&amp;rft_id=http%3A%2F%2Ftedxtalks.ted.com%2Fvideo%2FThe-Age-of-Artificial-Intellige&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FOOTNOTENewellSimon1976-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTENewellSimon1976_5-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFNewellSimon1976">Newell &amp; Simon 1976</a>, This is the term they use for "human-level" intelligence in the <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system</a> hypothesis.</span>
</li>
<li id="cite_note-FOOTNOTESearle1980-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle1980_6-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, See below for the origin of the term "strong AI", and see the academic definition of "<a href="/wiki/Chinese_room#Strong_AI" title="Chinese room">strong AI</a>" in the article <a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a>.</span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Encyclopædia Britannica <a rel="nofollow" class="external text" href="http://www.britannica.com/eb/article-219086/artificial-intelligence">Strong AI, applied AI, and cognitive simulation</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20071015054758/http://www.britannica.com/eb/article-219086/artificial-intelligence">Archived</a> 15 October 2007 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> or Jack Copeland <a rel="nofollow" class="external text" href="http://www.cs.usfca.edu/www.AlanTuring.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI02.html">What is artificial intelligence?</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20070818125256/http://www.cs.usfca.edu/www.AlanTuring.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI02.html">Archived</a> 18 August 2007 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> on AlanTuring.net</span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm">"The Open University on Strong and Weak AI"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20090925043908/http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm">Archived</a> from the original on 25 September 2009<span class="reference-accessdate">. Retrieved <span class="nowrap">8 October</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Open+University+on+Strong+and+Weak+AI&amp;rft_id=http%3A%2F%2Fwww.open2.net%2Fnextbigthing%2Fai%2Fai_in_depth%2Fin_depth.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><sup class="noprint Inline-Template"><span style="white-space: nowrap;">&#91;<i><a href="/wiki/Wikipedia:Link_rot" title="Wikipedia:Link rot"><span title="&#160;Dead link since October 2019">dead link</span></a></i>&#93;</span></sup></span>
</li>
<li id="cite_note-baum-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-baum_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-baum_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-baum_9-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Baum, Seth (12 November 2017). <a rel="nofollow" class="external text" href="https://ssrn.com/abstract=3070741">"Baum, Seth, A Survey of Artificial General Intelligence Projects for Ethics, Risk, and Policy (November 12, 2017). Global Catastrophic Risk Institute Working Paper 17-1"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Baum%2C+Seth%2C+A+Survey+of+Artificial+General+Intelligence+Projects+for+Ethics%2C+Risk%2C+and+Policy+%28November+12%2C+2017%29.+Global+Catastrophic+Risk+Institute+Working+Paper+17-1&amp;rft.date=2017-11-12&amp;rft.aulast=Baum&amp;rft.aufirst=Seth&amp;rft_id=https%3A%2F%2Fssrn.com%2Fabstract%3D3070741&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text">AI founder <a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">John McCarthy</a> writes: "we cannot yet characterize in general what kinds of computational procedures we want to call intelligent." <cite class="citation web"><a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">McCarthy, John</a> (2007). <a rel="nofollow" class="external text" href="http://www-formal.stanford.edu/jmc/whatisai/node1.html">"Basic Questions"</a>. <a href="/wiki/Stanford_University" title="Stanford University">Stanford University</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20071026100601/http://www-formal.stanford.edu/jmc/whatisai/node1.html">Archived</a> from the original on 26 October 2007<span class="reference-accessdate">. Retrieved <span class="nowrap">6 December</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Basic+Questions&amp;rft.pub=Stanford+University&amp;rft.date=2007&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rft_id=http%3A%2F%2Fwww-formal.stanford.edu%2Fjmc%2Fwhatisai%2Fnode1.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/> (For a discussion of some definitions of intelligence used by <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> researchers, see <a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">philosophy of artificial intelligence</a>.)</span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">
This list of intelligent traits is based on the topics covered by major AI textbooks, including:
<a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>,
<a href="#CITEREFLugerStubblefield2004">Luger &amp; Stubblefield 2004</a>,
<a href="#CITEREFPooleMackworthGoebel1998">Poole, Mackworth &amp; Goebel 1998</a> and
<a href="#CITEREFNilsson1998">Nilsson 1998</a>.</span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text">Pfeifer, R. and Bongard J. C., How the body shapes the way we think: a new view of intelligence (The MIT Press, 2007). <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-262-16239-3" title="Special:BookSources/0-262-16239-3">0-262-16239-3</a></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation journal">White, R. W. (1959). "Motivation reconsidered: The concept of competence". <i>Psychological Review</i>. <b>66</b> (5): 297–333. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1037%2Fh0040934">10.1037/h0040934</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/13844397">13844397</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychological+Review&amp;rft.atitle=Motivation+reconsidered%3A+The+concept+of+competence&amp;rft.volume=66&amp;rft.issue=5&amp;rft.pages=297-333&amp;rft.date=1959&amp;rft_id=info%3Adoi%2F10.1037%2Fh0040934&amp;rft_id=info%3Apmid%2F13844397&amp;rft.aulast=White&amp;rft.aufirst=R.+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><a href="#CITEREFJohnson1987">Johnson 1987</a></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text">deCharms, R. (1968). Personal causation. New York: Academic Press.</span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation web">Muehlhauser, Luke (11 August 2013). <a rel="nofollow" class="external text" href="http://intelligence.org/2013/08/11/what-is-agi/">"What is AGI?"</a>. Machine Intelligence Research Institute. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140425115445/http://intelligence.org/2013/08/11/what-is-agi/">Archived</a> from the original on 25 April 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">1 May</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=What+is+AGI%3F&amp;rft.pub=Machine+Intelligence+Research+Institute&amp;rft.date=2013-08-11&amp;rft.aulast=Muehlhauser&amp;rft.aufirst=Luke&amp;rft_id=http%3A%2F%2Fintelligence.org%2F2013%2F08%2F11%2Fwhat-is-agi%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.talkyblog.com/artificial_general_intelligence_agi/">"What is Artificial General Intelligence (AGI)? | 4 Tests For Ensuring Artificial General Intelligence"</a>. <i>Talky Blog</i>. 13 July 2019. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20190717071152/https://www.talkyblog.com/artificial_general_intelligence_agi/">Archived</a> from the original on 17 July 2019<span class="reference-accessdate">. Retrieved <span class="nowrap">17 July</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Talky+Blog&amp;rft.atitle=What+is+Artificial+General+Intelligence+%28AGI%29%3F+%7C+4+Tests+For+Ensuring+Artificial+General+Intelligence&amp;rft.date=2019-07-13&amp;rft_id=https%3A%2F%2Fwww.talkyblog.com%2Fartificial_general_intelligence_agi%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Liu, Feng; Shi, Yong; Liu, Ying (2017). "Intelligence Quotient and Intelligence Grade of Artificial Intelligence". <i>Annals of Data Science</i>. <b>4</b> (2): 179–191. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1709.10242">1709.10242</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs40745-017-0109-0">10.1007/s40745-017-0109-0</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Data+Science&amp;rft.atitle=Intelligence+Quotient+and+Intelligence+Grade+of+Artificial+Intelligence&amp;rft.volume=4&amp;rft.issue=2&amp;rft.pages=179-191&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1709.10242&amp;rft_id=info%3Adoi%2F10.1007%2Fs40745-017-0109-0&amp;rft.aulast=Liu&amp;rft.aufirst=Feng&amp;rft.au=Shi%2C+Yong&amp;rft.au=Liu%2C+Ying&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://t3n.de/news/iq-kind-schlauer-google-ki-siri-864003">"Google-KI doppelt so schlau wie Siri"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20190103055657/https://t3n.de/news/iq-kind-schlauer-google-ki-siri-864003/">Archived</a> from the original on 3 January 2019<span class="reference-accessdate">. Retrieved <span class="nowrap">2 January</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Google-KI+doppelt+so+schlau+wie+Siri&amp;rft_id=https%3A%2F%2Ft3n.de%2Fnews%2Fiq-kind-schlauer-google-ki-siri-864003&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Shapiro92-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-Shapiro92_20-0">^</a></b></span> <span class="reference-text">Shapiro, Stuart C. (1992). <a rel="nofollow" class="external text" href="http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf">Artificial Intelligence</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160201014644/http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf">Archived</a> 1 February 2016 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> In Stuart C. Shapiro (Ed.), <i>Encyclopedia of Artificial Intelligence</i> (Second Edition, pp.&#160;54–57). New York: John Wiley. (Section 4 is on "AI-Complete Tasks".)</span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text">Roman V. Yampolskiy. Turing Test as a Defining Feature of AI-Completeness. In Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) --In the footsteps of Alan Turing. Xin-She Yang (Ed.). pp. 3–17. (Chapter 1). Springer, London. 2013. <a rel="nofollow" class="external free" href="http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf">http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130522094547/http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf">Archived</a> 22 May 2013 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text">Luis von Ahn, Manuel Blum, Nicholas Hopper, and John Langford. <a rel="nofollow" class="external text" href="http://www.captcha.net/captcha_crypt.pdf">CAPTCHA: Using Hard AI Problems for Security</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160304001102/http://www.captcha.net/captcha_crypt.pdf">Archived</a> 4 March 2016 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>. In Proceedings of Eurocrypt, Vol. 2656 (2003), pp. 294–311.</span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bergmair, Richard (7 January 2006). "Natural Language Steganography and an "AI-complete" Security Primitive". <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.129">10.1.1.105.129</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Natural+Language+Steganography+and+an+%22AI-complete%22+Security+Primitive&amp;rft.date=2006-01-07&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.105.129&amp;rft.aulast=Bergmair&amp;rft.aufirst=Richard&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/> (unpublished?)</span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;48–50</span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><a href="#CITEREFSimon1965">Simon 1965</a>, p.&#160;96 quoted in <a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;109</span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://mitpress.mit.edu/e-books/Hal/chap2/two1.html">"Scientist on the Set: An Interview with Marvin Minsky"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120716182537/http://mitpress.mit.edu/e-books/Hal/chap2/two1.html">Archived</a> from the original on 16 July 2012<span class="reference-accessdate">. Retrieved <span class="nowrap">5 April</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Scientist+on+the+Set%3A+An+Interview+with+Marvin+Minsky&amp;rft_id=http%3A%2F%2Fmitpress.mit.edu%2Fe-books%2FHal%2Fchap2%2Ftwo1.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text">Marvin Minsky to <a href="#CITEREFDarrach1970">Darrach (1970)</a>, quoted in <a href="#CITEREFCrevier1993">Crevier (1993</a>, p.&#160;109).</span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text">The <a href="/wiki/Lighthill_report" title="Lighthill report">Lighthill report</a> specifically criticized AI's "grandiose objectives" and led the dismantling of AI research in England. (<a href="#CITEREFLighthill1973">Lighthill 1973</a>; <a href="#CITEREFHowe1994">Howe 1994</a>) In the U.S., <a href="/wiki/DARPA" title="DARPA">DARPA</a> became determined to fund only "mission-oriented direct research, rather than basic undirected research". See (<a href="#CITEREFNRC1999">NRC 1999</a>) under "Shift to Applied Research Increases Investment". See also (<a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;115–117) and (<a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, pp.&#160;21–22)</span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;211, <a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;24 and see also <a href="#CITEREFFeigenbaumMcCorduck1983">Feigenbaum &amp; McCorduck 1983</a></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;161–162,197–203,240; <a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;25; <a href="#CITEREFNRC1999">NRC 1999</a>, under "Shift to Applied Research Increases Investment"</span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;209–212</span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text">As AI founder <a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">John McCarthy</a> writes "it would be a great relief to the rest of the workers in AI if the inventors of new general formalisms would express their hopes in a more guarded form than has sometimes been the case." <cite class="citation web"><a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">McCarthy, John</a> (2000). <a rel="nofollow" class="external text" href="http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html">"Reply to Lighthill"</a>. Stanford University. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20080930164952/http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html">Archived</a> from the original on 30 September 2008<span class="reference-accessdate">. Retrieved <span class="nowrap">29 September</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Reply+to+Lighthill&amp;rft.pub=Stanford+University&amp;rft.date=2000&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rft_id=http%3A%2F%2Fwww-formal.stanford.edu%2Fjmc%2Freviews%2Flighthill%2Flighthill.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text">"At its low point, some computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers."<cite class="citation news">Markoff, John (14 October 2005). <a rel="nofollow" class="external text" href="https://www.nytimes.com/2005/10/14/technology/14artificial.html?ei=5070&amp;en=11ab55edb7cead5e&amp;ex=1185940800&amp;adxnnl=1&amp;adxnnlx=1185805173-o7WsfW7qaP0x5/NUs1cQCQ">"Behind Artificial Intelligence, a Squadron of Bright Real People"</a>. <i>The New York Times</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Behind+Artificial+Intelligence%2C+a+Squadron+of+Bright+Real+People&amp;rft.date=2005-10-14&amp;rft.aulast=Markoff&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2005%2F10%2F14%2Ftechnology%2F14artificial.html%3Fei%3D5070%26en%3D11ab55edb7cead5e%26ex%3D1185940800%26adxnnl%3D1%26adxnnlx%3D1185805173-o7WsfW7qaP0x5%2FNUs1cQCQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, pp.&#160;25–26</span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://blogs.gartner.com/smarterwithgartner/files/2018/08/PR_490866_5_Trends_in_the_Emerging_Tech_Hype_Cycle_2018_Hype_Cycle.png">"Trends in the Emerging Tech Hype Cycle"</a>. Gartner Reports. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20190522024829/https://blogs.gartner.com/smarterwithgartner/files/2018/08/PR_490866_5_Trends_in_the_Emerging_Tech_Hype_Cycle_2018_Hype_Cycle.png">Archived</a> from the original on 22 May 2019<span class="reference-accessdate">. Retrieved <span class="nowrap">7 May</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Trends+in+the+Emerging+Tech+Hype+Cycle&amp;rft.pub=Gartner+Reports&amp;rft_id=https%3A%2F%2Fblogs.gartner.com%2Fsmarterwithgartner%2Ffiles%2F2018%2F08%2FPR_490866_5_Trends_in_the_Emerging_Tech_Hype_Cycle_2018_Hype_Cycle.png&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><a href="#CITEREFMoravec1988">Moravec 1988</a>, p.&#160;20</span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><cite class="citation journal">Harnad, S (1990). "The Symbol Grounding Problem". <i>Physica D</i>. <b>42</b> (1–3): 335–346. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/cs/9906002">cs/9906002</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/1990PhyD...42..335H">1990PhyD...42..335H</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2F0167-2789%2890%2990087-6">10.1016/0167-2789(90)90087-6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Physica+D&amp;rft.atitle=The+Symbol+Grounding+Problem&amp;rft.volume=42&amp;rft.issue=1%E2%80%933&amp;rft.pages=335-346&amp;rft.date=1990&amp;rft_id=info%3Aarxiv%2Fcs%2F9906002&amp;rft_id=info%3Adoi%2F10.1016%2F0167-2789%2890%2990087-6&amp;rft_id=info%3Abibcode%2F1990PhyD...42..335H&amp;rft.aulast=Harnad&amp;rft.aufirst=S&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FOOTNOTEGoertzelPennachin2006-38"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEGoertzelPennachin2006_38-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGoertzelPennachin2006_38-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFGoertzelPennachin2006">Goertzel &amp; Pennachin 2006</a>.</span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-39">^</a></b></span> <span class="reference-text"><a href="#CITEREFGubrud1997">Gubrud 1997</a></span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-40">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://goertzel.org/who-coined-the-term-agi/">"Who coined the term "AGI"?&#160;» goertzel.org"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20181228083048/http://goertzel.org/who-coined-the-term-agi/">Archived</a> from the original on 28 December 2018<span class="reference-accessdate">. Retrieved <span class="nowrap">28 December</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Who+coined+the+term+%22AGI%22%3F+%C2%BB+goertzel.org&amp;rft_id=http%3A%2F%2Fgoertzel.org%2Fwho-coined-the-term-agi%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>, via <a href="/wiki/Life_3.0" title="Life 3.0">Life 3.0</a>: 'The term "AGI" was popularized by... Shane Legg, Mark Gubrud and Ben Goertzel'</span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text"><a href="#CITEREFGoertzelWang2006">Goertzel &amp; Wang 2006</a>. See also <a href="#CITEREFWang2006">Wang (2006)</a> with an up-to-date summary and lots of links.</span>
</li>
<li id="cite_note-K-42"><span class="mw-cite-backlink">^ <a href="#cite_ref-K_42-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-K_42-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-K_42-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">(<a href="#CITEREFKurzweil2005">Kurzweil 2005</a>, p.&#160;260) or see <a rel="nofollow" class="external text" href="http://crnano.typepad.com/crnblog/2005/08/advanced_human_.html">Advanced Human Intelligence</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20110630032301/http://crnano.typepad.com/crnblog/2005/08/advanced_human_.html">Archived</a> 30 June 2011 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> where he defines strong AI as "machine intelligence with the full range of human intelligence."</span>
</li>
<li id="cite_note-FOOTNOTEGoertzel2007-43"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEGoertzel2007_43-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGoertzel2007_43-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGoertzel2007_43-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGoertzel2007_43-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGoertzel2007_43-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGoertzel2007_43-5"><sup><i><b>f</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFGoertzel2007">Goertzel 2007</a>.</span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text"><cite class="citation news">Markoff, John (27 November 2016). <a rel="nofollow" class="external text" href="https://www.nytimes.com/2016/11/27/technology/artificial-intelligence-pioneer-jurgen-schmidhuber-overlooked.html">"When A.I. Matures, It May Call Jürgen Schmidhuber 'Dad<span class="cs1-kern-right">'</span>"</a>. <i>The New York Times</i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20171226234555/https://www.nytimes.com/2016/11/27/technology/artificial-intelligence-pioneer-jurgen-schmidhuber-overlooked.html">Archived</a> from the original on 26 December 2017<span class="reference-accessdate">. Retrieved <span class="nowrap">26 December</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=When+A.I.+Matures%2C+It+May+Call+J%C3%BCrgen+Schmidhuber+%27Dad%27&amp;rft.date=2016-11-27&amp;rft.aulast=Markoff&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2016%2F11%2F27%2Ftechnology%2Fartificial-intelligence-pioneer-jurgen-schmidhuber-overlooked.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/James_Barrat" title="James Barrat">James Barrat</a> (2013). "Chapter 11: A Hard Takeoff". <a href="/wiki/Our_Final_Invention" title="Our Final Invention"><i>Our Final Invention: Artificial Intelligence and the End of the Human Era</i></a> (First ed.). New York: St. Martin's Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9780312622374" title="Special:BookSources/9780312622374"><bdi>9780312622374</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+11%3A+A+Hard+Takeoff&amp;rft.btitle=Our+Final+Invention%3A+Artificial+Intelligence+and+the+End+of+the+Human+Era&amp;rft.place=New+York&amp;rft.edition=First&amp;rft.pub=St.+Martin%27s+Press&amp;rft.date=2013&amp;rft.isbn=9780312622374&amp;rft.au=James+Barrat&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://intelligence.org/about/">"About the Machine Intelligence Research Institute"</a>. <i>Machine Intelligence Research Institute</i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180121025925/https://intelligence.org/about/">Archived</a> from the original on 21 January 2018<span class="reference-accessdate">. Retrieved <span class="nowrap">26 December</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Machine+Intelligence+Research+Institute&amp;rft.atitle=About+the+Machine+Intelligence+Research+Institute&amp;rft_id=https%3A%2F%2Fintelligence.org%2Fabout%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-47">^</a></b></span> <span class="reference-text"><cite class="citation news"><a rel="nofollow" class="external text" href="https://openai.com/about/">"About OpenAI"</a>. <i><a href="/wiki/OpenAI" title="OpenAI">OpenAI</a></i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20171222181056/https://openai.com/about/">Archived</a> from the original on 22 December 2017<span class="reference-accessdate">. Retrieved <span class="nowrap">26 December</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=OpenAI&amp;rft.atitle=About+OpenAI&amp;rft_id=https%3A%2F%2Fopenai.com%2Fabout%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text"><cite class="citation news">Theil, Stefan. <a rel="nofollow" class="external text" href="https://www.scientificamerican.com/article/why-the-human-brain-project-went-wrong-and-how-to-fix-it/">"Trouble in Mind"</a>. <i>Scientific American</i>. pp.&#160;36–42. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2015SciAm.313d..36T">2015SciAm.313d..36T</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fscientificamerican1015-36">10.1038/scientificamerican1015-36</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20171109234151/https://www.scientificamerican.com/article/why-the-human-brain-project-went-wrong-and-how-to-fix-it/">Archived</a> from the original on 9 November 2017<span class="reference-accessdate">. Retrieved <span class="nowrap">26 December</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Trouble+in+Mind&amp;rft.pages=36-42&amp;rft_id=info%3Adoi%2F10.1038%2Fscientificamerican1015-36&amp;rft_id=info%3Abibcode%2F2015SciAm.313d..36T&amp;rft.aulast=Theil&amp;rft.aufirst=Stefan&amp;rft_id=https%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fwhy-the-human-brain-project-went-wrong-and-how-to-fix-it%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Roadmap-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-Roadmap_49-0">^</a></b></span> <span class="reference-text">
<a href="#CITEREFSandbergBoström2008">Sandberg &amp; Boström 2008</a>. "The basic idea is to take a particular brain, scan its structure in detail, and construct a software model of it that is so faithful to the original that, when run on appropriate hardware, it will behave in essentially the same way as the original brain."</span>
</li>
<li id="cite_note-FOOTNOTESandbergBoström2008-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESandbergBoström2008_50-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSandbergBoström2008">Sandberg &amp; Boström 2008</a>.</span>
</li>
<li id="cite_note-FOOTNOTEDrachman2005-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEDrachman2005_51-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFDrachman2005">Drachman 2005</a>.</span>
</li>
<li id="cite_note-FOOTNOTERussellNorvig2003-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTERussellNorvig2003_52-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>.</span>
</li>
<li id="cite_note-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-53">^</a></b></span> <span class="reference-text">In "Mind Children" <a href="#CITEREFMoravec1988">Moravec 1988</a>, p.&#160;61 10<sup>15</sup> cps is used. More recently, in 1997, &lt;<cite class="citation web"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20060615031852/http://transhumanist.com/volume1/moravec.htm">"Archived copy"</a>. Archived from <a rel="nofollow" class="external text" href="https://www.transhumanist.com/volume1/moravec.htm">the original</a> on 15 June 2006<span class="reference-accessdate">. Retrieved <span class="nowrap">23 June</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Archived+copy&amp;rft_id=http%3A%2F%2Fwww.transhumanist.com%2Fvolume1%2Fmoravec.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: archived copy as title (<a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>&gt; Moravec argued for 10<sup>8</sup> MIPS which would roughly correspond to 10<sup>14</sup> cps.  Moravec talks in terms of MIPS, not "cps", which is a non-standard term Kurzweil introduced.</span>
</li>
<li id="cite_note-Discover2011JanFeb-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-Discover2011JanFeb_54-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Swaminathan, Nikhil (January–February 2011). <a rel="nofollow" class="external text" href="http://discovermagazine.com/2011/jan-feb/62">"Glia—the other brain cells"</a>. <i>Discover</i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140208071350/http://discovermagazine.com/2011/jan-feb/62">Archived</a> from the original on 8 February 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">24 January</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Discover&amp;rft.atitle=Glia%E2%80%94the+other+brain+cells&amp;rft.date=2011-01%2F2011-02&amp;rft.au=Swaminathan%2C+Nikhil&amp;rft_id=http%3A%2F%2Fdiscovermagazine.com%2F2011%2Fjan-feb%2F62&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55">^</a></b></span> <span class="reference-text"><cite class="citation journal">Izhikevich, Eugene M.; Edelman, Gerald M. (4 March 2008). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20090612095651/http://vesicle.nsi.edu/users/izhikevich/publications/large-scale_model_of_human_brain.pdf">"Large-scale model of mammalian thalamocortical systems"</a> <span class="cs1-format">(PDF)</span>. <i>PNAS</i>. <b>105</b> (9): 3593–3598. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2008PNAS..105.3593I">2008PNAS..105.3593I</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1073%2Fpnas.0712231105">10.1073/pnas.0712231105</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2265160">2265160</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/18292226">18292226</a>. Archived from <a rel="nofollow" class="external text" href="http://vesicle.nsi.edu/users/izhikevich/publications/large-scale_model_of_human_brain.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 12 June 2009<span class="reference-accessdate">. Retrieved <span class="nowrap">23 June</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PNAS&amp;rft.atitle=Large-scale+model+of+mammalian+thalamocortical+systems&amp;rft.volume=105&amp;rft.issue=9&amp;rft.pages=3593-3598&amp;rft.date=2008-03-04&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2265160&amp;rft_id=info%3Apmid%2F18292226&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.0712231105&amp;rft_id=info%3Abibcode%2F2008PNAS..105.3593I&amp;rft.aulast=Izhikevich&amp;rft.aufirst=Eugene+M.&amp;rft.au=Edelman%2C+Gerald+M.&amp;rft_id=http%3A%2F%2Fvesicle.nsi.edu%2Fusers%2Fizhikevich%2Fpublications%2Flarge-scale_model_of_human_brain.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-56">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://bluebrain.epfl.ch/Jahia/site/bluebrain/op/edit/pid/19085">"Project Milestones"</a>. <i>Blue Brain</i><span class="reference-accessdate">. Retrieved <span class="nowrap">11 August</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Blue+Brain&amp;rft.atitle=Project+Milestones&amp;rft_id=http%3A%2F%2Fbluebrain.epfl.ch%2FJahia%2Fsite%2Fbluebrain%2Fop%2Fedit%2Fpid%2F19085&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-57">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://news.bbc.co.uk/1/hi/technology/8164060.stm">"Artificial brain '10 years away' 2009 BBC news"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20170726040959/http://news.bbc.co.uk/1/hi/technology/8164060.stm">Archived</a> from the original on 26 July 2017<span class="reference-accessdate">. Retrieved <span class="nowrap">25 July</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Artificial+brain+%2710+years+away%27+2009+BBC+news&amp;rft_id=http%3A%2F%2Fnews.bbc.co.uk%2F1%2Fhi%2Ftechnology%2F8164060.stm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-58">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://gauntlet.ucalgary.ca/story/10343">University of Calgary news</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20090818081044/http://gauntlet.ucalgary.ca/story/10343">Archived</a> 18 August 2009 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, <a rel="nofollow" class="external text" href="http://www.nbcnews.com/id/12037941">NBC News news</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20170704063922/http://www.nbcnews.com/id/12037941/">Archived</a> 4 July 2017 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></span>
</li>
<li id="cite_note-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-59">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20060615031852/http://transhumanist.com/volume1/moravec.htm">"Archived copy"</a>. Archived from <a rel="nofollow" class="external text" href="https://www.transhumanist.com/volume1/moravec.htm">the original</a> on 15 June 2006<span class="reference-accessdate">. Retrieved <span class="nowrap">23 June</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Archived+copy&amp;rft_id=http%3A%2F%2Fwww.transhumanist.com%2Fvolume1%2Fmoravec.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: archived copy as title (<a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-60">^</a></b></span> <span class="reference-text"><a href="#CITEREFde_VegaGlenbergGraesser2008">de Vega, Glenberg &amp; Graesser 2008</a>. A wide range of views in current research, all of which require grounding to some degree</span>
</li>
<li id="cite_note-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-61">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20111005162232/http://www.setiai.com/archives/cat_honey_bee_brain.html">"some links to bee brain studies"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.setiai.com/archives/cat_honey_bee_brain.html">the original</a> on 5 October 2011<span class="reference-accessdate">. Retrieved <span class="nowrap">30 March</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=some+links+to+bee+brain+studies&amp;rft_id=http%3A%2F%2Fwww.setiai.com%2Farchives%2Fcat_honey_bee_brain.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-62">^</a></b></span> <span class="reference-text">In Goertzels' AGI book (<a href="#CITEREFYudkowsky2006">Yudkowsky 2006</a>), Yudkowsky proposes 5 levels of organisation that must be understood – code/data, sensory modality, concept &amp; category, thought, and deliberation (consciousness) – in order to use the available hardware</span>
</li>
<li id="cite_note-63"><span class="mw-cite-backlink"><b><a href="#cite_ref-63">^</a></b></span> <span class="reference-text"><cite class="citation journal">Yekutieli, Y; Sagiv-Zohar, R; Aharonov, R; Engel, Y; Hochner, B; Flash, T (August 2005). "Dynamic model of the octopus arm. I. Biomechanics of the octopus reaching movement". <i>J. Neurophysiol</i>. <b>94</b> (2): 1443–58. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1152%2Fjn.00684.2004">10.1152/jn.00684.2004</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/15829594">15829594</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J.+Neurophysiol.&amp;rft.atitle=Dynamic+model+of+the+octopus+arm.+I.+Biomechanics+of+the+octopus+reaching+movement&amp;rft.volume=94&amp;rft.issue=2&amp;rft.pages=1443-58&amp;rft.date=2005-08&amp;rft_id=info%3Adoi%2F10.1152%2Fjn.00684.2004&amp;rft_id=info%3Apmid%2F15829594&amp;rft.aulast=Yekutieli&amp;rft.aufirst=Y&amp;rft.au=Sagiv-Zohar%2C+R&amp;rft.au=Aharonov%2C+R&amp;rft.au=Engel%2C+Y&amp;rft.au=Hochner%2C+B&amp;rft.au=Flash%2C+T&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-64">^</a></b></span> <span class="reference-text"><a href="#CITEREFWilliamsHerrup1988">Williams &amp; Herrup 1988</a></span>
</li>
<li id="cite_note-65"><span class="mw-cite-backlink"><b><a href="#cite_ref-65">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://search.eb.com/eb/article-75525">"nervous system, human."</a> <i><a href="/wiki/Encyclop%C3%A6dia_Britannica" title="Encyclopædia Britannica">Encyclopædia Britannica</a></i>. 9 January 2007</span>
</li>
<li id="cite_note-FOOTNOTEAzevedo_et_al.2009-66"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEAzevedo_et_al.2009_66-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFAzevedo_et_al.2009">Azevedo et al. 2009</a>.</span>
</li>
<li id="cite_note-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-67">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a></span>
</li>
<li id="cite_note-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-68">^</a></b></span> <span class="reference-text">As defined in a standard AI textbook: "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis." (<a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>)</span>
</li>
<li id="cite_note-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-69">^</a></b></span> <span class="reference-text">For example:
<ul><li><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>,</li>
<li><a rel="nofollow" class="external text" href="http://www.encyclopedia.com/doc/1O87-strongAI.html">Oxford University Press Dictionary of Psychology</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20071203103022/http://www.encyclopedia.com/doc/1O87-strongAI.html">Archived</a> 3 December 2007 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> (quoted in "High Beam Encyclopedia"),</li>
<li><a rel="nofollow" class="external text" href="http://www.aaai.org/AITopics/html/phil.html">MIT Encyclopedia of Cognitive Science</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20080719074502/http://www.aaai.org/AITopics/html/phil.html">Archived</a> 19 July 2008 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> (quoted in "AITopics")</li>
<li><a rel="nofollow" class="external text" href="http://planetmath.org/encyclopedia/StrongAIThesis.html">Planet Math</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20070919012830/http://planetmath.org/encyclopedia/StrongAIThesis.html">Archived</a> 19 September 2007 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></li>
<li><a rel="nofollow" class="external text" href="http://www.cbhd.org/resources/biotech/tongen_2003-11-07.htm">Will Biological Computers Enable Artificially Intelligent Machines to Become Persons?</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20080513031753/http://www.cbhd.org/resources/biotech/tongen_2003-11-07.htm">Archived</a> 13 May 2008 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> Anthony Tongen</li></ul>
</span></li>
<li id="cite_note-FOOTNOTERussellNorvig2003947-70"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTERussellNorvig2003947_70-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;947.</span>
</li>
<li id="cite_note-71"><span class="mw-cite-backlink"><b><a href="#cite_ref-71">^</a></b></span> <span class="reference-text">Note that <a href="/wiki/Consciousness" title="Consciousness">consciousness</a> is difficult to define. A popular definition, due to <a href="/wiki/Thomas_Nagel" title="Thomas Nagel">Thomas Nagel</a>, is that it "feels like" something to be conscious. If we are not conscious, then it doesn't feel like anything. Nagel uses the example of a bat: we can sensibly ask "what does it feel like to be a bat?" However, we are unlikely to ask "what does it feel like to be a toaster?" Nagel concludes that a bat appears to be conscious (i.e. has consciousness) but a toaster does not. See (<a href="#CITEREFNagel1974">Nagel 1974</a>)</span>
</li>
<li id="cite_note-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-72">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/Bill_Joy" title="Bill Joy">Joy, Bill</a> (April 2000). "Why the future doesn't need us". <i>Wired</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=Why+the+future+doesn%27t+need+us&amp;rft.date=2000-04&amp;rft.aulast=Joy&amp;rft.aufirst=Bill&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FOOTNOTEYudkowsky2006-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEYudkowsky2006_73-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFYudkowsky2006">Yudkowsky 2006</a>.</span>
</li>
<li id="cite_note-FOOTNOTEAleksander1996-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEAleksander1996_74-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFAleksander1996">Aleksander 1996</a>.</span>
</li>
<li id="cite_note-FOOTNOTEClocksin2003-75"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEClocksin2003_75-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-FOOTNOTEClocksin2003_75-8"><sup><i><b>i</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFClocksin2003">Clocksin 2003</a>.</span>
</li>
<li id="cite_note-FOOTNOTEMcCarthy2003-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEMcCarthy2003_76-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFMcCarthy2003">McCarthy 2003</a>.</span>
</li>
<li id="cite_note-FOOTNOTEGelernter2010-77"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEGelernter2010_77-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGelernter2010_77-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGelernter2010_77-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTEGelernter2010_77-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFGelernter2010">Gelernter 2010</a>.</span>
</li>
<li id="cite_note-FOOTNOTEMcCarthy2007-78"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEMcCarthy2007_78-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEMcCarthy2007_78-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFMcCarthy2007">McCarthy 2007</a>.</span>
</li>
<li id="cite_note-FOOTNOTEHolteChoueiry2003-79"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEHolteChoueiry2003_79-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHolteChoueiry2003_79-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHolteChoueiry2003_79-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHolteChoueiry2003_79-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFHolteChoueiry2003">Holte &amp; Choueiry 2003</a>.</span>
</li>
<li id="cite_note-FOOTNOTEZucker2003-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEZucker2003_80-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFZucker2003">Zucker 2003</a>.</span>
</li>
<li id="cite_note-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-81">^</a></b></span> <span class="reference-text"><cite class="citation journal">Kaplan, Andreas; Haenlein, Michael (2019). "Kaplan Andreas and Haelein Michael (2019) Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence". <i>Business Horizons</i>. <b>62</b>: 15–25. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.bushor.2018.08.004">10.1016/j.bushor.2018.08.004</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Business+Horizons&amp;rft.atitle=Kaplan+Andreas+and+Haelein+Michael+%282019%29+Siri%2C+Siri%2C+in+my+hand%3A+Who%27s+the+fairest+in+the+land%3F+On+the+interpretations%2C+illustrations%2C+and+implications+of+artificial+intelligence&amp;rft.volume=62&amp;rft.pages=15-25&amp;rft.date=2019&amp;rft_id=info%3Adoi%2F10.1016%2Fj.bushor.2018.08.004&amp;rft.aulast=Kaplan&amp;rft.aufirst=Andreas&amp;rft.au=Haenlein%2C+Michael&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-82">^</a></b></span> <span class="reference-text"><cite class="citation news">Allen, Paul. <a rel="nofollow" class="external text" href="http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/">"The Singularity Isn't Near"</a>. <i><a href="/wiki/MIT_Technology_Review" title="MIT Technology Review">MIT Technology Review</a></i><span class="reference-accessdate">. Retrieved <span class="nowrap">17 September</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=The+Singularity+Isn%27t+Near&amp;rft.aulast=Allen&amp;rft.aufirst=Paul&amp;rft_id=http%3A%2F%2Fwww.technologyreview.com%2Fview%2F425733%2Fpaul-allen-the-singularity-isnt-near%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-83">^</a></b></span> <span class="reference-text"><cite class="citation news">Winfield, Alan. <a rel="nofollow" class="external text" href="https://www.theguardian.com/technology/2014/aug/10/artificial-intelligence-will-not-become-a-frankensteins-monster-ian-winfield">"Artificial intelligence will not turn into a Frankenstein's monster"</a>. <i><a href="/wiki/The_Guardian" title="The Guardian">The Guardian</a></i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140917135230/http://www.theguardian.com/technology/2014/aug/10/artificial-intelligence-will-not-become-a-frankensteins-monster-ian-winfield">Archived</a> from the original on 17 September 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">17 September</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Guardian&amp;rft.atitle=Artificial+intelligence+will+not+turn+into+a+Frankenstein%27s+monster&amp;rft.aulast=Winfield&amp;rft.aufirst=Alan&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2014%2Faug%2F10%2Fartificial-intelligence-will-not-become-a-frankensteins-monster-ian-winfield&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-new_yorker_doomsday-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-new_yorker_doomsday_84-0">^</a></b></span> <span class="reference-text"><cite class="citation news">Raffi Khatchadourian (23 November 2015). <a rel="nofollow" class="external text" href="http://www.newyorker.com/magazine/2015/11/23/doomsday-invention-artificial-intelligence-nick-bostrom">"The Doomsday Invention: Will artificial intelligence bring us utopia or destruction?"</a>. <i><a href="/wiki/The_New_Yorker_(magazine)" class="mw-redirect" title="The New Yorker (magazine)">The New Yorker</a></i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160128105955/http://www.newyorker.com/magazine/2015/11/23/doomsday-invention-artificial-intelligence-nick-bostrom">Archived</a> from the original on 28 January 2016<span class="reference-accessdate">. Retrieved <span class="nowrap">7 February</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+Yorker&amp;rft.atitle=The+Doomsday+Invention%3A+Will+artificial+intelligence+bring+us+utopia+or+destruction%3F&amp;rft.date=2015-11-23&amp;rft.au=Raffi+Khatchadourian&amp;rft_id=http%3A%2F%2Fwww.newyorker.com%2Fmagazine%2F2015%2F11%2F23%2Fdoomsday-invention-artificial-intelligence-nick-bostrom&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-85"><span class="mw-cite-backlink"><b><a href="#cite_ref-85">^</a></b></span> <span class="reference-text">Müller, V. C., &amp; Bostrom, N. (2016). Future progress in artificial intelligence: A survey of expert opinion. In Fundamental issues of artificial intelligence (pp. 555–572). Springer, Cham.</span>
</li>
<li id="cite_note-BBC_News-86"><span class="mw-cite-backlink"><b><a href="#cite_ref-BBC_News_86-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Rawlinson, Kevin. <a rel="nofollow" class="external text" href="https://www.bbc.co.uk/news/31047780">"Microsoft's Bill Gates insists AI is a threat"</a>. <a href="/wiki/BBC_News" title="BBC News">BBC News</a><span class="reference-accessdate">. Retrieved <span class="nowrap">30 January</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Microsoft%27s+Bill+Gates+insists+AI+is+a+threat&amp;rft.pub=BBC+News&amp;rft.aulast=Rawlinson&amp;rft.aufirst=Kevin&amp;rft_id=https%3A%2F%2Fwww.bbc.co.uk%2Fnews%2F31047780&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-hawking_editorial-87"><span class="mw-cite-backlink"><b><a href="#cite_ref-hawking_editorial_87-0">^</a></b></span> <span class="reference-text"><cite class="citation news"><a rel="nofollow" class="external text" href="https://www.independent.co.uk/news/science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence--but-are-we-taking-ai-seriously-enough-9313474.html">"Stephen Hawking: 'Transcendence looks at the implications of artificial intelligence&#160;– but are we taking AI seriously enough?<span class="cs1-kern-right">'</span>"</a>. <a href="/wiki/The_Independent_(UK)" class="mw-redirect" title="The Independent (UK)">The Independent (UK)</a><span class="reference-accessdate">. Retrieved <span class="nowrap">3 December</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Stephen+Hawking%3A+%27Transcendence+looks+at+the+implications+of+artificial+intelligence+%E2%80%93+but+are+we+taking+AI+seriously+enough%3F%27&amp;rft_id=https%3A%2F%2Fwww.independent.co.uk%2Fnews%2Fscience%2Fstephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence--but-are-we-taking-ai-seriously-enough-9313474.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-superintelligence-88"><span class="mw-cite-backlink"><b><a href="#cite_ref-superintelligence_88-0">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Bostrom, Nick</a> (2014). <a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies"><i>Superintelligence: Paths, Dangers, Strategies</i></a> (First ed.). <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0199678112" title="Special:BookSources/978-0199678112"><bdi>978-0199678112</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Superintelligence%3A+Paths%2C+Dangers%2C+Strategies&amp;rft.edition=First&amp;rft.date=2014&amp;rft.isbn=978-0199678112&amp;rft.aulast=Bostrom&amp;rft.aufirst=Nick&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-physica_scripta-89"><span class="mw-cite-backlink"><b><a href="#cite_ref-physica_scripta_89-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Kaj Sotala; <a href="/wiki/Roman_Yampolskiy" title="Roman Yampolskiy">Roman Yampolskiy</a> (19 December 2014). "Responses to catastrophic AGI risk: a survey". <i><a href="/wiki/Physica_Scripta" title="Physica Scripta">Physica Scripta</a></i>. <b>90</b> (1).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Physica+Scripta&amp;rft.atitle=Responses+to+catastrophic+AGI+risk%3A+a+survey&amp;rft.volume=90&amp;rft.issue=1&amp;rft.date=2014-12-19&amp;rft.au=Kaj+Sotala&amp;rft.au=Roman+Yampolskiy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-atlantic-but-what-90"><span class="mw-cite-backlink"><b><a href="#cite_ref-atlantic-but-what_90-0">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.theatlantic.com/health/archive/2014/05/but-what-does-the-end-of-humanity-mean-for-me/361931/">"But What Would the End of Humanity Mean for Me?"</a>. The Atlantic. 9 May 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=But+What+Would+the+End+of+Humanity+Mean+for+Me%3F&amp;rft.pub=The+Atlantic&amp;rft.date=2014-05-09&amp;rft_id=https%3A%2F%2Fwww.theatlantic.com%2Fhealth%2Farchive%2F2014%2F05%2Fbut-what-does-the-end-of-humanity-mean-for-me%2F361931%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-shermer-91"><span class="mw-cite-backlink"><b><a href="#cite_ref-shermer_91-0">^</a></b></span> <span class="reference-text"><cite class="citation news">Shermer, Michael (1 March 2017). <a rel="nofollow" class="external text" href="https://www.scientificamerican.com/article/artificial-intelligence-is-not-a-threat-mdash-yet/">"Apocalypse AI"</a>. <i>Scientific American</i>. p.&#160;77. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2017SciAm.316c..77S">2017SciAm.316c..77S</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fscientificamerican0317-77">10.1038/scientificamerican0317-77</a><span class="reference-accessdate">. Retrieved <span class="nowrap">27 November</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Apocalypse+AI&amp;rft.pages=77&amp;rft.date=2017-03-01&amp;rft_id=info%3Adoi%2F10.1038%2Fscientificamerican0317-77&amp;rft_id=info%3Abibcode%2F2017SciAm.316c..77S&amp;rft.aulast=Shermer&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fartificial-intelligence-is-not-a-threat-mdash-yet%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=24" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r886047268">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class="refbegin reflist columns references-column-count references-column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;">
<ul><li><cite class="citation web">Halal, William E. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130606101835/http://www.techcast.org/Upload/PDFs/633615794236495345_TCTheAutomationofThought.pdf">"TechCast Article Series: The Automation of Thought"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://www.techcast.org/Upload/PDFs/633615794236495345_TCTheAutomationofThought.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 6 June 2013.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=TechCast+Article+Series%3A+The+Automation+of+Thought&amp;rft.aulast=Halal&amp;rft.aufirst=William+E.&amp;rft_id=http%3A%2F%2Fwww.techcast.org%2FUpload%2FPDFs%2F633615794236495345_TCTheAutomationofThought.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFAleksander1996" class="citation"><a href="/wiki/Igor_Aleksander" title="Igor Aleksander">Aleksander, Igor</a> (1996), <span class="cs1-lock-registration" title="Free registration required"><a rel="nofollow" class="external text" href="https://archive.org/details/impossiblemindsm0000alek"><i>Impossible Minds</i></a></span>, World Scientific Publishing Company, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-86094-036-1" title="Special:BookSources/978-1-86094-036-1"><bdi>978-1-86094-036-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Impossible+Minds&amp;rft.pub=World+Scientific+Publishing+Company&amp;rft.date=1996&amp;rft.isbn=978-1-86094-036-1&amp;rft.aulast=Aleksander&amp;rft.aufirst=Igor&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fimpossiblemindsm0000alek&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFOmohundro2008" class="citation"><a href="/wiki/Steve_Omohundro" title="Steve Omohundro">Omohundro, Steve</a> (2008), <i>The Nature of Self-Improving Artificial Intelligence</i>, presented and distributed at the 2007 Singularity Summit, San Francisco, CA.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Nature+of+Self-Improving+Artificial+Intelligence&amp;rft.pub=presented+and+distributed+at+the+2007+Singularity+Summit%2C+San+Francisco%2C+CA.&amp;rft.date=2008&amp;rft.aulast=Omohundro&amp;rft.aufirst=Steve&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSandbergBoström2008" class="citation">Sandberg, Anders; Boström, Nick (2008), <a rel="nofollow" class="external text" href="http://www.fhi.ox.ac.uk/Reports/2008-3.pdf"><i>Whole Brain Emulation: A Roadmap</i></a> <span class="cs1-format">(PDF)</span>, Technical Report #2008‐3, Future of Humanity Institute, Oxford University<span class="reference-accessdate">, retrieved <span class="nowrap">5 April</span> 2009</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Whole+Brain+Emulation%3A+A+Roadmap&amp;rft.series=Technical+Report+%232008%E2%80%903&amp;rft.pub=Future+of+Humanity+Institute%2C+Oxford+University&amp;rft.date=2008&amp;rft.aulast=Sandberg&amp;rft.aufirst=Anders&amp;rft.au=Bostr%C3%B6m%2C+Nick&amp;rft_id=http%3A%2F%2Fwww.fhi.ox.ac.uk%2FReports%2F2008-3.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFAzevedo_et_al.2009" class="citation">Azevedo FA, Carvalho LR, Grinberg LT,  et al. (April 2009), <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/24024444">"Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain"</a>, <i>The Journal of Comparative Neurology</i>, <b>513</b> (5): 532–41, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1002%2Fcne.21974">10.1002/cne.21974</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/19226510">19226510</a><span class="reference-accessdate">, retrieved <span class="nowrap">4 September</span> 2013</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Journal+of+Comparative+Neurology&amp;rft.atitle=Equal+numbers+of+neuronal+and+nonneuronal+cells+make+the+human+brain+an+isometrically+scaled-up+primate+brain&amp;rft.volume=513&amp;rft.issue=5&amp;rft.pages=532-41&amp;rft.date=2009-04&amp;rft_id=info%3Adoi%2F10.1002%2Fcne.21974&amp;rft_id=info%3Apmid%2F19226510&amp;rft.aulast=Azevedo&amp;rft.aufirst=FA&amp;rft.au=Carvalho%2C+LR&amp;rft.au=Grinberg%2C+LT&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F24024444&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFBerglas2008" class="citation">Berglas, Anthony (2008), <a rel="nofollow" class="external text" href="http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html"><i>Artificial Intelligence will Kill our Grandchildren</i></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence+will+Kill+our+Grandchildren&amp;rft.date=2008&amp;rft.aulast=Berglas&amp;rft.aufirst=Anthony&amp;rft_id=http%3A%2F%2Fberglas.org%2FArticles%2FAIKillGrandchildren%2FAIKillGrandchildren.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFChalmers1996" class="citation"><a href="/wiki/David_Chalmers" title="David Chalmers">Chalmers, David</a> (1996), <i>The Conscious Mind</i>, Oxford University Press.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Conscious+Mind&amp;rft.pub=Oxford+University+Press.&amp;rft.date=1996&amp;rft.aulast=Chalmers&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFClocksin2003" class="citation">Clocksin, William (August 2003), "Artificial intelligence and the future", <i><a href="/wiki/Philosophical_Transactions_of_the_Royal_Society_A" title="Philosophical Transactions of the Royal Society A">Philosophical Transactions of the Royal Society A</a></i>, <b>361</b> (1809): 1721–1748, <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2003RSPTA.361.1721C">2003RSPTA.361.1721C</a>, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1098%2Frsta.2003.1232">10.1098/rsta.2003.1232</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/12952683">12952683</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+A&amp;rft.atitle=Artificial+intelligence+and+the+future&amp;rft.volume=361&amp;rft.issue=1809&amp;rft.pages=1721-1748&amp;rft.date=2003-08&amp;rft_id=info%3Apmid%2F12952683&amp;rft_id=info%3Adoi%2F10.1098%2Frsta.2003.1232&amp;rft_id=info%3Abibcode%2F2003RSPTA.361.1721C&amp;rft.aulast=Clocksin&amp;rft.aufirst=William&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFCrevier1993" class="citation"><a href="/wiki/Daniel_Crevier" title="Daniel Crevier">Crevier, Daniel</a> (1993), <i>AI: The Tumultuous Search for Artificial Intelligence</i>, New York, NY: BasicBooks, <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-465-02997-3" title="Special:BookSources/0-465-02997-3">0-465-02997-3</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=AI%3A+The+Tumultuous+Search+for+Artificial+Intelligence&amp;rft.place=New+York%2C+NY&amp;rft.pub=BasicBooks&amp;rft.date=1993&amp;rft.aulast=Crevier&amp;rft.aufirst=Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFDarrach1970" class="citation">Darrach, Brad (20 November 1970), "Meet Shakey, the First Electronic Person", <i><a href="/wiki/Life_Magazine" class="mw-redirect" title="Life Magazine">Life Magazine</a></i>, pp.&#160;58–68</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Life+Magazine&amp;rft.atitle=Meet+Shakey%2C+the+First+Electronic+Person&amp;rft.pages=58-68&amp;rft.date=1970-11-20&amp;rft.aulast=Darrach&amp;rft.aufirst=Brad&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>.</li>
<li><cite id="CITEREFDrachman2005" class="citation">Drachman, D (2005), "Do we have brain to spare?", <i>Neurology</i>, <b>64</b> (12): 2004–5, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1212%2F01.WNL.0000166914.38327.BB">10.1212/01.WNL.0000166914.38327.BB</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/15985565">15985565</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neurology&amp;rft.atitle=Do+we+have+brain+to+spare%3F&amp;rft.volume=64&amp;rft.issue=12&amp;rft.pages=2004-5&amp;rft.date=2005&amp;rft_id=info%3Adoi%2F10.1212%2F01.WNL.0000166914.38327.BB&amp;rft_id=info%3Apmid%2F15985565&amp;rft.aulast=Drachman&amp;rft.aufirst=D&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFFeigenbaumMcCorduck1983" class="citation"><a href="/wiki/Edward_Feigenbaum" title="Edward Feigenbaum">Feigenbaum, Edward A.</a>; <a href="/wiki/Pamela_McCorduck" title="Pamela McCorduck">McCorduck, Pamela</a> (1983), <i>The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World</i>, Michael Joseph, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7181-2401-4" title="Special:BookSources/978-0-7181-2401-4"><bdi>978-0-7181-2401-4</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Fifth+Generation%3A+Artificial+Intelligence+and+Japan%27s+Computer+Challenge+to+the+World&amp;rft.pub=Michael+Joseph&amp;rft.date=1983&amp;rft.isbn=978-0-7181-2401-4&amp;rft.aulast=Feigenbaum&amp;rft.aufirst=Edward+A.&amp;rft.au=McCorduck%2C+Pamela&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFGelernter2010" class="citation">Gelernter, David (2010), <a rel="nofollow" class="external text" href="http://www.edge.org/3rd_culture/gelernter10.1/gelernter10.1_index.html"><i>Dream-logic, the Internet and Artificial Thought</i></a><span class="reference-accessdate">, retrieved <span class="nowrap">25 July</span> 2010</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Dream-logic%2C+the+Internet+and+Artificial+Thought&amp;rft.date=2010&amp;rft.aulast=Gelernter&amp;rft.aufirst=David&amp;rft_id=http%3A%2F%2Fwww.edge.org%2F3rd_culture%2Fgelernter10.1%2Fgelernter10.1_index.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFGoertzelPennachin2006" class="citation">Goertzel, Ben; Pennachin, Cassio, eds. (2006), <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130320184603/http://people.inf.elte.hu/csizsekp/ai/books/artificial-general-intelligence-cognitive-technologies.9783540237334.27156.pdf"><i>Artificial General Intelligence</i></a> <span class="cs1-format">(PDF)</span>, Springer, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-23733-4" title="Special:BookSources/978-3-540-23733-4"><bdi>978-3-540-23733-4</bdi></a>, archived from <a rel="nofollow" class="external text" href="http://people.inf.elte.hu/csizsekp/ai/books/artificial-general-intelligence-cognitive-technologies.9783540237334.27156.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 20 March 2013</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+General+Intelligence&amp;rft.pub=Springer&amp;rft.date=2006&amp;rft.isbn=978-3-540-23733-4&amp;rft_id=http%3A%2F%2Fpeople.inf.elte.hu%2Fcsizsekp%2Fai%2Fbooks%2Fartificial-general-intelligence-cognitive-technologies.9783540237334.27156.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFGoertzelWang2006" class="citation"><a href="/wiki/Ben_Goertzel" title="Ben Goertzel">Goertzel, Ben</a>; Wang, Pei (2006), <a rel="nofollow" class="external text" href="https://sites.google.com/site/narswang/publications/wang-goertzel.AGI_Aspects.pdf?attredirects=1"><i>Introduction: Aspects of Artificial General Intelligence</i></a> <span class="cs1-format">(PDF)</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction%3A+Aspects+of+Artificial+General+Intelligence&amp;rft.date=2006&amp;rft.aulast=Goertzel&amp;rft.aufirst=Ben&amp;rft.au=Wang%2C+Pei&amp;rft_id=http%3A%2F%2Fsites.google.com%2Fsite%2Fnarswang%2Fpublications%2Fwang-goertzel.AGI_Aspects.pdf%3Fattredirects%3D1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFGoertzel2007" class="citation"><a href="/wiki/Ben_Goertzel" title="Ben Goertzel">Goertzel, Ben</a> (December 2007), <a rel="nofollow" class="external text" href="https://scholar.google.com/scholar?hl=sv&amp;lr=&amp;cluster=15189798216526465792">"Human-level artificial general intelligence and the possibility of a technological singularity: a reaction to Ray Kurzweil's The Singularity Is Near, and McDermott's critique of Kurzweil"</a>, <i>Artificial Intelligence</i>, <b>171</b> (18, Special Review Issue): 1161–1173, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.artint.2007.10.011">10.1016/j.artint.2007.10.011</a><span class="reference-accessdate">, retrieved <span class="nowrap">1 April</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence&amp;rft.atitle=Human-level+artificial+general+intelligence+and+the+possibility+of+a+technological+singularity%3A+a+reaction+to+Ray+Kurzweil%27s+The+Singularity+Is+Near%2C+and+McDermott%27s+critique+of+Kurzweil&amp;rft.volume=171&amp;rft.issue=18%2C+Special+Review+Issue&amp;rft.pages=1161-1173&amp;rft.date=2007-12&amp;rft_id=info%3Adoi%2F10.1016%2Fj.artint.2007.10.011&amp;rft.aulast=Goertzel&amp;rft.aufirst=Ben&amp;rft_id=https%3A%2F%2Fscholar.google.com%2Fscholar%3Fhl%3Dsv%26lr%3D%26cluster%3D15189798216526465792&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFGubrud1997" class="citation">Gubrud, Mark (November 1997), <a rel="nofollow" class="external text" href="http://www.foresight.org/Conferences/MNT05/Papers/Gubrud/">"Nanotechnology and International Security"</a>, <i>Fifth Foresight Conference on Molecular Nanotechnology</i><span class="reference-accessdate">, retrieved <span class="nowrap">7 May</span> 2011</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Fifth+Foresight+Conference+on+Molecular+Nanotechnology&amp;rft.atitle=Nanotechnology+and+International+Security&amp;rft.date=1997-11&amp;rft.aulast=Gubrud&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.foresight.org%2FConferences%2FMNT05%2FPapers%2FGubrud%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFHolteChoueiry2003" class="citation">Holte, RC; Choueiry, BY (2003), "Abstraction and reformulation in artificial intelligence", <i><a href="/wiki/Philosophical_Transactions_of_the_Royal_Society_B" title="Philosophical Transactions of the Royal Society B">Philosophical Transactions of the Royal Society B</a></i>, <b>358</b> (1435): 1197–1204, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1098%2Frstb.2003.1317">10.1098/rstb.2003.1317</a>, <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC1693218">1693218</a></span>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/12903653">12903653</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B&amp;rft.atitle=Abstraction+and+reformulation+in+artificial+intelligence&amp;rft.volume=358&amp;rft.issue=1435&amp;rft.pages=1197-1204&amp;rft.date=2003&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1693218&amp;rft_id=info%3Apmid%2F12903653&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2003.1317&amp;rft.aulast=Holte&amp;rft.aufirst=RC&amp;rft.au=Choueiry%2C+BY&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFHowe1994" class="citation">Howe, J. (November 1994), <a rel="nofollow" class="external text" href="http://www.dai.ed.ac.uk/AI_at_Edinburgh_perspective.html"><i>Artificial Intelligence at Edinburgh University&#160;: a Perspective</i></a><span class="reference-accessdate">, retrieved <span class="nowrap">30 August</span> 2007</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence+at+Edinburgh+University+%3A+a+Perspective&amp;rft.date=1994-11&amp;rft.aulast=Howe&amp;rft.aufirst=J.&amp;rft_id=http%3A%2F%2Fwww.dai.ed.ac.uk%2FAI_at_Edinburgh_perspective.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFJohnson1987" class="citation">Johnson, Mark (1987), <i>The body in the mind</i>, Chicago, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-226-40317-5" title="Special:BookSources/978-0-226-40317-5"><bdi>978-0-226-40317-5</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+body+in+the+mind&amp;rft.pub=Chicago&amp;rft.date=1987&amp;rft.isbn=978-0-226-40317-5&amp;rft.aulast=Johnson&amp;rft.aufirst=Mark&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFKurzweil2005" class="citation"><a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Kurzweil, Ray</a> (2005), <a href="/wiki/The_Singularity_is_Near" class="mw-redirect" title="The Singularity is Near"><i>The Singularity is Near</i></a>, Viking Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Singularity+is+Near&amp;rft.pub=Viking+Press&amp;rft.date=2005&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFLighthill1973" class="citation"><a href="/wiki/James_Lighthill" title="James Lighthill">Lighthill, Professor Sir James</a> (1973), "Artificial Intelligence: A General Survey", <i>Artificial Intelligence: a paper symposium</i>, Science Research Council</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Artificial+Intelligence%3A+A+General+Survey&amp;rft.btitle=Artificial+Intelligence%3A+a+paper+symposium&amp;rft.pub=Science+Research+Council&amp;rft.date=1973&amp;rft.aulast=Lighthill&amp;rft.aufirst=Professor+Sir+James&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFLugerStubblefield2004" class="citation">Luger, George; Stubblefield, William (2004), <a rel="nofollow" class="external text" href="https://archive.org/details/artificialintell0000luge/page/720"><i>Artificial Intelligence: Structures and Strategies for Complex Problem Solving</i></a> (5th ed.), The Benjamin/Cummings Publishing Company, Inc., p.&#160;<a rel="nofollow" class="external text" href="https://archive.org/details/artificialintell0000luge/page/720">720</a>, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-8053-4780-7" title="Special:BookSources/978-0-8053-4780-7"><bdi>978-0-8053-4780-7</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+Structures+and+Strategies+for+Complex+Problem+Solving&amp;rft.pages=720&amp;rft.edition=5th&amp;rft.pub=The+Benjamin%2FCummings+Publishing+Company%2C+Inc.&amp;rft.date=2004&amp;rft.isbn=978-0-8053-4780-7&amp;rft.aulast=Luger&amp;rft.aufirst=George&amp;rft.au=Stubblefield%2C+William&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fartificialintell0000luge%2Fpage%2F720&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMcCarthy2007" class="citation"><a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">McCarthy, John</a> (October 2007), "From here to human-level AI", <i>Artificial Intelligence</i>, <b>171</b> (18): 1174–1182, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.artint.2007.10.009">10.1016/j.artint.2007.10.009</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence&amp;rft.atitle=From+here+to+human-level+AI&amp;rft.volume=171&amp;rft.issue=18&amp;rft.pages=1174-1182&amp;rft.date=2007-10&amp;rft_id=info%3Adoi%2F10.1016%2Fj.artint.2007.10.009&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMcCorduck2004" class="citation"><a href="/wiki/Pamela_McCorduck" title="Pamela McCorduck">McCorduck, Pamela</a> (2004), <a rel="nofollow" class="external text" href="http://www.pamelamc.com/html/machines_who_think.html"><i>Machines Who Think</i></a> (2nd ed.), Natick, MA: A. K. Peters, Ltd., <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/1-56881-205-1" title="Special:BookSources/1-56881-205-1"><bdi>1-56881-205-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Machines+Who+Think&amp;rft.place=Natick%2C+MA&amp;rft.edition=2nd&amp;rft.pub=A.+K.+Peters%2C+Ltd.&amp;rft.date=2004&amp;rft.isbn=1-56881-205-1&amp;rft.aulast=McCorduck&amp;rft.aufirst=Pamela&amp;rft_id=http%3A%2F%2Fwww.pamelamc.com%2Fhtml%2Fmachines_who_think.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMoravec1976" class="citation"><a href="/wiki/Hans_Moravec" title="Hans Moravec">Moravec, Hans</a> (1976), <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160303232511/http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html"><i>The Role of Raw Power in Intelligence</i></a>, archived from <a rel="nofollow" class="external text" href="http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html">the original</a> on 3 March 2016<span class="reference-accessdate">, retrieved <span class="nowrap">29 September</span> 2007</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Role+of+Raw+Power+in+Intelligence&amp;rft.date=1976&amp;rft.aulast=Moravec&amp;rft.aufirst=Hans&amp;rft_id=http%3A%2F%2Fwww.frc.ri.cmu.edu%2Fusers%2Fhpm%2Fproject.archive%2Fgeneral.articles%2F1975%2FRaw.Power.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMoravec1988" class="citation"><a href="/wiki/Hans_Moravec" title="Hans Moravec">Moravec, Hans</a> (1988), <i>Mind Children</i>, Harvard University Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind+Children&amp;rft.pub=Harvard+University+Press&amp;rft.date=1988&amp;rft.aulast=Moravec&amp;rft.aufirst=Hans&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNagel1974" class="citation">Nagel (1974), <a rel="nofollow" class="external text" href="http://organizations.utep.edu/Portals/1475/nagel_bat.pdf">"What Is it Like to Be a Bat"</a> <span class="cs1-format">(PDF)</span>, <i>Philosophical Review</i>, <b>83</b> (4): 435–50, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F2183914">10.2307/2183914</a>, <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/2183914">2183914</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Review&amp;rft.atitle=What+Is+it+Like+to+Be+a+Bat&amp;rft.volume=83&amp;rft.issue=4&amp;rft.pages=435-50&amp;rft.date=1974&amp;rft_id=info%3Adoi%2F10.2307%2F2183914&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2183914&amp;rft.au=Nagel&amp;rft_id=http%3A%2F%2Forganizations.utep.edu%2FPortals%2F1475%2Fnagel_bat.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNewellSimon1963" class="citation"><a href="/wiki/Allen_Newell" title="Allen Newell">Newell, Allen</a>; <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Simon, H. A.</a> (1963), "GPS: A Program that Simulates Human Thought",  in Feigenbaum, E.A.; Feldman, J. (eds.), <i>Computers and Thought</i>, New York: McGraw-Hill</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=GPS%3A+A+Program+that+Simulates+Human+Thought&amp;rft.btitle=Computers+and+Thought&amp;rft.place=New+York&amp;rft.pub=McGraw-Hill&amp;rft.date=1963&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Simon%2C+H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNewellSimon1976" class="citation journal"><a href="/wiki/Allen_Newell" title="Allen Newell">Newell, Allen</a>; <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Simon, H. A.</a> (1976). "Computer Science as Empirical Inquiry: Symbols and Search". <i>Communications of the ACM</i>. <b>19</b> (3): 113–126. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F360018.360022">10.1145/360018.360022</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Computer+Science+as+Empirical+Inquiry%3A+Symbols+and+Search&amp;rft.volume=19&amp;rft.issue=3&amp;rft.pages=113-126&amp;rft.date=1976&amp;rft_id=info%3Adoi%2F10.1145%2F360018.360022&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Simon%2C+H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNilsson1998" class="citation"><a href="/wiki/Nils_Nilsson_(researcher)" class="mw-redirect" title="Nils Nilsson (researcher)">Nilsson, Nils</a> (1998), <i>Artificial Intelligence: A New Synthesis</i>, Morgan Kaufmann Publishers, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-55860-467-4" title="Special:BookSources/978-1-55860-467-4"><bdi>978-1-55860-467-4</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+New+Synthesis&amp;rft.pub=Morgan+Kaufmann+Publishers&amp;rft.date=1998&amp;rft.isbn=978-1-55860-467-4&amp;rft.aulast=Nilsson&amp;rft.aufirst=Nils&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFRussellNorvig2003" class="citation"><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell, Stuart J.</a>; <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig, Peter</a> (2003), <a rel="nofollow" class="external text" href="http://aima.cs.berkeley.edu/"><i>Artificial Intelligence: A Modern Approach</i></a> (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-13-790395-2" title="Special:BookSources/0-13-790395-2"><bdi>0-13-790395-2</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.place=Upper+Saddle+River%2C+New+Jersey&amp;rft.edition=2nd&amp;rft.pub=Prentice+Hall&amp;rft.date=2003&amp;rft.isbn=0-13-790395-2&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart+J.&amp;rft.au=Norvig%2C+Peter&amp;rft_id=http%3A%2F%2Faima.cs.berkeley.edu%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNRC1999" class="citation"><a href="/wiki/United_States_National_Research_Council" class="mw-redirect" title="United States National Research Council">NRC</a> (1999), <a rel="nofollow" class="external text" href="http://www.nap.edu/readingroom/books/far/ch9.html">"Developments in Artificial Intelligence"</a>, <i>Funding a Revolution: Government Support for Computing Research</i>, National Academy Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Developments+in+Artificial+Intelligence&amp;rft.btitle=Funding+a+Revolution%3A+Government+Support+for+Computing+Research&amp;rft.pub=National+Academy+Press&amp;rft.date=1999&amp;rft.au=NRC&amp;rft_id=http%3A%2F%2Fwww.nap.edu%2Freadingroom%2Fbooks%2Ffar%2Fch9.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFPooleMackworthGoebel1998" class="citation"><a href="/w/index.php?title=David_Poole_(researcher)&amp;action=edit&amp;redlink=1" class="new" title="David Poole (researcher) (page does not exist)">Poole, David</a>; Mackworth, Alan; Goebel, Randy (1998), <a rel="nofollow" class="external text" href="http://www.cs.ubc.ca/spider/poole/ci.html"><i>Computational Intelligence: A Logical Approach</i></a>, New York: Oxford University Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computational+Intelligence%3A+A+Logical+Approach&amp;rft.place=New+York&amp;rft.pub=Oxford+University+Press&amp;rft.date=1998&amp;rft.aulast=Poole&amp;rft.aufirst=David&amp;rft.au=Mackworth%2C+Alan&amp;rft.au=Goebel%2C+Randy&amp;rft_id=http%3A%2F%2Fwww.cs.ubc.ca%2Fspider%2Fpoole%2Fci.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle1980" class="citation"><a href="/wiki/John_Searle" title="John Searle">Searle, John</a> (1980), "Minds, Brains and Programs", <i>Behavioral and Brain Sciences</i>, <b>3</b> (3): 417–457, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1017%2FS0140525X00005756">10.1017/S0140525X00005756</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.atitle=Minds%2C+Brains+and+Programs&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=417-457&amp;rft.date=1980&amp;rft_id=info%3Adoi%2F10.1017%2FS0140525X00005756&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSimon1965" class="citation"><a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Simon, H. A.</a> (1965), <i>The Shape of Automation for Men and Management</i>, New York: Harper &amp; Row</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Shape+of+Automation+for+Men+and+Management&amp;rft.place=New+York&amp;rft.pub=Harper+%26+Row&amp;rft.date=1965&amp;rft.aulast=Simon&amp;rft.aufirst=H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSutherland1990" class="citation">Sutherland, J.G. (1990), "Holographic Model of Memory, Learning, and Expression", <i>International Journal of Neural Systems</i>, <b>1–3</b>: 256–267.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Neural+Systems&amp;rft.atitle=Holographic+Model+of+Memory%2C+Learning%2C+and+Expression&amp;rft.volume=1%E2%80%933&amp;rft.pages=256-267&amp;rft.date=1990&amp;rft.aulast=Sutherland&amp;rft.aufirst=J.G.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFWilliamsHerrup1988" class="citation">Williams RW, Herrup K (1988), "The control of neuron number", <i>Annual Review of Neuroscience</i>, <b>11</b>: 423–53, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1146%2Fannurev.ne.11.030188.002231">10.1146/annurev.ne.11.030188.002231</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/3284447">3284447</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annual+Review+of+Neuroscience&amp;rft.atitle=The+control+of+neuron+number&amp;rft.volume=11&amp;rft.pages=423-53&amp;rft.date=1988&amp;rft_id=info%3Adoi%2F10.1146%2Fannurev.ne.11.030188.002231&amp;rft_id=info%3Apmid%2F3284447&amp;rft.aulast=Williams&amp;rft.aufirst=RW&amp;rft.au=Herrup%2C+K&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFde_VegaGlenbergGraesser2008" class="citation">de Vega, Manuel; Glenberg, Arthur; Graesser, Arthur, eds. (2008), <i>Symbols and Embodiment: Debates on meaning and cognition</i>, Oxford University Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-19-921727-4" title="Special:BookSources/978-0-19-921727-4"><bdi>978-0-19-921727-4</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Symbols+and+Embodiment%3A+Debates+on+meaning+and+cognition&amp;rft.pub=Oxford+University+Press&amp;rft.date=2008&amp;rft.isbn=978-0-19-921727-4&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFYudkowsky2006" class="citation"><a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Yudkowsky, Eliezer</a> (2006),  Goertzel, Ben; Pennachin, Cassio (eds.), <a rel="nofollow" class="external text" href="https://web.archive.org/web/20090411050423/http://www.singinst.org/upload/LOGI/LOGI.pdf">"Artificial General Intelligence"</a> <span class="cs1-format">(PDF)</span>, <i>Annual Review of Psychology</i>, Springer, <b>49</b>: 585–612, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1146%2Fannurev.psych.49.1.585">10.1146/annurev.psych.49.1.585</a>, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-23733-4" title="Special:BookSources/978-3-540-23733-4"><bdi>978-3-540-23733-4</bdi></a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/9496632">9496632</a>, archived from <a rel="nofollow" class="external text" href="http://www.singinst.org/upload/LOGI//LOGI.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 11 April 2009</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annual+Review+of+Psychology&amp;rft.atitle=Artificial+General+Intelligence&amp;rft.volume=49&amp;rft.pages=585-612&amp;rft.date=2006&amp;rft_id=info%3Apmid%2F9496632&amp;rft_id=info%3Adoi%2F10.1146%2Fannurev.psych.49.1.585&amp;rft.isbn=978-3-540-23733-4&amp;rft.aulast=Yudkowsky&amp;rft.aufirst=Eliezer&amp;rft_id=http%3A%2F%2Fwww.singinst.org%2Fupload%2FLOGI%2F%2FLOGI.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFZucker2003" class="citation">Zucker, Jean-Daniel (July 2003), "A grounded theory of abstraction in artificial intelligence", <i><a href="/wiki/Philosophical_Transactions_of_the_Royal_Society_B" title="Philosophical Transactions of the Royal Society B">Philosophical Transactions of the Royal Society B</a></i>, <b>358</b> (1435): 1293–1309, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1098%2Frstb.2003.1308">10.1098/rstb.2003.1308</a>, <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC1693211">1693211</a></span>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/12903672">12903672</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B&amp;rft.atitle=A+grounded+theory+of+abstraction+in+artificial+intelligence&amp;rft.volume=358&amp;rft.issue=1435&amp;rft.pages=1293-1309&amp;rft.date=2003-07&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1693211&amp;rft_id=info%3Apmid%2F12903672&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2003.1308&amp;rft.aulast=Zucker&amp;rft.aufirst=Jean-Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFYudkowsky2008" class="citation"><a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Yudkowsky, Eliezer</a> (2008), "Artificial Intelligence as a Positive and Negative Factor in Global Risk", <i>Global Catastrophic Risks</i>, <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2008gcr..book..303Y">2008gcr..book..303Y</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Global+Catastrophic+Risks&amp;rft.atitle=Artificial+Intelligence+as+a+Positive+and+Negative+Factor+in+Global+Risk&amp;rft.date=2008&amp;rft_id=info%3Abibcode%2F2008gcr..book..303Y&amp;rft.aulast=Yudkowsky&amp;rft.aufirst=Eliezer&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>.</li></ul>
</div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=25" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="https://cis.temple.edu/~pwang/AGI-Intro.html">The AGI portal maintained by Pei Wang</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20050405071221/http://genesis.csail.mit.edu/index.html">The Genesis Group at MIT's CSAIL</a> – Modern research on the computations that underlay human intelligence</li>
<li><a rel="nofollow" class="external text" href="http://www.opencog.org/">OpenCog – open source project to develop a human-level AI</a></li>
<li><a rel="nofollow" class="external text" href="http://academia.wikia.com/wiki/A_Method_for_Simulating_the_Process_of_Logical_Human_Thought">Simulating logical human thought</a></li>
<li><a rel="nofollow" class="external text" href="http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/ai-timelines">What Do We Know about AI Timelines?</a> – Literature review</li></ul>
<div role="navigation" class="navbox" aria-labelledby="Existential_risk_from_artificial_intelligence" style="padding:3px"><table class="nowraplinks mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Existential_risk_from_artificial_intelligence" title="Template:Existential risk from artificial intelligence"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Existential_risk_from_artificial_intelligence" title="Template talk:Existential risk from artificial intelligence"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Existential_risk_from_artificial_intelligence&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Existential_risk_from_artificial_intelligence" style="font-size:114%;margin:0 4em"><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk</a> from <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%">Concepts</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Accelerating_change" title="Accelerating change">Accelerating change</a></li>
<li><a href="/wiki/AI_box" title="AI box">AI box</a></li>
<li><a href="/wiki/AI_takeover" title="AI takeover">AI takeover</a></li>
<li><a href="/wiki/AI_control_problem" title="AI control problem">Control problem</a></li>
<li><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk from artificial general intelligence</a></li>
<li><a href="/wiki/Friendly_artificial_intelligence" title="Friendly artificial intelligence">Friendly artificial intelligence</a></li>
<li><a href="/wiki/Instrumental_convergence" title="Instrumental convergence">Instrumental convergence</a></li>
<li><a href="/wiki/Intelligence_explosion" class="mw-redirect" title="Intelligence explosion">Intelligence explosion</a></li>
<li><a href="/wiki/Machine_ethics" title="Machine ethics">Machine ethics</a></li>
<li><a href="/wiki/Superintelligence" title="Superintelligence">Superintelligence</a></li>
<li><a href="/wiki/Technological_singularity" title="Technological singularity">Technological singularity</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Organizations</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Allen_Institute_for_Artificial_Intelligence" class="mw-redirect" title="Allen Institute for Artificial Intelligence">Allen Institute for Artificial Intelligence</a></li>
<li><a href="/wiki/Center_for_Applied_Rationality" title="Center for Applied Rationality">Center for Applied Rationality</a></li>
<li><a href="/wiki/Center_for_Human-Compatible_Artificial_Intelligence" title="Center for Human-Compatible Artificial Intelligence">Center for Human-Compatible Artificial Intelligence</a></li>
<li><a href="/wiki/Center_for_Security_and_Emerging_Technology" title="Center for Security and Emerging Technology">Center for Security and Emerging Technology</a></li>
<li><a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a></li>
<li><a href="/wiki/DeepMind" title="DeepMind">DeepMind</a></li>
<li><a href="/wiki/Foundational_Questions_Institute" title="Foundational Questions Institute">Foundational Questions Institute</a></li>
<li><a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a></li>
<li><a href="/wiki/Future_of_Life_Institute" title="Future of Life Institute">Future of Life Institute</a></li>
<li><a href="/wiki/Humanity%2B" title="Humanity+">Humanity+</a></li>
<li><a href="/wiki/Institute_for_Ethics_and_Emerging_Technologies" title="Institute for Ethics and Emerging Technologies">Institute for Ethics and Emerging Technologies</a></li>
<li><a href="/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence" title="Leverhulme Centre for the Future of Intelligence">Leverhulme Centre for the Future of Intelligence</a></li>
<li><a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a></li>
<li><a href="/wiki/OpenAI" title="OpenAI">OpenAI</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">People</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a></li>
<li><a href="/wiki/K._Eric_Drexler" title="K. Eric Drexler">Eric Drexler</a></li>
<li><a href="/wiki/Sam_Harris" title="Sam Harris">Sam Harris</a></li>
<li><a href="/wiki/Stephen_Hawking" title="Stephen Hawking">Stephen Hawking</a></li>
<li><a href="/wiki/Bill_Hibbard" title="Bill Hibbard">Bill Hibbard</a></li>
<li><a href="/wiki/Bill_Joy" title="Bill Joy">Bill Joy</a></li>
<li><a href="/wiki/Elon_Musk" title="Elon Musk">Elon Musk</a></li>
<li><a href="/wiki/Steve_Omohundro" title="Steve Omohundro">Steve Omohundro</a></li>
<li><a href="/wiki/Huw_Price" title="Huw Price">Huw Price</a></li>
<li><a href="/wiki/Martin_Rees" title="Martin Rees">Martin Rees</a></li>
<li><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart J. Russell</a></li>
<li><a href="/wiki/Jaan_Tallinn" title="Jaan Tallinn">Jaan Tallinn</a></li>
<li><a href="/wiki/Max_Tegmark" title="Max Tegmark">Max Tegmark</a></li>
<li><a href="/wiki/Frank_Wilczek" title="Frank Wilczek">Frank Wilczek</a></li>
<li><a href="/wiki/Roman_Yampolskiy" title="Roman Yampolskiy">Roman Yampolskiy</a></li>
<li><a href="/wiki/Andrew_Yang" title="Andrew Yang">Andrew Yang</a></li>
<li><a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Other</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Global_catastrophic_risk#Artificial_intelligence" title="Global catastrophic risk">Artificial intelligence as a global catastrophic risk</a></li>
<li><a href="/wiki/Artificial_general_intelligence#Controversies_and_dangers" title="Artificial general intelligence">Controversies and dangers of artificial general intelligence</a></li>
<li><a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">Ethics of artificial intelligence</a></li>
<li><i><a href="/wiki/Human_Compatible" title="Human Compatible">Human Compatible</a></i></li>
<li><a href="/wiki/Open_Letter_on_Artificial_Intelligence" title="Open Letter on Artificial Intelligence">Open Letter on Artificial Intelligence</a></li>
<li><i><a href="/wiki/Our_Final_Invention" title="Our Final Invention">Our Final Invention</a></i></li>
<li><i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<dl><dt><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" decoding="async" title="Category" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31" /> <a href="/wiki/Category:Existential_risk_from_artificial_general_intelligence" title="Category:Existential risk from artificial general intelligence">Category</a></dt></dl>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1337
Cached time: 20200219213028
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 1.240 seconds
Real time usage: 1.454 seconds
Preprocessor visited node count: 6724/1000000
Post‐expand include size: 204093/2097152 bytes
Template argument size: 6070/2097152 bytes
Highest expansion depth: 17/40
Expensive parser function count: 15/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 257357/5000000 bytes
Number of Wikibase entities loaded: 6/400
Lua time usage: 0.702/10.000 seconds
Lua memory usage: 8.43 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1298.179      1 -total
 41.92%  544.230      1 Template:Reflist
 22.46%  291.626     42 Template:Citation
 11.17%  145.020     12 Template:Cite_journal
  6.71%   87.097     19 Template:Cite_web
  6.41%   83.228      4 Template:Citation_needed
  6.34%   82.321      6 Template:Fix
  6.07%   78.773      1 Template:Short_description
  5.70%   73.963     38 Template:Sfn
  4.60%   59.757      1 Template:Pagetype
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:586357-0!canonical and timestamp 20200219213029 and revision id 941648935
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;oldid=941648935">https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;oldid=941648935</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Hypothetical_technology" title="Category:Hypothetical technology">Hypothetical technology</a></li><li><a href="/wiki/Category:Artificial_intelligence" title="Category:Artificial intelligence">Artificial intelligence</a></li><li><a href="/wiki/Category:Computational_neuroscience" title="Category:Computational neuroscience">Computational neuroscience</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:Webarchive_template_wayback_links" title="Category:Webarchive template wayback links">Webarchive template wayback links</a></li><li><a href="/wiki/Category:All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="/wiki/Category:Articles_with_dead_external_links_from_October_2019" title="Category:Articles with dead external links from October 2019">Articles with dead external links from October 2019</a></li><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">CS1 maint: archived copy as title</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Use_British_English_from_March_2019" title="Category:Use British English from March 2019">Use British English from March 2019</a></li><li><a href="/wiki/Category:Use_dmy_dates_from_December_2019" title="Category:Use dmy dates from December 2019">Use dmy dates from December 2019</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_June_2011" title="Category:Articles with unsourced statements from June 2011">Articles with unsourced statements from June 2011</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_January_2017" title="Category:Articles with unsourced statements from January 2017">Articles with unsourced statements from January 2017</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_December_2017" title="Category:Articles with unsourced statements from December 2017">Articles with unsourced statements from December 2017</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_April_2011" title="Category:Articles with unsourced statements from April 2011">Articles with unsourced statements from April 2011</a></li><li><a href="/wiki/Category:All_articles_needing_examples" title="Category:All articles needing examples">All articles needing examples</a></li><li><a href="/wiki/Category:Articles_needing_examples_from_September_2017" title="Category:Articles needing examples from September 2017">Articles needing examples from September 2017</a></li><li><a href="/wiki/Category:Articles_to_be_expanded_from_February_2016" title="Category:Articles to be expanded from February 2016">Articles to be expanded from February 2016</a></li><li><a href="/wiki/Category:All_articles_to_be_expanded" title="Category:All articles to be expanded">All articles to be expanded</a></li><li><a href="/wiki/Category:Articles_using_small_message_boxes" title="Category:Articles using small message boxes">Articles using small message boxes</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
    <h2>Navigation menu</h2>
    <div id="mw-head">
        
<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
	<h3 id="p-personal-label">Personal tools</h3>
	<ul >
		
		<li id="pt-anonuserpage">Not logged in</li>
		<li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Artificial+general+intelligence" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Artificial+general+intelligence" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>
	</ul>
</div>

        <div id="left-navigation">
            <div id="p-namespaces" role="navigation" class="vectorTabs " aria-labelledby="p-namespaces-label">
	<h3 id="p-namespaces-label">Namespaces</h3>
	<ul >
		<li id="ca-nstab-main" class="selected"><a href="/wiki/Artificial_general_intelligence" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Artificial_general_intelligence" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>
	</ul>
</div>
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
	<h3 id="p-variants-label">
		<span>Variants</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>

        </div>
        <div id="right-navigation">
            <div id="p-views" role="navigation" class="vectorTabs " aria-labelledby="p-views-label">
	<h3 id="p-views-label">Views</h3>
	<ul >
		<li id="ca-view" class="collapsible selected"><a href="/wiki/Artificial_general_intelligence">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>
	</ul>
</div>
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
	<h3 id="p-cactions-label">
		<span>More</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>
<div id="p-search" role="search">
	<h3 >
		<label for="searchInput">Search</label>
	</h3>
	<form action="/w/index.php" id="searchform">
		<div id="simpleSearch">
			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
			<input type="hidden" value="Special:Search" name="title"/>
			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
		</div>
	</form>
</div>

        </div>
    </div>
    <div id="mw-panel">
        <div id="p-logo" role="banner">
            <a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
        </div>
        
<div class="portal" role="navigation" id="p-navigation"  aria-labelledby="p-navigation-label">
	<h3  id="p-navigation-label">
		Navigation
	</h3>
	<div class="body">
		<ul><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-interaction"  aria-labelledby="p-interaction-label">
	<h3  id="p-interaction-label">
		Interaction
	</h3>
	<div class="body">
		<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-tb"  aria-labelledby="p-tb-label">
	<h3  id="p-tb-label">
		Tools
	</h3>
	<div class="body">
		<ul><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Artificial_general_intelligence" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Artificial_general_intelligence" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Artificial_general_intelligence&amp;oldid=941648935" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Artificial_general_intelligence&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q2264109" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Artificial_general_intelligence&amp;id=941648935" title="Information on how to cite this page">Cite this page</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-coll-print_export"  aria-labelledby="p-coll-print_export-label">
	<h3  id="p-coll-print_export-label">
		Print/export
	</h3>
	<div class="body">
		<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Artificial+general+intelligence">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Artificial+general+intelligence&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Artificial_general_intelligence&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-lang"  aria-labelledby="p-lang-label">
	<h3  id="p-lang-label">
		Languages
	</h3>
	<div class="body">
		<ul><li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1_%D8%A7%D9%84%D8%B9%D8%A7%D9%85_%D8%A7%D9%84%D8%A5%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A" title="الذكاء العام الإصطناعي – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Intel%C2%B7lig%C3%A8ncia_artificial_forta" title="Intel·ligència artificial forta – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A9_byt%C3%AD" title="Umělé bytí – Czech" lang="cs" hreflang="cs" class="interlanguage-link-target">Čeština</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Inteligencia_artificial_fuerte" title="Inteligencia artificial fuerte – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-eu"><a href="https://eu.wikipedia.org/wiki/Adimen_artifizial_orokorra" title="Adimen artifizial orokorra – Basque" lang="eu" hreflang="eu" class="interlanguage-link-target">Euskara</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D9%87%D9%88%D8%B4_%D8%AC%D8%A7%D9%85%D8%B9_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C" title="هوش جامع مصنوعی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Intelligence_artificielle#Intelligence_artificielle_forte" title="Intelligence artificielle – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EC%9D%BC%EB%B0%98_%EC%A7%80%EB%8A%A5" title="인공 일반 지능 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-hy"><a href="https://hy.wikipedia.org/wiki/%D4%B8%D5%B6%D5%A4%D5%B0%D5%A1%D5%B6%D5%B8%D6%82%D6%80_%D5%A1%D6%80%D5%B0%D5%A5%D5%BD%D5%BF%D5%A1%D5%AF%D5%A1%D5%B6_%D5%A2%D5%A1%D5%B6%D5%A1%D5%AF%D5%A1%D5%B6%D5%B8%D6%82%D5%A9%D5%B5%D5%B8%D6%82%D5%B6" title="Ընդհանուր արհեստական բանականություն – Armenian" lang="hy" hreflang="hy" class="interlanguage-link-target">Հայերեն</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Kecerdasan_umum_buatan" title="Kecerdasan umum buatan – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Intelligenza_artificiale_forte" title="Intelligenza artificiale forte – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%91%D7%99%D7%A0%D7%94_%D7%9E%D7%9C%D7%90%D7%9B%D7%95%D7%AA%D7%99%D7%AA_%D7%97%D7%96%D7%A7%D7%94" title="בינה מלאכותית חזקה – Hebrew" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E5%BC%B7%E3%81%84AI%E3%81%A8%E5%BC%B1%E3%81%84AI" title="強いAIと弱いAI – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Silna_sztuczna_inteligencja" title="Silna sztuczna inteligencja – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%B8_%D1%81%D0%BB%D0%B0%D0%B1%D1%8B%D0%B9_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%8B" title="Сильный и слабый искусственные интеллекты – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-sv"><a href="https://sv.wikipedia.org/wiki/Artificiell_generell_intelligens" title="Artificiell generell intelligens – Swedish" lang="sv" hreflang="sv" class="interlanguage-link-target">Svenska</a></li><li class="interlanguage-link interwiki-th"><a href="https://th.wikipedia.org/wiki/%E0%B8%9B%E0%B8%B1%E0%B8%8D%E0%B8%8D%E0%B8%B2%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%94%E0%B8%B4%E0%B8%A9%E0%B8%90%E0%B9%8C%E0%B8%97%E0%B8%B1%E0%B9%88%E0%B8%A7%E0%B9%84%E0%B8%9B" title="ปัญญาประดิษฐ์ทั่วไป – Thai" lang="th" hreflang="th" class="interlanguage-link-target">ไทย</a></li><li class="interlanguage-link interwiki-tr"><a href="https://tr.wikipedia.org/wiki/Yapay_genel_zek%C3%A2" title="Yapay genel zekâ – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target">Türkçe</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D1%88%D1%82%D1%83%D1%87%D0%BD%D0%B8%D0%B9_%D1%96%D0%BD%D1%82%D0%B5%D0%BB%D0%B5%D0%BA%D1%82" title="Сильний штучний інтелект – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh-yue"><a href="https://zh-yue.wikipedia.org/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" title="強人工智能 – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target">粵語</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" title="通用人工智慧 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>
		<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q2264109#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
	</div>
</div>

    </div>
</div>


<div id="footer" role="contentinfo" >
	<ul id="footer-info" class="">
		<li id="footer-info-lastmod"> This page was last edited on 19 February 2020, at 21:30<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" class="">
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</div>


<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"1.240","walltime":"1.454","ppvisitednodes":{"value":6724,"limit":1000000},"postexpandincludesize":{"value":204093,"limit":2097152},"templateargumentsize":{"value":6070,"limit":2097152},"expansiondepth":{"value":17,"limit":40},"expensivefunctioncount":{"value":15,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":257357,"limit":5000000},"entityaccesscount":{"value":6,"limit":400},"timingprofile":["100.00% 1298.179      1 -total"," 41.92%  544.230      1 Template:Reflist"," 22.46%  291.626     42 Template:Citation"," 11.17%  145.020     12 Template:Cite_journal","  6.71%   87.097     19 Template:Cite_web","  6.41%   83.228      4 Template:Citation_needed","  6.34%   82.321      6 Template:Fix","  6.07%   78.773      1 Template:Short_description","  5.70%   73.963     38 Template:Sfn","  4.60%   59.757      1 Template:Pagetype"]},"scribunto":{"limitreport-timeusage":{"value":"0.702","limit":"10.000"},"limitreport-memusage":{"value":8844692,"limit":52428800}},"cachereport":{"origin":"mw1337","timestamp":"20200219213028","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Artificial general intelligence","url":"https:\/\/en.wikipedia.org\/wiki\/Artificial_general_intelligence","sameAs":"http:\/\/www.wikidata.org\/entity\/Q2264109","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q2264109","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2004-04-09T21:10:09Z","dateModified":"2020-02-19T21:30:22Z","headline":"theoretical class of AI able to perform any intelligence-based task a human can"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":133,"wgHostname":"mw1273"});});</script></body></html>
