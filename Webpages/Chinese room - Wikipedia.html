<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Chinese room - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRequestId":"Xk3UvQpAMMIAAP80OOgAAAEO","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Chinese_room","wgTitle":"Chinese room","wgCurRevisionId":937552112,"wgRevisionId":937552112,"wgArticleId":6216,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Wikipedia articles needing page number citations from February 2012","Wikipedia articles needing page number citations from February 2011","All articles with specifically marked weasel-worded phrases",
"Articles with specifically marked weasel-worded phrases from March 2011","Wikipedia articles needing page number citations from January 2019","Pages using quote template with unknown parameters","All articles with unsourced statements","Articles with unsourced statements from October 2018","Articles with Internet Encyclopedia of Philosophy links","Wikipedia articles with GND identifiers","Philosophy of technology","Philosophy of artificial intelligence","Philosophical arguments","Thought experiments in philosophy of mind"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Chinese_room","wgRelevantArticleId":6216,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"Strong_AI_hypothesis","wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en",
"pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgInternalRedirectTargetUrl":"/wiki/Chinese_room#Strong_AI","wgWikibaseItemId":"Q304726","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","jquery.makeCollapsible.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=[
"mediawiki.action.view.redirect","ext.cite.ux-enhancements","ext.scribunto.logs","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.19"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Chinese_room#Strong_AI"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Chinese_room&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Chinese_room&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Chinese_room#Strong_AI"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Chinese_room rootpage-Chinese_room skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Chinese room</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"><span class="mw-redirectedfrom">&#160;&#160;(Redirected from <a href="/w/index.php?title=Strong_AI_hypothesis&amp;redirect=no" class="mw-redirect" title="Strong AI hypothesis">Strong AI hypothesis</a>)</span></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">For the British video game development studio, see <a href="/wiki/The_Chinese_Room" title="The Chinese Room">The Chinese Room</a>.</div>
<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%;width: 16em;"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Outline_of_artificial_intelligence" title="Outline of artificial intelligence">Artificial intelligence</a></th></tr><tr><th style="padding:0.1em">
<a href="/wiki/Artificial_intelligence#Goals" title="Artificial intelligence">Major goals</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Knowledge_representation_and_reasoning" title="Knowledge representation and reasoning">Knowledge reasoning</a></li>
<li><a href="/wiki/Automated_planning_and_scheduling" title="Automated planning and scheduling">Planning</a></li>
<li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li>
<li><a href="/wiki/Natural_language_processing" title="Natural language processing">Natural language processing</a></li>
<li><a href="/wiki/Computer_vision" title="Computer vision">Computer vision</a></li>
<li><a href="/wiki/Robotics" title="Robotics">Robotics</a></li>
<li><a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">Artificial general intelligence</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Approaches</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Symbolic_artificial_intelligence" title="Symbolic artificial intelligence">Symbolic</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayesian networks</a></li>
<li><a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">Evolutionary algorithms</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
<a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">Ethics</a></li>
<li><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk</a></li>
<li><a href="/wiki/Turing_test" title="Turing test">Turing test</a></li>
<li><a class="mw-selflink selflink">Chinese room</a></li>
<li><a href="/wiki/AI_control_problem" title="AI control problem">Control problem</a></li>
<li><a href="/wiki/Friendly_artificial_intelligence" title="Friendly artificial intelligence">Friendly AI</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
<a href="/wiki/History_of_artificial_intelligence" title="History of artificial intelligence">History</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Timeline_of_artificial_intelligence" title="Timeline of artificial intelligence">Timeline</a></li>
<li><a href="/wiki/Progress_in_artificial_intelligence" title="Progress in artificial intelligence">Progress</a></li>
<li><a href="/wiki/AI_winter" title="AI winter">AI winter</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Technology</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Applications_of_artificial_intelligence" title="Applications of artificial intelligence">Applications</a></li>
<li><a href="/wiki/List_of_artificial_intelligence_projects" title="List of artificial intelligence projects">Projects</a></li>
<li><a href="/wiki/List_of_programming_languages_for_artificial_intelligence" title="List of programming languages for artificial intelligence">Programming languages</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Glossary</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary</a></li></ul></td>
</tr><tr><td style="text-align:right;font-size:115%"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Artificial_intelligence" title="Template:Artificial intelligence"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Artificial_intelligence" title="Template talk:Artificial intelligence"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Artificial_intelligence&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>The <b>Chinese room argument</b> holds that a digital computer executing a program cannot be shown to have a "<a href="/wiki/Mind" title="Mind">mind</a>", "<a href="/wiki/Intentionality" title="Intentionality">understanding</a>" or "<a href="/wiki/Consciousness" title="Consciousness">consciousness</a>",<sup id="cite_ref-Consciousness_1-0" class="reference"><a href="#cite_note-Consciousness-1">&#91;a&#93;</a></sup> regardless of how intelligently or human-like the program may make the computer behave.  The argument was first presented by philosopher <a href="/wiki/John_Searle" title="John Searle">John Searle</a> in his paper, "Minds, Brains, and Programs", published in <i><a href="/wiki/Behavioral_and_Brain_Sciences" title="Behavioral and Brain Sciences">Behavioral and Brain Sciences</a></i> in 1980. It has been widely discussed in the years since.<sup id="cite_ref-FOOTNOTEHarnad20011_2-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad20011-2">&#91;1&#93;</a></sup> The centerpiece of the argument is a <a href="/wiki/Thought_experiment" title="Thought experiment">thought experiment</a> known as the <i>Chinese room</i>.<sup id="cite_ref-Roberts_3-0" class="reference"><a href="#cite_note-Roberts-3">&#91;2&#93;</a></sup>
</p><p>The argument is directed against the <a href="/wiki/Philosophical_position" class="mw-redirect" title="Philosophical position">philosophical positions</a> of <a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">functionalism</a> and <a href="/wiki/Computationalism" class="mw-redirect" title="Computationalism">computationalism</a>,<sup id="cite_ref-FOOTNOTESearle199244_4-0" class="reference"><a href="#cite_note-FOOTNOTESearle199244-4">&#91;3&#93;</a></sup> which hold that the mind may be viewed as an information-processing system operating on formal symbols. Specifically, the argument is intended to refute a position Searle calls <b>strong AI</b>: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."<sup id="cite_ref-Strong_AI_5-0" class="reference"><a href="#cite_note-Strong_AI-5">&#91;b&#93;</a></sup>
</p><p>Although it was originally presented in reaction to the statements of <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> (AI) researchers, it is not an argument against the goals of AI research, because it does not limit the amount of intelligence a machine can display.<sup id="cite_ref-FOOTNOTERussellNorvig2003947_6-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003947-6">&#91;4&#93;</a></sup> The argument applies only to digital computers running programs and does not apply to machines in general.<sup id="cite_ref-FOOTNOTESearle198011_7-0" class="reference"><a href="#cite_note-FOOTNOTESearle198011-7">&#91;5&#93;</a></sup>
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Chinese_room_thought_experiment"><span class="tocnumber">1</span> <span class="toctext">Chinese room thought experiment</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#History"><span class="tocnumber">2</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Philosophy"><span class="tocnumber">3</span> <span class="toctext">Philosophy</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="#Strong_AI"><span class="tocnumber">3.1</span> <span class="toctext">Strong AI</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Strong_AI_as_computationalism_or_functionalism"><span class="tocnumber">3.2</span> <span class="toctext">Strong AI as computationalism or functionalism</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Strong_AI_vs._biological_naturalism"><span class="tocnumber">3.3</span> <span class="toctext">Strong AI vs. biological naturalism</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Consciousness"><span class="tocnumber">3.4</span> <span class="toctext">Consciousness</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Applied_ethics"><span class="tocnumber">3.5</span> <span class="toctext">Applied ethics</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="#Computer_science"><span class="tocnumber">4</span> <span class="toctext">Computer science</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="#Strong_AI_vs._AI_research"><span class="tocnumber">4.1</span> <span class="toctext">Strong AI vs. AI research</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Turing_test"><span class="tocnumber">4.2</span> <span class="toctext">Turing test</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Symbol_processing"><span class="tocnumber">4.3</span> <span class="toctext">Symbol processing</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Chinese_room_and_Turing_completeness"><span class="tocnumber">4.4</span> <span class="toctext">Chinese room and Turing completeness</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="#Complete_argument"><span class="tocnumber">5</span> <span class="toctext">Complete argument</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#Replies"><span class="tocnumber">6</span> <span class="toctext">Replies</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Systems_and_virtual_mind_replies:_finding_the_mind"><span class="tocnumber">6.1</span> <span class="toctext">Systems and virtual mind replies: finding the mind</span></a>
<ul>
<li class="toclevel-3 tocsection-17"><a href="#System_reply"><span class="tocnumber">6.1.1</span> <span class="toctext">System reply</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#Virtual_mind_reply"><span class="tocnumber">6.1.2</span> <span class="toctext">Virtual mind reply</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-19"><a href="#Robot_and_semantics_replies:_finding_the_meaning"><span class="tocnumber">6.2</span> <span class="toctext">Robot and semantics replies: finding the meaning</span></a>
<ul>
<li class="toclevel-3 tocsection-20"><a href="#Robot_reply"><span class="tocnumber">6.2.1</span> <span class="toctext">Robot reply</span></a></li>
<li class="toclevel-3 tocsection-21"><a href="#Derived_meaning"><span class="tocnumber">6.2.2</span> <span class="toctext">Derived meaning</span></a></li>
<li class="toclevel-3 tocsection-22"><a href="#Commonsense_knowledge_/_contextualist_reply"><span class="tocnumber">6.2.3</span> <span class="toctext">Commonsense knowledge / contextualist reply</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-23"><a href="#Brain_simulation_and_connectionist_replies:_redesigning_the_room"><span class="tocnumber">6.3</span> <span class="toctext">Brain simulation and connectionist replies: redesigning the room</span></a>
<ul>
<li class="toclevel-3 tocsection-24"><a href="#Brain_simulator_reply"><span class="tocnumber">6.3.1</span> <span class="toctext">Brain simulator reply</span></a>
<ul>
<li class="toclevel-4 tocsection-25"><a href="#China_brain"><span class="tocnumber">6.3.1.1</span> <span class="toctext">China brain</span></a></li>
<li class="toclevel-4 tocsection-26"><a href="#Brain_replacement_scenario"><span class="tocnumber">6.3.1.2</span> <span class="toctext">Brain replacement scenario</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-27"><a href="#Connectionist_replies"><span class="tocnumber">6.3.2</span> <span class="toctext">Connectionist replies</span></a></li>
<li class="toclevel-3 tocsection-28"><a href="#Combination_reply"><span class="tocnumber">6.3.3</span> <span class="toctext">Combination reply</span></a></li>
<li class="toclevel-3 tocsection-29"><a href="#Many_mansions_/_wait_till_next_year_reply"><span class="tocnumber">6.3.4</span> <span class="toctext">Many mansions / wait till next year reply</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-30"><a href="#Speed_and_complexity:_appeals_to_intuition"><span class="tocnumber">6.4</span> <span class="toctext">Speed and complexity: appeals to intuition</span></a>
<ul>
<li class="toclevel-3 tocsection-31"><a href="#Speed_and_complexity_replies"><span class="tocnumber">6.4.1</span> <span class="toctext">Speed and complexity replies</span></a></li>
<li class="toclevel-3 tocsection-32"><a href="#Churchland&#39;s_luminous_room"><span class="tocnumber">6.4.2</span> <span class="toctext">Churchland's luminous room</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-33"><a href="#Other_minds_and_zombies:_meaninglessness"><span class="tocnumber">6.5</span> <span class="toctext">Other minds and zombies: meaninglessness</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-34"><a href="#In_popular_culture"><span class="tocnumber">7</span> <span class="toctext">In popular culture</span></a></li>
<li class="toclevel-1 tocsection-35"><a href="#See_also"><span class="tocnumber">8</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-36"><a href="#Notes"><span class="tocnumber">9</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-37"><a href="#Citations"><span class="tocnumber">10</span> <span class="toctext">Citations</span></a></li>
<li class="toclevel-1 tocsection-38"><a href="#References"><span class="tocnumber">11</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-39"><a href="#Further_reading"><span class="tocnumber">12</span> <span class="toctext">Further reading</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Chinese_room_thought_experiment">Chinese room thought experiment</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=1" title="Edit section: Chinese room thought experiment">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:John_searle2.jpg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/69/John_searle2.jpg/220px-John_searle2.jpg" decoding="async" width="220" height="293" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/6/69/John_searle2.jpg/330px-John_searle2.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/69/John_searle2.jpg/440px-John_searle2.jpg 2x" data-file-width="1704" data-file-height="2272" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:John_searle2.jpg" class="internal" title="Enlarge"></a></div>John Searle in December 2005</div></div></div>
<p>Searle's <a href="/wiki/Thought_experiment" title="Thought experiment">thought experiment</a> begins with this hypothetical premise: suppose that <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> research has succeeded in constructing a computer that behaves as if it understands <a href="/wiki/Chinese_language" title="Chinese language">Chinese</a>. It takes <a href="/wiki/Chinese_character" class="mw-redirect" title="Chinese character">Chinese characters</a> as input and, by following the instructions of a <a href="/wiki/Computer_program" title="Computer program">computer program</a>, produces other Chinese characters, which it presents as output. Suppose, says Searle, that this computer performs its task so convincingly that it comfortably passes the <a href="/wiki/Turing_test" title="Turing test">Turing test</a>: it convinces a human Chinese speaker that the program is itself a live Chinese speaker. To all of the questions that the person asks, it makes appropriate responses, such that any Chinese speaker would be convinced that they are talking to another Chinese-speaking human being.
</p><p>The question Searle wants to answer is this: does the machine <i>literally</i> "understand" Chinese? Or is it merely <i>simulating</i> the ability to understand Chinese?<sup id="cite_ref-FOOTNOTESearle19802_8-0" class="reference"><a href="#cite_note-FOOTNOTESearle19802-8">&#91;6&#93;</a></sup><sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;c&#93;</a></sup> Searle calls the first position "<a href="#Strong_AI">strong AI</a>" and the latter "weak AI".<sup id="cite_ref-Strong_AI_in_Searle_(1980)_12-0" class="reference"><a href="#cite_note-Strong_AI_in_Searle_(1980)-12">&#91;d&#93;</a></sup>
</p><p>Searle then supposes that he is in a closed room and has a book with an English version of the computer program, along with sufficient papers, pencils, erasers, and filing cabinets. Searle could receive Chinese characters through a slot in the door, process them according to the program's instructions, and produce Chinese characters as output. If the computer had passed the Turing test this way, it follows, says Searle, that he would do so as well, simply by running the program manually.
</p><p>Searle asserts that there is no essential difference between the roles of the computer and himself in the experiment. Each simply follows a program, step-by-step, producing a behavior which is then interpreted by the user as demonstrating intelligent conversation. However, Searle himself would not be able to understand the conversation. ("I don't speak a word of Chinese,"<sup id="cite_ref-FOOTNOTESearle19803_13-0" class="reference"><a href="#cite_note-FOOTNOTESearle19803-13">&#91;9&#93;</a></sup> he points out.)  Therefore, he argues, it follows that the computer would not be able to understand the conversation either.
</p><p>Searle argues that, without "understanding" (or "<a href="/wiki/Intentionality" title="Intentionality">intentionality</a>"), we cannot describe what the machine is doing as "thinking" and, since it does not think, it does not have a "mind" in anything like the normal sense of the word. Therefore, he concludes that the "strong AI" hypothesis is false.
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=2" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><a href="/wiki/Gottfried_Leibniz" class="mw-redirect" title="Gottfried Leibniz">Gottfried Leibniz</a> made a similar argument in 1714 against <a href="/wiki/Mechanism_(philosophy)" title="Mechanism (philosophy)">mechanism</a> (the position that the mind is a machine and nothing more). Leibniz used the thought experiment of expanding the brain until it was the size of a <a href="/wiki/Mill_(factory)" class="mw-redirect" title="Mill (factory)">mill</a>.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;10&#93;</a></sup> Leibniz found it difficult to imagine that a "mind" capable of "perception" could be constructed using only mechanical processes.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;e&#93;</a></sup> In the 1961 short story "The Game" by <a href="/wiki/Anatoly_Dneprov_(writer)" title="Anatoly Dneprov (writer)">Anatoly Dneprov</a>, a stadium of people act as switches and memory cells implementing a program to translate a sentence of Portuguese, a language that none of them knows.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;11&#93;</a></sup> In 1974, <a href="/w/index.php?title=Lawrence_Davis_(scientist)&amp;action=edit&amp;redlink=1" class="new" title="Lawrence Davis (scientist) (page does not exist)">Lawrence Davis</a> imagined duplicating the brain using telephone lines and offices staffed by people, and in 1978 <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a> envisioned the entire population of China involved in such a brain simulation. This thought experiment is called the <a href="/wiki/China_brain" title="China brain">China brain</a>, also the "Chinese Nation" or the "Chinese Gym".<sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;12&#93;</a></sup>
</p><p>The Chinese Room Argument was introduced in Searle's 1980 paper "Minds, Brains, and Programs", published in <i><a href="/wiki/Behavioral_and_Brain_Sciences" title="Behavioral and Brain Sciences">Behavioral and Brain Sciences</a></i>.<sup id="cite_ref-FOOTNOTESearle1980_18-0" class="reference"><a href="#cite_note-FOOTNOTESearle1980-18">&#91;13&#93;</a></sup> It eventually became the journal's "most influential target article",<sup id="cite_ref-FOOTNOTEHarnad20011_2-1" class="reference"><a href="#cite_note-FOOTNOTEHarnad20011-2">&#91;1&#93;</a></sup> generating an enormous number of commentaries and responses in the ensuing decades, and Searle has continued to defend and refine the argument in many papers, popular articles and books. David Cole writes that "the Chinese Room argument has probably been the most widely discussed philosophical argument in cognitive science to appear in the past 25 years".<sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;14&#93;</a></sup>
</p><p>Most of the discussion consists of attempts to refute it. "The overwhelming majority", notes <i><a href="/wiki/Behavioral_and_Brain_Sciences" title="Behavioral and Brain Sciences">BBS</a></i> editor <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a>,<sup id="cite_ref-20" class="reference"><a href="#cite_note-20">&#91;f&#93;</a></sup> "still think that the Chinese Room Argument is dead wrong".<sup id="cite_ref-FOOTNOTEHarnad20012_21-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad20012-21">&#91;15&#93;</a></sup> The sheer volume of the literature that has grown up around it inspired <a href="/wiki/Patrick_J._Hayes" class="mw-redirect" title="Patrick J. Hayes">Pat Hayes</a> to comment that the field of <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive science</a> ought to be redefined as "the ongoing research program of showing Searle's Chinese Room Argument to be false".<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;16&#93;</a></sup>
</p><p>Searle's argument has become "something of a classic in cognitive science", according to Harnad.<sup id="cite_ref-FOOTNOTEHarnad20012_21-1" class="reference"><a href="#cite_note-FOOTNOTEHarnad20012-21">&#91;15&#93;</a></sup> <a href="/wiki/Varol_Akman" title="Varol Akman">Varol Akman</a> agrees, and has described the original paper as "an exemplar of philosophical clarity and purity".<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;17&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Philosophy">Philosophy</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=3" title="Edit section: Philosophy">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Although the Chinese Room argument was originally presented in reaction to the statements of <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">AI</a> researchers, philosophers have come to view it as an important part of the <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">philosophy of mind</a>. It is a challenge to <a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">functionalism</a> and the <a href="/wiki/Computational_theory_of_mind" title="Computational theory of mind">computational theory of mind</a>,<sup id="cite_ref-Computationalism_26-0" class="reference"><a href="#cite_note-Computationalism-26">&#91;g&#93;</a></sup> and is related to such questions as the <a href="/wiki/Mind%E2%80%93body_problem" title="Mind–body problem">mind–body problem</a>, the <a href="/wiki/Problem_of_other_minds" title="Problem of other minds">problem of other minds</a>, the <a href="/wiki/Symbol_grounding" class="mw-redirect" title="Symbol grounding">symbol-grounding</a> problem, and the <a href="/wiki/Hard_problem_of_consciousness" title="Hard problem of consciousness">hard problem of consciousness</a>.<sup id="cite_ref-Consciousness_1-1" class="reference"><a href="#cite_note-Consciousness-1">&#91;a&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Strong_AI">Strong AI</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=4" title="Edit section: Strong AI">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/John_Searle" title="John Searle">Searle</a> identified a <a href="/wiki/Philosophical_position" class="mw-redirect" title="Philosophical position">philosophical position</a> he calls "strong AI":
</p>
<blockquote><p>The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.<sup id="cite_ref-Strong_AI_5-1" class="reference"><a href="#cite_note-Strong_AI-5">&#91;b&#93;</a></sup></p></blockquote>
<p>The definition hinges on the distinction between <i>simulating</i> a mind and <i>actually having</i> a mind. Searle writes that "according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind."<sup id="cite_ref-FOOTNOTESearle20091_9-1" class="reference"><a href="#cite_note-FOOTNOTESearle20091-9">&#91;7&#93;</a></sup>
</p><p>The position is implicit in some of the statements of early AI researchers and analysts. For example, in 1955, AI founder <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Herbert A. Simon</a> declared that "there are now in the world machines that think, that learn and create"<sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;23&#93;</a></sup><sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;h&#93;</a></sup> and claimed that they had "solved the venerable <a href="/wiki/Mind%E2%80%93body_problem" title="Mind–body problem">mind–body problem</a>, explaining how a system composed of matter can have the properties of <a href="/wiki/Mind" title="Mind">mind</a>."<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;24&#93;</a></sup> <a href="/wiki/John_Haugeland" title="John Haugeland">John Haugeland</a> wrote that "AI wants only the genuine article: <i>machines with minds</i>, in the full and literal sense. This is not science fiction, but real science, based on a theoretical conception as deep as it is daring: namely, we are, at root, <i>computers ourselves</i>."<sup id="cite_ref-FOOTNOTEHaugeland19852_33-0" class="reference"><a href="#cite_note-FOOTNOTEHaugeland19852-33">&#91;25&#93;</a></sup>
</p><p>Searle also ascribes the following positions to advocates of strong AI:
</p>
<ul><li>AI systems can be used to explain the mind;<sup id="cite_ref-Strong_AI_in_Searle_(1980)_12-1" class="reference"><a href="#cite_note-Strong_AI_in_Searle_(1980)-12">&#91;d&#93;</a></sup></li>
<li>The study of the brain is irrelevant to the study of the mind;<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">&#91;i&#93;</a></sup> and</li>
<li>The <a href="/wiki/Turing_test" title="Turing test">Turing test</a> is adequate for establishing the existence of mental states.<sup id="cite_ref-39" class="reference"><a href="#cite_note-39">&#91;j&#93;</a></sup></li></ul>
<h3><span class="mw-headline" id="Strong_AI_as_computationalism_or_functionalism">Strong AI as computationalism or functionalism</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=5" title="Edit section: Strong AI as computationalism or functionalism">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In more recent presentations of the Chinese room argument, Searle has identified "strong AI" as "computer <a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">functionalism</a>" (a term he attributes to <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>).<sup id="cite_ref-FOOTNOTESearle199244_4-1" class="reference"><a href="#cite_note-FOOTNOTESearle199244-4">&#91;3&#93;</a></sup><sup id="cite_ref-FOOTNOTESearle200445_40-0" class="reference"><a href="#cite_note-FOOTNOTESearle200445-40">&#91;30&#93;</a></sup> Functionalism is a position in modern <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">philosophy of mind</a> that holds that we can define mental phenomena (such as beliefs, desires, and perceptions) by describing their functions in relation to each other and to the outside world. Because a computer program can accurately represent functional relationships as relationships between symbols, a computer can have mental phenomena if it runs the right program, according to functionalism.
</p><p><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a> argues that Searle's depictions of strong AI can be reformulated as "recognizable tenets of <i>computationalism</i>, a position (unlike "strong AI") that is actually held by many thinkers, and hence one worth refuting."<sup id="cite_ref-FOOTNOTEHarnad2001p._3_(Italics_his)_41-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad2001p._3_(Italics_his)-41">&#91;31&#93;</a></sup> <a href="/wiki/Computationalism" class="mw-redirect" title="Computationalism">Computationalism</a><sup id="cite_ref-44" class="reference"><a href="#cite_note-44">&#91;k&#93;</a></sup> is the position in the philosophy of mind which argues that the <a href="/wiki/Mind" title="Mind">mind</a> can be accurately described as an <a href="/wiki/Information_processing" title="Information processing">information-processing</a> system.
</p><p>Each of the following, according to Harnad, is a "tenet" of computationalism:<sup id="cite_ref-FOOTNOTEHarnad20013–5_45-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad20013–5-45">&#91;34&#93;</a></sup>
</p>
<ul><li>Mental states are computational states (which is why computers can have mental states and help to explain the mind);</li>
<li>Computational states are <a href="/wiki/Multiple_realizability" title="Multiple realizability">implementation-independent</a>—in other words, it is the software that determines the computational state, not the hardware (which is why the brain, being hardware, is irrelevant); and that</li>
<li>Since implementation is unimportant, the only empirical data that matters is how the system functions; hence the <a href="/wiki/Turing_test" title="Turing test">Turing test</a> is definitive.</li></ul>
<h3><span class="mw-headline" id="Strong_AI_vs._biological_naturalism">Strong AI vs. biological naturalism</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=6" title="Edit section: Strong AI vs. biological naturalism">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Searle holds a philosophical position he calls "<a href="/wiki/Biological_naturalism" title="Biological naturalism">biological naturalism</a>": that <a href="/wiki/Consciousness" title="Consciousness">consciousness</a><sup id="cite_ref-Consciousness_1-2" class="reference"><a href="#cite_note-Consciousness-1">&#91;a&#93;</a></sup> and <a href="/wiki/Intentionality" title="Intentionality">understanding</a> require specific biological machinery that are found in brains. He writes "brains cause minds"<sup id="cite_ref-FOOTNOTESearle198011_7-1" class="reference"><a href="#cite_note-FOOTNOTESearle198011-7">&#91;5&#93;</a></sup> and that "actual human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains".<sup id="cite_ref-FOOTNOTESearle199029_46-0" class="reference"><a href="#cite_note-FOOTNOTESearle199029-46">&#91;35&#93;</a></sup> Searle argues that this machinery (known to <a href="/wiki/Neuroscience" title="Neuroscience">neuroscience</a> as the "<a href="/wiki/Neural_correlates_of_consciousness" title="Neural correlates of consciousness">neural correlates of consciousness</a>") must have some (unspecified) "causal powers" that permit the human experience of consciousness.<sup id="cite_ref-FOOTNOTESearle1990_47-0" class="reference"><a href="#cite_note-FOOTNOTESearle1990-47">&#91;36&#93;</a></sup> Searle's faith in the existence of these powers has been criticized.<sup id="cite_ref-48" class="reference"><a href="#cite_note-48">&#91;l&#93;</a></sup>
</p><p>Searle does not disagree with the notion that machines can have consciousness and understanding, because, as he writes, "we are precisely such machines".<sup id="cite_ref-FOOTNOTESearle198011_7-2" class="reference"><a href="#cite_note-FOOTNOTESearle198011-7">&#91;5&#93;</a></sup> Searle holds that the brain is, in fact, a machine, but that the brain gives rise to consciousness and understanding using machinery that is non-computational. If neuroscience is able to isolate the mechanical process that gives rise to consciousness, then Searle grants that it may be possible to create machines that have consciousness and understanding. However, without the specific machinery required, Searle does not believe that consciousness can occur.
</p><p>Biological naturalism implies that one cannot determine if the experience of consciousness is occurring merely by examining how a system functions, because the specific machinery of the brain is essential. Thus, biological naturalism is directly opposed to both <a href="/wiki/Behaviorism" title="Behaviorism">behaviorism</a> and <a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">functionalism</a> (including "computer functionalism" or "strong AI").<sup id="cite_ref-FOOTNOTEHauser20068_49-0" class="reference"><a href="#cite_note-FOOTNOTEHauser20068-49">&#91;37&#93;</a></sup> Biological naturalism is similar to <a href="/wiki/Identity_theory_of_mind" class="mw-redirect" title="Identity theory of mind">identity theory</a> (the position that mental states are "identical to" or "composed of" neurological events);  however, Searle has specific technical objections to identity theory.<sup id="cite_ref-FOOTNOTESearle1992chpt._5_50-0" class="reference"><a href="#cite_note-FOOTNOTESearle1992chpt._5-50">&#91;38&#93;</a></sup><sup id="cite_ref-51" class="reference"><a href="#cite_note-51">&#91;m&#93;</a></sup> Searle's biological naturalism and strong AI are both opposed to <a href="/wiki/Cartesian_dualism" class="mw-redirect" title="Cartesian dualism">Cartesian dualism</a>,<sup id="cite_ref-FOOTNOTEHauser20068_49-2" class="reference"><a href="#cite_note-FOOTNOTEHauser20068-49">&#91;37&#93;</a></sup> the classical idea that the brain and mind are made of different "substances". Indeed, Searle accuses strong AI of dualism, writing that "strong AI only makes sense given the dualistic assumption that, where the mind is concerned, the brain doesn't matter."<sup id="cite_ref-FOOTNOTESearle198013_34-1" class="reference"><a href="#cite_note-FOOTNOTESearle198013-34">&#91;26&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Consciousness">Consciousness</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=7" title="Edit section: Consciousness">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Searle's original presentation emphasized "understanding"—that is, mental states with what philosophers call "<a href="/wiki/Intentionality" title="Intentionality">intentionality</a>"—and did not directly address other closely related ideas such as "consciousness". However, in more recent presentations Searle has included consciousness as the real target of the argument.<sup id="cite_ref-FOOTNOTESearle199244_4-2" class="reference"><a href="#cite_note-FOOTNOTESearle199244-4">&#91;3&#93;</a></sup>
</p>
<style data-mw-deduplicate="TemplateStyles:r886047036">.mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}</style><blockquote class="templatequote"><p>Computational models of consciousness are not sufficient by themselves for consciousness. The computational model for consciousness stands to consciousness in the same way the computational model of anything stands to the domain being modelled. Nobody supposes that the computational model of rainstorms in London will leave us all wet. But they make the mistake of supposing that the computational model of consciousness is somehow conscious. It is the same mistake in both cases.<sup id="cite_ref-FOOTNOTESearle2002_52-0" class="reference"><a href="#cite_note-FOOTNOTESearle2002-52">&#91;39&#93;</a></sup></p><div class="templatequotecite">—&#8201;<cite>John R. Searle, Consciousness and Language, p. 16</cite></div>
</blockquote>
<p><a href="/wiki/David_Chalmers" title="David Chalmers">David Chalmers</a> writes "it is fairly clear that consciousness is at the root of the matter" of the Chinese room.<sup id="cite_ref-FOOTNOTEChalmers1996322_53-0" class="reference"><a href="#cite_note-FOOTNOTEChalmers1996322-53">&#91;40&#93;</a></sup>
</p><p><a href="/wiki/Colin_McGinn" title="Colin McGinn">Colin McGinn</a> argues that the Chinese room provides strong evidence that the <a href="/wiki/Hard_problem_of_consciousness" title="Hard problem of consciousness">hard problem of consciousness</a> is fundamentally insoluble. The argument, to be clear, is not about whether a machine can be conscious, but about whether it (or anything else for that matter) can be shown to be conscious. It is plain that any other method of probing the occupant of a Chinese room has the same difficulties in principle as exchanging questions and answers in Chinese. It is simply not possible to divine whether a conscious agency or some clever simulation inhabits the room.<sup id="cite_ref-FOOTNOTEMcGinn2000_54-0" class="reference"><a href="#cite_note-FOOTNOTEMcGinn2000-54">&#91;41&#93;</a></sup>
</p><p>Searle argues that this is only true for an observer <i>outside</i> of the room. The whole point of the thought experiment is to put someone <i>inside</i> the room, where they can directly observe the operations of consciousness. Searle claims that from his vantage point within the room there is nothing he can see that could imaginably give rise to consciousness, other than himself, and clearly he does not have a mind that can speak Chinese.
</p>
<h3><span class="mw-headline" id="Applied_ethics">Applied ethics</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=8" title="Edit section: Applied ethics">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:USS_Vincennes_(CG-49)_Aegis_large_screen_displays.jpg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/8/81/USS_Vincennes_%28CG-49%29_Aegis_large_screen_displays.jpg/220px-USS_Vincennes_%28CG-49%29_Aegis_large_screen_displays.jpg" decoding="async" width="220" height="178" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/81/USS_Vincennes_%28CG-49%29_Aegis_large_screen_displays.jpg/330px-USS_Vincennes_%28CG-49%29_Aegis_large_screen_displays.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/81/USS_Vincennes_%28CG-49%29_Aegis_large_screen_displays.jpg/440px-USS_Vincennes_%28CG-49%29_Aegis_large_screen_displays.jpg 2x" data-file-width="2254" data-file-height="1825" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:USS_Vincennes_(CG-49)_Aegis_large_screen_displays.jpg" class="internal" title="Enlarge"></a></div>Sitting in the combat information center aboard <a href="/wiki/USS_Vincennes_(CG-49)" title="USS Vincennes (CG-49)">a warship</a> – proposed as a real-life analog to the Chinese Room</div></div></div>
<p>Patrick Hew used the Chinese Room argument to deduce requirements from military <a href="/wiki/Command_and_control" title="Command and control">command and control</a> systems if they are to preserve a commander's <a href="/wiki/Moral_agency" title="Moral agency">moral agency</a>. He drew an analogy between a commander in their <a href="/wiki/Command_center" title="Command center">command center</a> and the person in the Chinese Room, and analyzed it under a reading of <a href="/wiki/Nicomachean_Ethics" title="Nicomachean Ethics">Aristotle’s notions of "compulsory" and "ignorance"</a>. Information could be "down converted" from meaning to symbols, and manipulated symbolically, but moral agency could be undermined if there was inadequate 'up conversion' into meaning. Hew cited examples from the <a href="/wiki/Iran_Air_Flight_655" title="Iran Air Flight 655">USS <i>Vincennes</i> incident</a>.<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">&#91;42&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Computer_science">Computer science</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=9" title="Edit section: Computer science">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The Chinese room argument is primarily an argument in the <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">philosophy of mind</a>, and both major computer scientists and artificial intelligence researchers consider it irrelevant to their fields.<sup id="cite_ref-FOOTNOTERussellNorvig2003947_6-2" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003947-6">&#91;4&#93;</a></sup> However, several concepts developed by computer scientists are essential to understanding the argument, including <a href="/wiki/Physical_symbol_system" title="Physical symbol system">symbol processing</a>, <a href="/wiki/Turing_machine" title="Turing machine">Turing machines</a>, <a href="/wiki/Turing_completeness" title="Turing completeness">Turing completeness</a>, and the <a href="/wiki/Turing_test" title="Turing test">Turing test</a>.
</p>
<h3><span class="mw-headline" id="Strong_AI_vs._AI_research">Strong AI vs. AI research</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=10" title="Edit section: Strong AI vs. AI research">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Searle's arguments are not usually considered an issue for AI research. <a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Peter Norvig</a> observe that most AI researchers "don't care about the strong AI hypothesis—as long as the program works, they don't care whether you call it a simulation of intelligence or real intelligence."<sup id="cite_ref-FOOTNOTERussellNorvig2003947_6-3" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003947-6">&#91;4&#93;</a></sup> The primary mission of <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> research is only to create useful systems that <i>act</i> intelligently, and it does not matter if the intelligence is "merely" a simulation.
</p><p>Searle does not disagree that AI research can create machines that are capable of highly intelligent behavior. The Chinese room argument leaves open the possibility that a digital machine could be built that <i>acts</i> more intelligently than a person, but does not have a <a href="/wiki/Mind" title="Mind">mind</a> or <a href="/wiki/Intentionality" title="Intentionality">intentionality</a> in the same way that <a href="/wiki/Human_brain" title="Human brain">brains</a> do. The Chinese room argument is not a <i><a href="/wiki/Reductio_ad_absurdum" title="Reductio ad absurdum">reductio ad absurdum</a></i>, rather it is an example that requires explanation. 
</p><p>Searle's "strong AI" should not be confused with "<a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">strong AI</a>" as defined by <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a> and other futurists,<sup id="cite_ref-FOOTNOTEKurzweil2005260_56-0" class="reference"><a href="#cite_note-FOOTNOTEKurzweil2005260-56">&#91;43&#93;</a></sup> who use the term to describe machine intelligence that rivals or exceeds human intelligence. Kurzweil is concerned primarily with the <i>amount</i> of intelligence displayed by the machine, whereas Searle's argument sets no limit on this. Searle argues that even a super-intelligent machine would not necessarily have a mind and consciousness.
</p>
<h3><span class="mw-headline" id="Turing_test">Turing test</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=11" title="Edit section: Turing test">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Turing_test" title="Turing test">Turing test</a></div>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Turing_Test_version_3.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Turing_Test_version_3.png/220px-Turing_Test_version_3.png" decoding="async" width="220" height="282" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/e/e4/Turing_Test_version_3.png 1.5x" data-file-width="250" data-file-height="320" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Turing_Test_version_3.png" class="internal" title="Enlarge"></a></div>The "standard interpretation" of the Turing Test, in which player C, the interrogator, is given the task of trying to determine which player – A or B – is a computer and which is a human. The interrogator is limited to using the responses to written questions to make the determination. Image adapted from Saygin, 2000.<sup id="cite_ref-FOOTNOTESaygin2000_57-0" class="reference"><a href="#cite_note-FOOTNOTESaygin2000-57">&#91;44&#93;</a></sup></div></div></div>
<p>The Chinese room implements a version of the <a href="/wiki/Turing_test" title="Turing test">Turing test</a>.<sup id="cite_ref-FOOTNOTETuring1950_58-0" class="reference"><a href="#cite_note-FOOTNOTETuring1950-58">&#91;45&#93;</a></sup> <a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a> introduced the test in 1950 to help answer the question "can machines think?" In the standard version, a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being. All participants are separated from one another. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test.
</p><p>Turing then considered each possible objection to the proposal "machines can think", and found that there are simple, obvious answers if the question is de-mystified in this way. He did not, however, intend for the test to measure for the presence of "consciousness" or "understanding". He did not believe this was relevant to the issues that he was addressing. He wrote:
</p>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886047036"/><blockquote class="templatequote"><p>I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper.<sup id="cite_ref-FOOTNOTETuring1950_58-1" class="reference"><a href="#cite_note-FOOTNOTETuring1950-58">&#91;45&#93;</a></sup>
</p></blockquote>
<p>To Searle, as a philosopher investigating in the nature of <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">mind</a> and <a href="/wiki/Consciousness" title="Consciousness">consciousness</a>, these are the relevant mysteries. The Chinese room is designed to show that the Turing test is insufficient to detect the presence of consciousness, even if the room can <a href="/wiki/Behaviourism" class="mw-redirect" title="Behaviourism">behave</a> or <a href="/wiki/Functionalism_(philosophy)" class="mw-redirect" title="Functionalism (philosophy)">function</a> as a conscious mind would.
</p>
<h3><span class="mw-headline" id="Symbol_processing">Symbol processing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=12" title="Edit section: Symbol processing">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Physical_symbol_system" title="Physical symbol system">Physical symbol system</a></div>
<p>The Chinese room (and all modern computers) manipulate physical objects in order to carry out calculations and do simulations. AI researchers <a href="/wiki/Allen_Newell" title="Allen Newell">Allen Newell</a> and <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Herbert A. Simon</a> called this kind of machine a <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system</a>. It is also equivalent to the <a href="/wiki/Formal_system" title="Formal system">formal systems</a> used in the field of <a href="/wiki/Mathematical_logic" title="Mathematical logic">mathematical logic</a>.
</p><p>Searle emphasizes the fact that this kind of symbol manipulation is <a href="/wiki/Syntax" title="Syntax">syntactic</a> (borrowing a term from the study of <a href="/wiki/Grammar" title="Grammar">grammar</a>). The computer manipulates the symbols using a form of <a href="/wiki/Syntax" title="Syntax">syntax rules</a>, without any knowledge of the symbol's <a href="/wiki/Semantics" title="Semantics">semantics</a> (that is, their <a href="/wiki/Meaning_(semiotics)" title="Meaning (semiotics)">meaning</a>).
</p><p>Newell and Simon had conjectured that a physical symbol system (such as a digital computer) had all the necessary machinery for "general intelligent action", or, as it is known today, <a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">artificial general intelligence</a>. They framed this as a philosophical position, the <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system hypothesis</a>: "A physical symbol system has the <a href="/wiki/Sufficient" class="mw-redirect" title="Sufficient">necessary and sufficient means</a> for general intelligent action."<sup id="cite_ref-FOOTNOTENewellSimon1976116_59-0" class="reference"><a href="#cite_note-FOOTNOTENewellSimon1976116-59">&#91;46&#93;</a></sup><sup id="cite_ref-FOOTNOTERussellNorvig200318_60-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig200318-60">&#91;47&#93;</a></sup> The Chinese room argument does not refute this, because it is framed in terms of "intelligent action", i.e. the external behavior of the machine, rather than the presence or absence of understanding, consciousness and mind.
</p>
<h3><span class="mw-headline" id="Chinese_room_and_Turing_completeness">Chinese room and Turing completeness</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=13" title="Edit section: Chinese room and Turing completeness">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Turing_completeness" title="Turing completeness">Turing completeness</a> and <a href="/wiki/Church%E2%80%93Turing_thesis" title="Church–Turing thesis">Church–Turing thesis</a></div>
<p>The Chinese room has a design analogous to that of a modern computer. It has a <a href="/wiki/Von_Neumann_architecture" title="Von Neumann architecture">Von Neumann architecture</a>, which consists of a program (the book of instructions), some memory (the papers and file cabinets), a <a href="/wiki/Central_processing_unit" title="Central processing unit">CPU</a> which follows the instructions (the man), and a means to write symbols in memory (the pencil and eraser). A machine with this design is known in <a href="/wiki/Theoretical_computer_science" title="Theoretical computer science">theoretical computer science</a> as "<a href="/wiki/Turing_complete" class="mw-redirect" title="Turing complete">Turing complete</a>", because it has the necessary machinery to carry out any computation that a <a href="/wiki/Turing_machine" title="Turing machine">Turing machine</a> can do, and therefore it is capable of doing a step-by-step simulation of any other digital machine, given enough memory and time. <a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a> writes, "all digital computers are in a sense equivalent."<sup id="cite_ref-FOOTNOTETuring1950442_61-0" class="reference"><a href="#cite_note-FOOTNOTETuring1950442-61">&#91;48&#93;</a></sup> The widely accepted <a href="/wiki/Church%E2%80%93Turing_thesis" title="Church–Turing thesis">Church–Turing thesis</a> holds that any function computable by an effective procedure is computable by a Turing machine.
</p><p>The Turing completeness of the Chinese room implies that it can do whatever any other digital computer can do (albeit much, much more slowly). Thus, if the Chinese room does not or can not contain a Chinese-speaking mind, then no other digital computer can contain a mind. Some replies to Searle begin by arguing that the room, as described, cannot have a Chinese-speaking mind. Arguments of this form, according to <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a>, are "no refutation (but rather an affirmation)"<sup id="cite_ref-FOOTNOTEHarnad200114_62-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad200114-62">&#91;49&#93;</a></sup> of the Chinese room argument, because these arguments actually imply that <i>no</i> digital computers can have a mind.<sup id="cite_ref-FOOTNOTEHarnad2001_36-3" class="reference"><a href="#cite_note-FOOTNOTEHarnad2001-36">&#91;28&#93;</a></sup>
</p><p>There are some critics, such as Hanoch Ben-Yami, who argue that the Chinese room cannot simulate all the abilities of a digital computer, such as being able to determine the current time.<sup id="cite_ref-FOOTNOTEBen-Yami1993_63-0" class="reference"><a href="#cite_note-FOOTNOTEBen-Yami1993-63">&#91;50&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Complete_argument">Complete argument</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=14" title="Edit section: Complete argument">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Searle has produced a more formal version of the argument of which the Chinese Room forms a part. He presented the first version in 1984. The version given below is from 1990.<sup id="cite_ref-64" class="reference"><a href="#cite_note-64">&#91;51&#93;</a></sup><sup id="cite_ref-67" class="reference"><a href="#cite_note-67">&#91;n&#93;</a></sup> The only part of the argument which should be controversial is A3 and it is this point which the Chinese room thought experiment is intended to prove.<sup id="cite_ref-69" class="reference"><a href="#cite_note-69">&#91;o&#93;</a></sup>
</p><p>He begins with three axioms:
</p>
<dl><dd>(A1) "Programs are formal (<a href="/wiki/Syntax" title="Syntax">syntactic</a>)."
<dl><dd>A program uses <a href="/wiki/Syntax" title="Syntax">syntax</a> to manipulate symbols and pays no attention to the <a href="/wiki/Semantics" title="Semantics">semantics</a> of the symbols. It knows where to put the symbols and how to move them around, but it doesn't know what they stand for or what they mean. For the program, the symbols are just physical objects like any others.</dd></dl></dd></dl>
<dl><dd>(A2) "Minds have mental contents (<a href="/wiki/Semantics" title="Semantics">semantics</a>)."
<dl><dd>Unlike the symbols used by a program, our thoughts have meaning: they represent things and we know what it is they represent.</dd></dl></dd></dl>
<dl><dd>(A3) "Syntax by itself is neither constitutive of nor sufficient for semantics."
<dl><dd>This is what the Chinese room thought experiment is intended to prove: the Chinese room has syntax (because there is a man in there moving symbols around). The Chinese room has no semantics (because, according to Searle, there is no one or nothing in the room that understands what the symbols mean). Therefore, having syntax is not enough to generate semantics.</dd></dl></dd></dl>
<p>Searle posits that these lead directly to this conclusion:
</p>
<dl><dd>(C1) Programs are neither constitutive of nor sufficient for minds.
<dl><dd>This should follow without controversy from the first three: Programs don't have semantics. Programs have only syntax, and syntax is insufficient for semantics. Every mind has semantics. Therefore no programs are minds.</dd></dl></dd></dl>
<p>This much of the argument is intended to show that <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> can never produce a machine with a mind by writing programs that manipulate symbols. The remainder of the argument addresses a different issue. Is the human brain running a program? In other words, is the <a href="/wiki/Computational_theory_of_mind" title="Computational theory of mind">computational theory of mind</a> correct?<sup id="cite_ref-Computationalism_26-1" class="reference"><a href="#cite_note-Computationalism-26">&#91;g&#93;</a></sup> He begins with an axiom that is intended to express the basic modern scientific consensus about brains and minds:
</p>
<dl><dd>(A4) Brains cause minds.</dd></dl>
<p>Searle claims that we can derive "immediately" and "trivially"<sup id="cite_ref-FOOTNOTESearle1990_47-2" class="reference"><a href="#cite_note-FOOTNOTESearle1990-47">&#91;36&#93;</a></sup> that:
</p>
<dl><dd>(C2) Any other system capable of causing minds would have to have causal powers (at least) equivalent to those of brains.
<dl><dd>Brains must have something that causes a mind to exist. Science has yet to determine exactly what it is, but it must exist, because minds exist. Searle calls it "causal powers". "Causal powers" is whatever the brain uses to create a mind. If anything else can cause a mind to exist, it must have "equivalent causal powers". "Equivalent causal powers" is whatever <i>else</i> that could be used to make a mind.</dd></dl></dd></dl>
<p>And from this he derives the further conclusions:
</p>
<dl><dd>(C3) Any artifact that produced mental phenomena, any artificial brain, would have to be able to duplicate the specific causal powers of brains, and it could not do that just by running a formal program.
<dl><dd>This <a href="/wiki/Logical_consequence" title="Logical consequence">follows from</a> C1 and C2: Since no program can produce a mind, and "equivalent causal powers" produce minds, it follows that programs do not have "equivalent causal powers."</dd></dl></dd></dl>
<dl><dd>(C4) The way that human brains actually produce mental phenomena cannot be solely by virtue of running a computer program.
<dl><dd>Since programs do not have "equivalent causal powers", "equivalent causal powers" produce minds, and brains produce minds, it follows that brains do not use programs to produce minds.</dd></dl></dd></dl>
<h2><span class="mw-headline" id="Replies">Replies</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=15" title="Edit section: Replies">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Replies to Searle's argument may be classified according to what they claim to show:<sup id="cite_ref-71" class="reference"><a href="#cite_note-71">&#91;p&#93;</a></sup>
</p>
<ul><li>Those which identify <i>who</i> speaks Chinese</li>
<li>Those which demonstrate how meaningless symbols can become meaningful</li>
<li>Those which suggest that the Chinese room should be redesigned in some way</li>
<li>Those which contend that Searle's argument is misleading</li>
<li>Those which argue that the argument makes false assumptions about subjective conscious experience and therefore proves nothing</li></ul>
<p>Some of the arguments (robot and brain simulation, for example) fall into multiple categories.
</p>
<h3><span class="mw-headline" id="Systems_and_virtual_mind_replies:_finding_the_mind">Systems and virtual mind replies: finding the mind</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=16" title="Edit section: Systems and virtual mind replies: finding the mind">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>These replies attempt to answer the question: since the man in the room doesn't speak Chinese, <i>where</i> is the "mind" that does? These replies address the key <a href="/wiki/Ontological" class="mw-redirect" title="Ontological">ontological</a> issues of <a href="/wiki/Mind/body_problem" class="mw-redirect" title="Mind/body problem">mind vs. body</a> and simulation vs. reality. All of the replies that identify the mind in the room are versions of "the system reply".
</p>
<h4><span class="mw-headline" id="System_reply">System reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=17" title="Edit section: System reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>The basic version argues that it is the "whole system" that understands Chinese.<sup id="cite_ref-72" class="reference"><a href="#cite_note-72">&#91;56&#93;</a></sup><sup id="cite_ref-74" class="reference"><a href="#cite_note-74">&#91;q&#93;</a></sup>  While the man understands only English, when he is combined with the program, scratch paper, pencils and file cabinets, they form a system that can understand Chinese. "Here, understanding is not being ascribed to the mere individual; rather it is being ascribed to this whole system of which he is a part" Searle explains.<sup id="cite_ref-FOOTNOTESearle19806_38-1" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup> The fact that man does not understand Chinese is irrelevant, because it is only the system as a whole that matters.</dd></dl>
<p>Searle notes that (in this simple version of the reply) the "system" is nothing more than a collection of ordinary physical objects; it grants the power of understanding and consciousness to "the conjunction of that person and bits of paper"<sup id="cite_ref-FOOTNOTESearle19806_38-2" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup> without making any effort to explain how this pile of objects has become a conscious, thinking being. Searle argues that no reasonable person should be satisfied with the reply, unless they are "under the grip of an ideology;"<sup id="cite_ref-FOOTNOTESearle19806_38-3" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup> In order for this reply to be remotely plausible, one must take it for granted that consciousness can be the product of an information processing "system", and does not require anything resembling the actual biology of the brain.
</p><p>Searle then responds by simplifying this list of physical objects: he asks what happens if the man memorizes the rules and keeps track of everything in his head? Then the whole system consists of just one object: the man himself. Searle argues that if the man doesn't understand Chinese then the system doesn't understand Chinese either because now "the system" and "the man" both describe exactly the same object.<sup id="cite_ref-FOOTNOTESearle19806_38-4" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup> 
</p><p>Critics of Searle's response argue that the program has allowed the man to have two minds in one head.<sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Manual_of_Style/Words_to_watch#Unsupported_attributions" title="Wikipedia:Manual of Style/Words to watch"><span title="The material near this tag possibly uses too-vague attribution or weasel words. (March 2011)">who?</span></a></i>&#93;</sup> If we assume a "mind" is a form of information processing, then the <a href="/wiki/Theory_of_computation" title="Theory of computation">theory of computation</a> can account for two computations occurring at once, namely (1) the computation for <a href="/wiki/Universal_Turing_machine" title="Universal Turing machine">universal programmability</a> (which is the function instantiated by the person and note-taking materials <i>independently</i> from any particular program contents) and (2) the computation of the Turing machine that is described by the program (which is instantiated by everything <i>including</i> the specific program).<sup id="cite_ref-FOOTNOTEYee199344_75-0" class="reference"><a href="#cite_note-FOOTNOTEYee199344-75">&#91;58&#93;</a></sup> The theory of computation thus formally explains the open possibility that the second computation in the Chinese Room could entail a human-equivalent semantic understanding of the Chinese inputs. The focus belongs on the program's Turing machine rather than on the person's.<sup id="cite_ref-FOOTNOTEYee199342–47_76-0" class="reference"><a href="#cite_note-FOOTNOTEYee199342–47-76">&#91;59&#93;</a></sup> However, from Searle's perspective, this argument is circular. The question at issue is whether consciousness is a form of information processing, and this reply requires that we make that assumption.
</p><p>More sophisticated versions of the systems reply try to identify more precisely what "the system" is and they differ in exactly how they describe it. According to these replies,<sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Manual_of_Style/Words_to_watch#Unsupported_attributions" title="Wikipedia:Manual of Style/Words to watch"><span title="The material near this tag possibly uses too-vague attribution or weasel words. (March 2011)">who?</span></a></i>&#93;</sup> the "mind that speaks Chinese" could be such things as: the "software", a "program", a "running program", a simulation of the "neural correlates of consciousness", the "functional system", a "simulated mind", an "<a href="/wiki/Strong_emergence" class="mw-redirect" title="Strong emergence">emergent</a> property", or "a <a href="/wiki/Virtual_artifact" title="Virtual artifact">virtual</a> mind" (<a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a>'s version of the systems reply, described below).
</p>
<h4><span class="mw-headline" id="Virtual_mind_reply">Virtual mind reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=18" title="Edit section: Virtual mind reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>The term "<a href="/wiki/Virtual_artifact" title="Virtual artifact">virtual</a>" is used in computer science to describe an object that appears to exist "in" a computer (or computer network) only because software makes it appear to exist. The objects "inside" computers (including files, folders, and so on) are all "virtual", except for the computer's electronic components. Similarly, <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Minsky</a> argues, a computer may contain a "mind" that is virtual in the same sense as <a href="/wiki/Virtual_machine" title="Virtual machine">virtual machines</a>, <a href="/wiki/Virtual_community" title="Virtual community">virtual communities</a> and <a href="/wiki/Virtual_reality" title="Virtual reality">virtual reality</a>.<sup id="cite_ref-80" class="reference"><a href="#cite_note-80">&#91;r&#93;</a></sup></dd></dl>
<dl><dd>To clarify the distinction between the simple systems reply given above and virtual mind reply, David Cole notes that two simulations could be running on one system at the same time: one speaking Chinese and one speaking Korean. While there is only one system, there can be multiple "virtual minds," thus the "system" cannot be the "mind".<sup id="cite_ref-FOOTNOTECole20048_81-0" class="reference"><a href="#cite_note-FOOTNOTECole20048-81">&#91;63&#93;</a></sup></dd></dl>
<p>Searle responds that such a mind is, at best, a simulation, and writes: "No one supposes that computer simulations of a five-alarm fire will burn the neighborhood down or that a computer simulation of a rainstorm will leave us all drenched."<sup id="cite_ref-FOOTNOTESearle198012_82-0" class="reference"><a href="#cite_note-FOOTNOTESearle198012-82">&#91;64&#93;</a></sup> Nicholas Fearn responds that, for some things, simulation is as good as the real thing. "When we call up the pocket calculator function on a desktop computer, the image of a pocket calculator appears on the screen. We don't complain that 'it isn't <i>really</i> a calculator', because the physical attributes of the device do not matter."<sup id="cite_ref-FOOTNOTEFearn200747_83-0" class="reference"><a href="#cite_note-FOOTNOTEFearn200747-83">&#91;65&#93;</a></sup> The question is, is the human mind like the pocket calculator, essentially composed of information? Or is the mind like the rainstorm, something other than a computer, and not realizable in full by a computer simulation? (The issue of simulation is also discussed in the article <a href="/wiki/Synthetic_intelligence" title="Synthetic intelligence">synthetic intelligence</a>.)
</p><p>These replies provide an explanation of exactly who it is that understands Chinese. If there is something <i>besides</i> the man in the room that can understand Chinese, Searle can't argue that (1) the man doesn't understand Chinese, therefore (2) nothing in the room understands Chinese. This, according to those who make this reply, shows that Searle's argument fails to prove that "strong AI" is false.<sup id="cite_ref-85" class="reference"><a href="#cite_note-85">&#91;s&#93;</a></sup>
</p><p>However, the thought experiment is not intended to be a <i><a href="/wiki/Reductio_ad_absurdum" title="Reductio ad absurdum">reductio ad absurdum</a>,</i> but rather an example that requires explanation. Searle is not asserting that the situation is impossible, but rather that it is difficult or impossible to explain how this system can have subjective conscious experience.<sup id="cite_ref-FOOTNOTESearle200463_86-0" class="reference"><a href="#cite_note-FOOTNOTESearle200463-86">&#91;67&#93;</a></sup> The system reply succeeds in showing that it is <i>not impossible</i> but fails to show how the system would have consciousness; the replies, by themselves, provide no evidence that the system (or the virtual mind) understands Chinese, other than the <a href="/wiki/Hypothetical" class="mw-redirect" title="Hypothetical">hypothetical</a> premise that it passes the <a href="/wiki/Turing_Test" class="mw-redirect" title="Turing Test">Turing Test</a>. As Searle writes "the systems reply simply begs the question by insisting that the system must understand Chinese."<sup id="cite_ref-FOOTNOTESearle19806_38-5" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Robot_and_semantics_replies:_finding_the_meaning">Robot and semantics replies: finding the meaning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=19" title="Edit section: Robot and semantics replies: finding the meaning">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>As far as the person in the room is concerned, the symbols are just meaningless "squiggles." But if the Chinese room really "understands" what it is saying, then the symbols must get their meaning from somewhere. These arguments attempt to connect the symbols to the things they symbolize. These replies address Searle's concerns about <a href="/wiki/Intentionality" title="Intentionality">intentionality</a>, <a href="/wiki/Symbol_grounding" class="mw-redirect" title="Symbol grounding">symbol grounding</a> and <a href="/wiki/Syntax" title="Syntax">syntax</a> vs. <a href="/wiki/Semantic" class="mw-redirect" title="Semantic">semantics</a>.
</p>
<h4><span class="mw-headline" id="Robot_reply">Robot reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=20" title="Edit section: Robot reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>Suppose that instead of a room, the program was placed into a robot that could wander around and interact with its environment. This would allow a "<a href="/wiki/Causality" title="Causality">causal</a> connection" between the symbols and things they represent.<sup id="cite_ref-87" class="reference"><a href="#cite_note-87">&#91;68&#93;</a></sup><sup id="cite_ref-89" class="reference"><a href="#cite_note-89">&#91;t&#93;</a></sup> <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> comments: "If we could graft a robot to a reasoning program, we wouldn't need a person to provide the meaning anymore: it would come from the physical world."<sup id="cite_ref-90" class="reference"><a href="#cite_note-90">&#91;70&#93;</a></sup><sup id="cite_ref-92" class="reference"><a href="#cite_note-92">&#91;u&#93;</a></sup></dd></dl>
<dl><dd>Searle's reply is to suppose that, unbeknownst to the individual in the Chinese room, some of the inputs came directly from a camera mounted on a robot, and some of the outputs were used to manipulate the arms and legs of the robot. Nevertheless, the person in the room is still just following the rules, and <i>does not know what the symbols mean.</i> Searle writes "he doesn't <i>see</i> what comes into the robot's eyes."<sup id="cite_ref-FOOTNOTESearle19807_93-0" class="reference"><a href="#cite_note-FOOTNOTESearle19807-93">&#91;72&#93;</a></sup> (See <a href="/wiki/Mary%27s_room" class="mw-redirect" title="Mary&#39;s room">Mary's room</a> for a similar thought experiment.)</dd></dl>
<h4><span class="mw-headline" id="Derived_meaning">Derived meaning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=21" title="Edit section: Derived meaning">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>Some respond that the room, as Searle describes it, <i>is</i> connected to the world: through the Chinese speakers that it is "talking" to and through the programmers who designed the <a href="/wiki/Knowledge_base" title="Knowledge base">knowledge base</a> in his file cabinet. The symbols Searle manipulates <i>are already meaningful</i>, they're just not meaningful to <i>him</i>.<sup id="cite_ref-94" class="reference"><a href="#cite_note-94">&#91;73&#93;</a></sup><sup id="cite_ref-95" class="reference"><a href="#cite_note-95">&#91;v&#93;</a></sup></dd></dl>
<dl><dd>Searle says that the symbols only have a "derived" meaning, like the meaning of words in books. The meaning of the symbols depends on the conscious understanding of the Chinese speakers and the programmers outside the room. The room, like a book, has no understanding of its own.<sup id="cite_ref-97" class="reference"><a href="#cite_note-97">&#91;w&#93;</a></sup></dd></dl>
<h4><span id="Commonsense_knowledge_.2F_contextualist_reply"></span><span class="mw-headline" id="Commonsense_knowledge_/_contextualist_reply">Commonsense knowledge / contextualist reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=22" title="Edit section: Commonsense knowledge / contextualist reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>Some have argued that the meanings of the symbols would come from a vast "background" of <a href="/wiki/Commonsense_knowledge" class="mw-redirect" title="Commonsense knowledge">commonsense knowledge</a> encoded in the program and the filing cabinets. This would provide a "<a href="/wiki/Contextualism" title="Contextualism">context</a>" that would give the symbols their meaning.<sup id="cite_ref-FOOTNOTECole200418_91-1" class="reference"><a href="#cite_note-FOOTNOTECole200418-91">&#91;71&#93;</a></sup><sup id="cite_ref-99" class="reference"><a href="#cite_note-99">&#91;x&#93;</a></sup></dd></dl>
<dl><dd>Searle agrees that this background exists, but he does not agree that it can be built into programs. <a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Hubert Dreyfus</a> has also criticized the idea that the "background" can be represented symbolically.<sup id="cite_ref-FOOTNOTEDreyfus1979&quot;The_&#91;&#91;epistemological&#93;&#93;_assumption&quot;_100-0" class="reference"><a href="#cite_note-FOOTNOTEDreyfus1979&quot;The_[[epistemological]]_assumption&quot;-100">&#91;76&#93;</a></sup></dd></dl>
<p>To each of these suggestions, Searle's response is the same: no matter how much knowledge is written into the program and no matter how the program is connected to the world, he is still in the room manipulating symbols according to rules. His actions are <a href="/wiki/Syntax" title="Syntax">syntactic</a> and this can never explain to him what the symbols stand for. Searle writes "syntax is insufficient for semantics."<sup id="cite_ref-FOOTNOTESearle1984_101-0" class="reference"><a href="#cite_note-FOOTNOTESearle1984-101">&#91;77&#93;</a></sup><sup id="cite_ref-103" class="reference"><a href="#cite_note-103">&#91;y&#93;</a></sup>
</p><p>However, for those who accept that Searle's actions simulate a mind, separate from his own, the important question is not what the symbols mean <i>to Searle</i>, what is important is what they mean <i>to the virtual mind.</i> While Searle is trapped in the room, the virtual mind is not: it is connected to the outside world through the Chinese speakers it speaks to, through the programmers who gave it world knowledge, and through the cameras and other sensors that <a href="/wiki/Roboticist" class="mw-redirect" title="Roboticist">roboticists</a> can supply.
</p>
<h3><span class="mw-headline" id="Brain_simulation_and_connectionist_replies:_redesigning_the_room">Brain simulation and connectionist replies: redesigning the room</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=23" title="Edit section: Brain simulation and connectionist replies: redesigning the room">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>These arguments are all versions of the systems reply that identify a particular <i>kind</i> of system as being important; they identify some special technology that would create conscious understanding in a machine. (Note that the "robot" and "commonsense knowledge" replies above also specify a certain kind of system as being important.)
</p>
<h4><span class="mw-headline" id="Brain_simulator_reply">Brain simulator reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=24" title="Edit section: Brain simulator reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>Suppose that the program simulated in fine detail the action of every neuron in the brain of a Chinese speaker.<sup id="cite_ref-104" class="reference"><a href="#cite_note-104">&#91;79&#93;</a></sup><sup id="cite_ref-106" class="reference"><a href="#cite_note-106">&#91;z&#93;</a></sup> This strengthens the intuition that there would be no significant difference between the operation of the program and the operation of a live human brain.</dd></dl>
<dl><dd>Searle replies that such a simulation does not reproduce the important features of the brain—its causal and intentional states. <a href="/wiki/John_Searle" title="John Searle">Searle</a> is adamant that "human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains."<sup id="cite_ref-FOOTNOTESearle198013_34-2" class="reference"><a href="#cite_note-FOOTNOTESearle198013-34">&#91;26&#93;</a></sup> Moreover, he argues:</dd></dl>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886047036"/><blockquote class="templatequote"><p>[I]magine that instead of a monolingual man in a room shuffling symbols we have the man operate an elaborate set of water pipes with valves connecting them. When the man receives the Chinese symbols, he looks up in the program, written in English, which valves he has to turn on and off. Each water connection corresponds to a synapse in the Chinese brain, and the whole system is rigged up so that after doing all the right firings, that is after turning on all the right faucets, the Chinese answers pop out at the output end of the series of pipes.
</p><p>Now where is the understanding in this system? It takes Chinese as input, it simulates the formal structure of the synapses of the Chinese brain, and it gives Chinese as output. But the man certainly doesn't understand Chinese, and neither do the water pipes, and if we are tempted to adopt what I think is the absurd view that somehow the conjunction of man and water pipes understands, remember that in principle the man can internalize the formal structure of the water pipes and do all the "neuron firings" in his imagination.<sup id="cite_ref-FOOTNOTESearle1980_18-1" class="reference"><a href="#cite_note-FOOTNOTESearle1980-18">&#91;13&#93;</a></sup><sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources"><span title="This citation requires a reference to the specific page or range of pages in which the material appears. (January 2019)">page&#160;needed</span></a></i>&#93;</sup>
</p>
</blockquote>
<dl><dd>Two variations on the brain simulator reply are the <a href="/wiki/China_brain" title="China brain">China brain</a> and the brain-replacement scenario.</dd></dl>
<h5><span class="mw-headline" id="China_brain">China brain</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=25" title="Edit section: China brain">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<dl><dd>What if we ask each citizen of China to simulate one neuron, using the telephone system to simulate the connections between <a href="/wiki/Axon" title="Axon">axons</a> and <a href="/wiki/Dendrite" title="Dendrite">dendrites</a>? In this version, it seems obvious that no individual would have any understanding of what the brain might be saying.<sup id="cite_ref-107" class="reference"><a href="#cite_note-107">&#91;81&#93;</a></sup><sup id="cite_ref-109" class="reference"><a href="#cite_note-109">&#91;aa&#93;</a></sup> It is also obvious that this system would be functionally equivalent to a brain, so if consciousness is a function, this system would be conscious.</dd></dl>
<h5><span class="mw-headline" id="Brain_replacement_scenario">Brain replacement scenario</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=26" title="Edit section: Brain replacement scenario">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<dl><dd>In this, we are asked to imagine that engineers have invented a tiny computer that simulates the action of an individual neuron. What would happen if we replaced one neuron at a time? Replacing one would clearly do nothing to change conscious awareness. Replacing all of them would create a digital computer that simulates a brain. If Searle is right, then conscious awareness must disappear during the procedure (either gradually or all at once). Searle's critics argue that there would be no point during the procedure when he can claim that conscious awareness ends and mindless simulation begins.<sup id="cite_ref-110" class="reference"><a href="#cite_note-110">&#91;83&#93;</a></sup><sup id="cite_ref-112" class="reference"><a href="#cite_note-112">&#91;ab&#93;</a></sup> Searle predicts that, while going through the brain prosthesis, "you find, to your total amazement, that you are indeed losing control of your external behavior. You find, for example, that when doctors test your vision, you hear them say 'We are holding up a red object in front of you; please tell us what you see.' You want to cry out 'I can't see anything. I'm going totally blind.' But you hear your voice saying in a way that is completely outside of your control, 'I see a red object in front of me.' [...] [Y]our conscious experience slowly shrinks to nothing, while your externally observable behavior remains the same."<sup id="cite_ref-113" class="reference"><a href="#cite_note-113">&#91;85&#93;</a></sup> (See <a href="/wiki/Ship_of_Theseus" title="Ship of Theseus">Ship of Theseus</a> for a similar thought experiment.)</dd></dl>
<h4><span class="mw-headline" id="Connectionist_replies">Connectionist replies</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=27" title="Edit section: Connectionist replies">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>Closely related to the brain simulator reply, this claims that a massively parallel connectionist architecture would be capable of understanding.<sup id="cite_ref-116" class="reference"><a href="#cite_note-116">&#91;ac&#93;</a></sup></dd></dl>
<h4><span class="mw-headline" id="Combination_reply">Combination reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=28" title="Edit section: Combination reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>This response combines the robot reply with the brain simulation reply, arguing that a brain simulation connected to the world through a robot body could have a mind.<sup id="cite_ref-117" class="reference"><a href="#cite_note-117">&#91;88&#93;</a></sup></dd></dl>
<h4><span id="Many_mansions_.2F_wait_till_next_year_reply"></span><span class="mw-headline" id="Many_mansions_/_wait_till_next_year_reply">Many mansions / wait till next year reply</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=29" title="Edit section: Many mansions / wait till next year reply">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>Better technology in the future will allow computers to understand.<sup id="cite_ref-FOOTNOTESearle19808_35-1" class="reference"><a href="#cite_note-FOOTNOTESearle19808-35">&#91;27&#93;</a></sup><sup id="cite_ref-118" class="reference"><a href="#cite_note-118">&#91;ad&#93;</a></sup> Searle agrees that this is possible, but considers this point irrelevant. His argument is that a machine using a program to manipulate formally defined elements can not produce understanding. Searle's argument, if correct, rules out only this particular design. Searle agrees that there may be other designs that would cause a machine to have conscious understanding.</dd></dl>
<p>These arguments (and the robot or commonsense knowledge replies) identify some special technology that would help create conscious understanding in a machine. They may be interpreted in two ways: either they claim (1) this technology is required for consciousness, the Chinese room does not or cannot implement this technology, and therefore the Chinese room cannot pass the Turing test or (even if it did) it would not have conscious understanding. Or they may be claiming that (2) it is easier to see that the Chinese room has a mind if we visualize this technology as being used to create it.
</p><p>In the first case, where features like a robot body or a connectionist architecture are required, Searle claims that strong AI (as he understands it) has been abandoned.<sup id="cite_ref-119" class="reference"><a href="#cite_note-119">&#91;ae&#93;</a></sup> The Chinese room has all the elements of a Turing complete machine, and thus is capable of simulating any digital computation whatsoever. If Searle's room can't pass the Turing test then there is no other digital technology that could pass the Turing test. If Searle's room <i>could</i> pass the Turing test, but still does not have a mind, then the Turing test is not sufficient to determine if the room has a "mind". Either way, it denies one or the other of the positions Searle thinks of as "strong AI", proving his argument.
</p><p>The brain arguments in particular deny strong AI if they assume that there is no simpler way to describe the mind than to create a program that is just as mysterious as the brain was. He writes "I thought the whole idea of strong AI was that we don't need to know how the brain works to know how the mind works."<sup id="cite_ref-FOOTNOTESearle19808_35-2" class="reference"><a href="#cite_note-FOOTNOTESearle19808-35">&#91;27&#93;</a></sup> If computation does not provide an <i>explanation</i> of the human mind, then strong AI has failed, according to Searle.
</p><p>Other critics hold that the room as Searle described it does, in fact, have a mind, however they argue that it is difficult to see—Searle's description is correct, but <i>misleading.</i> By redesigning the room more realistically they hope to make this more obvious. In this case, these arguments are being used as appeals to intuition (see next section).
</p><p>In fact, the room can just as easily be redesigned to <i>weaken</i> our intuitions. <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a>'s <a href="/wiki/Blockhead_argument" class="mw-redirect" title="Blockhead argument">Blockhead argument</a><sup id="cite_ref-FOOTNOTEBlock1981_120-0" class="reference"><a href="#cite_note-FOOTNOTEBlock1981-120">&#91;89&#93;</a></sup> suggests that the program could, in theory, be rewritten into a simple <a href="/wiki/Lookup_table" title="Lookup table">lookup table</a> of <a href="/wiki/Production_system_(computer_science)" title="Production system (computer science)">rules</a> of the form "if the user writes <i>S</i>, reply with <i>P</i> and goto X". At least in principle, any program can be rewritten (or "<a href="/wiki/Refactored" class="mw-redirect" title="Refactored">refactored</a>") into this form, even a brain simulation.<sup id="cite_ref-121" class="reference"><a href="#cite_note-121">&#91;af&#93;</a></sup> In the blockhead scenario, the entire mental state is hidden in the letter X, which represents a <a href="/wiki/Memory_address" title="Memory address">memory address</a>—a number associated with the next rule. It is hard to visualize that an instant of one's conscious experience can be captured in a single large number, yet this is exactly what "strong AI" claims. On the other hand, such a lookup table would be ridiculously large (to the point of being physically impossible), and the states could therefore be <i>extremely</i> specific.
</p><p>Searle argues that however the program is written or however the machine is connected to the world, the mind is being <i>simulated</i> by a simple step-by-step digital machine (or machines). These machines are always just like the man in the room: they understand nothing and don't speak Chinese. They are merely manipulating symbols without knowing what they mean. Searle writes: "I can have any formal program you like, but I still understand nothing."<sup id="cite_ref-FOOTNOTESearle19803_13-1" class="reference"><a href="#cite_note-FOOTNOTESearle19803-13">&#91;9&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Speed_and_complexity:_appeals_to_intuition">Speed and complexity: appeals to intuition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=30" title="Edit section: Speed and complexity: appeals to intuition">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The following arguments (and the intuitive interpretations of the arguments above) do not directly explain how a Chinese speaking mind could exist in Searle's room, or how the symbols he manipulates could become meaningful. However, by raising doubts about Searle's intuitions they support other positions, such as the system and robot replies. These arguments, if accepted, prevent Searle from claiming that his conclusion is obvious by undermining the intuitions that his certainty requires.
</p><p>Several critics believe that Searle's argument relies entirely on intuitions. <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a> writes "Searle's argument depends for its force on intuitions that certain entities do not think."<sup id="cite_ref-122" class="reference"><a href="#cite_note-122">&#91;90&#93;</a></sup> <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> describes the Chinese room argument as a misleading "<a href="/wiki/Intuition_pump" title="Intuition pump">intuition pump</a>"<sup id="cite_ref-FOOTNOTEDennett1991437–440_123-0" class="reference"><a href="#cite_note-FOOTNOTEDennett1991437–440-123">&#91;91&#93;</a></sup> and writes "Searle's thought experiment depends, illicitly, on your imagining too simple a case, an irrelevant case, and drawing the 'obvious' conclusion from it."<sup id="cite_ref-FOOTNOTEDennett1991437–440_123-1" class="reference"><a href="#cite_note-FOOTNOTEDennett1991437–440-123">&#91;91&#93;</a></sup>
</p><p>Some of the arguments above also function as appeals to intuition, especially those that are intended to make it seem more plausible that the Chinese room contains a mind, which can include the robot, commonsense knowledge, brain simulation and connectionist replies. Several of the replies above also address the specific issue of complexity. The connectionist reply emphasizes that a working artificial intelligence system would have to be as complex and as interconnected as the human brain. The commonsense knowledge reply emphasizes that any program that passed a Turing test would have to be "an extraordinarily supple, sophisticated, and multilayered system, brimming with 'world knowledge' and meta-knowledge and meta-meta-knowledge", as <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> explains.<sup id="cite_ref-FOOTNOTEDennett1991438_98-1" class="reference"><a href="#cite_note-FOOTNOTEDennett1991438-98">&#91;75&#93;</a></sup>
</p>
<h4><span class="mw-headline" id="Speed_and_complexity_replies">Speed and complexity replies</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=31" title="Edit section: Speed and complexity replies">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>The speed at which human brains process information is (by some estimates) 100 billion operations per second.<sup id="cite_ref-FOOTNOTECrevier1993269_124-0" class="reference"><a href="#cite_note-FOOTNOTECrevier1993269-124">&#91;92&#93;</a></sup> Several critics point out that the man in the room would probably take millions of years to respond to a simple question, and would require "filing cabinets" of astronomical proportions. This brings the clarity of Searle's intuition into doubt.<sup id="cite_ref-125" class="reference"><a href="#cite_note-125">&#91;93&#93;</a></sup><sup id="cite_ref-127" class="reference"><a href="#cite_note-127">&#91;ag&#93;</a></sup></dd></dl>
<p>An especially vivid version of the speed and complexity reply is from <a href="/wiki/Paul_Churchland" title="Paul Churchland">Paul</a> and <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a>. They propose this analogous thought experiment:
</p>
<h4><span id="Churchland.27s_luminous_room"></span><span class="mw-headline" id="Churchland's_luminous_room">Churchland's luminous room</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=32" title="Edit section: Churchland&#039;s luminous room">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<dl><dd>"Consider a dark room containing a man holding a bar magnet or charged object. If the man pumps the magnet up and down, then, according to <a href="/wiki/James_Clerk_Maxwell" title="James Clerk Maxwell">Maxwell</a>'s theory of artificial luminance (AL), it will initiate a spreading circle of <a href="/wiki/Electromagnetic_radiation" title="Electromagnetic radiation">electromagnetic</a> waves and will thus be luminous. But as all of us who have toyed with magnets or charged balls well know, their forces (or any other forces for that matter), even when set in motion produce no luminance at all. It is inconceivable that you might constitute real luminance just by moving forces around!"<sup id="cite_ref-FOOTNOTEChurchlandChurchland1990_108-1" class="reference"><a href="#cite_note-FOOTNOTEChurchlandChurchland1990-108">&#91;82&#93;</a></sup> The problem is that he would have to wave the magnet up and down something like 450 trillion times per second in order to see anything.<sup id="cite_ref-128" class="reference"><a href="#cite_note-128">&#91;95&#93;</a></sup></dd></dl>
<p><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a> is critical of speed and complexity replies when they stray beyond addressing our intuitions. He writes "Some have made a cult of speed and timing, holding that, when accelerated to the right speed, the computational may make a <a href="/wiki/Phase_transition" title="Phase transition">phase transition</a> into the mental. It should be clear that is not a counterargument but merely an <i><a href="/wiki/Ad_hoc" title="Ad hoc">ad hoc</a></i> speculation (as is the view that it is all just a matter of ratcheting up to the right degree of 'complexity.')"<sup id="cite_ref-FOOTNOTEHarnad20017_129-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad20017-129">&#91;96&#93;</a></sup><sup id="cite_ref-132" class="reference"><a href="#cite_note-132">&#91;ah&#93;</a></sup>
</p><p>Searle argues that his critics are also relying on intuitions, however his opponents' intuitions have no empirical basis. He writes that, in order to consider the "system reply" as remotely plausible, a person must be "under the grip of an ideology".<sup id="cite_ref-FOOTNOTESearle19806_38-6" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup> The system reply only makes sense (to Searle) if one assumes that any "system" can have consciousness, just by virtue of being a system with the right behavior and functional parts. This assumption, he argues, is not tenable given our experience of consciousness.
</p>
<h3><span class="mw-headline" id="Other_minds_and_zombies:_meaninglessness">Other minds and zombies: meaninglessness</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=33" title="Edit section: Other minds and zombies: meaninglessness">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Several replies argue that Searle's argument is irrelevant because his assumptions about the mind and consciousness are faulty. Searle believes that  human beings directly experience their consciousness, intentionality and the nature of the mind every day, and that this experience of consciousness is not open to question.  He writes that we must "presuppose the reality and knowability of the mental."<sup id="cite_ref-FOOTNOTESearle198010_133-0" class="reference"><a href="#cite_note-FOOTNOTESearle198010-133">&#91;99&#93;</a></sup> These replies question whether Searle is justified in using his own experience of consciousness to determine that it is more than mechanical symbol processing. In particular, the other minds reply argues that we cannot use our experience of consciousness to answer questions about other minds (even the mind of a computer), and the epiphenomena reply argues that Searle's consciousness does not "exist" in the sense that Searle thinks it does.
</p>
<dl><dt>Other minds reply</dt>
<dd>This reply points out that Searle's argument is a version of the <a href="/wiki/Problem_of_other_minds" title="Problem of other minds">problem of other minds</a>, applied to machines. There is no way we can determine if other people's subjective experience is the same as our own. We can only study their behavior (i.e., by giving them our own <a href="/wiki/Turing_test" title="Turing test">Turing test</a>). Critics of Searle argue that he is holding the Chinese room to a higher standard than we would hold an ordinary person.<sup id="cite_ref-134" class="reference"><a href="#cite_note-134">&#91;100&#93;</a></sup><sup id="cite_ref-136" class="reference"><a href="#cite_note-136">&#91;ai&#93;</a></sup></dd></dl>
<p><a href="/wiki/Nils_Nilsson_(researcher)" class="mw-redirect" title="Nils Nilsson (researcher)">Nils Nilsson</a> writes "If a program behaves <i>as if</i>  it were multiplying, most of us would say that it is, in fact, multiplying.  For all I know, Searle may only be behaving <i>as if</i>  he were thinking deeply about these matters.  But, even though I disagree with him, his simulation is pretty good, so I'm willing to credit him with real thought."<sup id="cite_ref-FOOTNOTENilsson1984_137-0" class="reference"><a href="#cite_note-FOOTNOTENilsson1984-137">&#91;102&#93;</a></sup>
</p><p><a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a> anticipated Searle's line of argument (which he called "The Argument from Consciousness") in 1950 and makes the other minds reply.<sup id="cite_ref-FOOTNOTETuring195011–12_138-0" class="reference"><a href="#cite_note-FOOTNOTETuring195011–12-138">&#91;103&#93;</a></sup> He noted that people never consider the problem of other minds when dealing with each other. He writes that "instead of arguing continually over this point it is usual to have the polite convention that everyone thinks."<sup id="cite_ref-FOOTNOTETuring195011_139-0" class="reference"><a href="#cite_note-FOOTNOTETuring195011-139">&#91;104&#93;</a></sup> The <a href="/wiki/Turing_test" title="Turing test">Turing test</a> simply extends this "polite convention" to machines. He doesn't intend to solve the problem of other minds (for machines or people) and he doesn't think we need to.<sup id="cite_ref-142" class="reference"><a href="#cite_note-142">&#91;aj&#93;</a></sup>
</p>
<dl><dt>Eliminative Materialism reply</dt>
<dd>Several philosophers argue that consciousness, as Searle describes it, does not exist. This position is sometimes referred to as <a href="/wiki/Eliminative_materialism" title="Eliminative materialism">eliminative materialism</a>: the view that consciousness is a property that can be reduced to a strictly mechanical description, and that our experience of consciousness is, as Daniel Dennett describes it, a "<a href="/wiki/User_illusion" title="User illusion">user illusion</a>".<sup id="cite_ref-FOOTNOTEDennett1991&#91;&#91;Category:Wikipedia_articles_needing_page_number_citations_from_February_2011&#93;&#93;&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;&#91;&#91;Wikipedia:Citing_sources&#124;&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2011)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;&#93;&#93;&lt;/i&gt;&amp;#93;&lt;/sup&gt;_143-0" class="reference"><a href="#cite_note-FOOTNOTEDennett1991[[Category:Wikipedia_articles_needing_page_number_citations_from_February_2011]]&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;[[Wikipedia:Citing_sources|&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2011)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;]]&lt;/i&gt;&amp;#93;&lt;/sup&gt;-143">&#91;107&#93;</a></sup> Other mental properties, such as original <a href="/wiki/Intentionality" title="Intentionality">intentionality</a> (also called “meaning”, “content”, and “semantic character”), is also commonly regarded as something special about beliefs and other propositional attitudes. <a href="/wiki/Eliminative_materialism" title="Eliminative materialism">Eliminative materialism</a> maintains that propositional attitudes such as beliefs and desires, among other mental states that have content, do not exist. If <a href="/wiki/Eliminative_materialism" title="Eliminative materialism">eliminative materialism</a> is the correct scientific account of human cognition then the assumption of the Chinese room argument that "minds have mental contents (<a href="/wiki/Semantics" title="Semantics">semantics</a>)" must be rejected.<sup id="cite_ref-144" class="reference"><a href="#cite_note-144">&#91;108&#93;</a></sup></dd></dl>
<p><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Peter Norvig</a> argue that, if we accept Searle's description of intentionality, consciousness and the mind, we are forced to accept that consciousness is  <a href="/wiki/Epiphenomenal" class="mw-redirect" title="Epiphenomenal">epiphenomenal</a>: that it "casts no shadow", that it is undetectable in the outside world. They argue that Searle must be mistaken about the "knowability of the mental", and in his belief that there are "causal properties" in our neurons that give rise to the mind. They point out that, by Searle's own description, these causal properties can't be detected by anyone outside the mind, otherwise the Chinese Room couldn't pass the <a href="/wiki/Turing_test" title="Turing test">Turing test</a>—the people outside would be able to tell there wasn't a Chinese speaker in the room by detecting their causal properties. Since they can't detect causal properties, they can't detect the existence of the mental. In short, Searle's "causal properties" and consciousness itself is undetectable, and anything that cannot be detected either does not exist or does not matter.<sup id="cite_ref-FOOTNOTERussellNorvig2003_145-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003-145">&#91;109&#93;</a></sup>
</p><p><a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> provides this extension to the "epiphenomena" argument.
</p>
<dl><dt>Dennett's reply from natural selection</dt>
<dd>Suppose that, by some mutation, a human being is born that does not have Searle's "causal properties" but nevertheless acts exactly like a human being. (This sort of animal is called a "<a href="/wiki/Philosophical_zombie" title="Philosophical zombie">zombie</a>" in thought experiments in the <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">philosophy of mind</a>). This new animal would reproduce just as any other human and eventually there would be more of these zombies. Natural selection would favor the zombies, since their design is (we could suppose) a bit simpler. Eventually the humans would die out. So therefore, if Searle is right, it is most likely that human beings (as we see them today) are actually "zombies", who nevertheless insist they are conscious. It is impossible to know whether we are all zombies or not. Even if we are all zombies, we would still believe that we are not.<sup id="cite_ref-146" class="reference"><a href="#cite_note-146">&#91;110&#93;</a></sup></dd></dl>
<p>Searle disagrees with this analysis and argues that "the study of the mind starts with such facts as that humans have beliefs, while thermostats, telephones, and adding machines don't ... what we wanted to know is what distinguishes the mind from thermostats and livers."<sup id="cite_ref-FOOTNOTESearle19807_93-2" class="reference"><a href="#cite_note-FOOTNOTESearle19807-93">&#91;72&#93;</a></sup> He takes it as obvious that we can detect the presence of consciousness and dismisses these replies as being off the point.
</p>
<dl><dt><a href="/wiki/Newton%27s_flaming_laser_sword" class="mw-redirect" title="Newton&#39;s flaming laser sword">Newton's flaming laser sword</a> reply</dt>
<dd><a href="/wiki/Mike_Alder" title="Mike Alder">Mike Alder</a> argues that the entire argument is frivolous, because it is non-<a href="/wiki/Positivist" class="mw-redirect" title="Positivist">positivist</a>: not only is the distinction between <i>simulating</i> a mind and <i>having</i> a mind ill-defined, but it is also irrelevant because no experiments were, or even can be, proposed to distinguish between the two.<sup id="cite_ref-FOOTNOTEAlder2004_147-0" class="reference"><a href="#cite_note-FOOTNOTEAlder2004-147">&#91;111&#93;</a></sup></dd></dl>
<h2><span class="mw-headline" id="In_popular_culture">In popular culture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=34" title="Edit section: In popular culture">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The Chinese room argument is a central concept in <a href="/wiki/Peter_Watts_(author)" title="Peter Watts (author)">Peter Watts</a>'s novels <i><a href="/wiki/Blindsight_(Watts_novel)" title="Blindsight (Watts novel)">Blindsight</a></i> and (to a lesser extent) <i><a href="/wiki/Echopraxia_(novel)" title="Echopraxia (novel)">Echopraxia</a></i>.<sup id="cite_ref-148" class="reference"><a href="#cite_note-148">&#91;112&#93;</a></sup> It is also a central theme in the video game <i><a href="/wiki/Virtue%27s_Last_Reward" class="mw-redirect" title="Virtue&#39;s Last Reward">Virtue's Last Reward</a></i>, and ties into the game's narrative.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2018)">citation needed</span></a></i>&#93;</sup> In Season 4 of the American crime drama <i><a href="/wiki/Numb3rs" class="mw-redirect" title="Numb3rs">Numb3rs</a></i> there is a brief reference to the Chinese room.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2018)">citation needed</span></a></i>&#93;</sup>
</p><p><a href="/wiki/The_Chinese_Room" title="The Chinese Room">The Chinese Room</a> is also the name of a British independent video game development studio best known for working on experimental first-person games, such as <i><a href="/wiki/Everybody%27s_Gone_to_the_Rapture" title="Everybody&#39;s Gone to the Rapture">Everybody's Gone to the Rapture</a></i>, or <i><a href="/wiki/Dear_Esther" title="Dear Esther">Dear Esther</a></i>.<sup id="cite_ref-149" class="reference"><a href="#cite_note-149">&#91;113&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=35" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Computational_models_of_language_acquisition" class="mw-redirect" title="Computational models of language acquisition">Computational models of language acquisition</a></li>
<li><a href="/wiki/Emergent_behavior" class="mw-redirect" title="Emergent behavior">Emergent behavior</a></li>
<li><a href="/wiki/No_true_Scotsman" title="No true Scotsman">No true Scotsman</a></li>
<li><a href="/wiki/Philosophical_zombie" title="Philosophical zombie">Philosophical zombie</a></li>
<li><a href="/wiki/Sorites_paradox" title="Sorites paradox">Sorites paradox</a></li>
<li><i><a href="/wiki/I_Am_a_Strange_Loop" title="I Am a Strange Loop">I Am a Strange Loop</a></i></li></ul>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=36" title="Edit section: Notes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: lower-alpha;">
<ol class="references">
<li id="cite_note-Consciousness-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-Consciousness_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Consciousness_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Consciousness_1-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">The section <a href="/wiki/Chinese_room#Consciousness" title="Chinese room">consciousness</a> of this article discusses the relationship between the Chinese room argument and consciousness.</span>
</li>
<li id="cite_note-Strong_AI-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-Strong_AI_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Strong_AI_5-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">This version is from Searle's <i>Mind, Language and Society</i><sup id="cite_ref-FOOTNOTESearle1999&#91;&#91;Category:Wikipedia_articles_needing_page_number_citations_from_February_2012&#93;&#93;&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;&#91;&#91;Wikipedia:Citing_sources&#124;&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2012)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;&#93;&#93;&lt;/i&gt;&amp;#93;&lt;/sup&gt;_27-0" class="reference"><a href="#cite_note-FOOTNOTESearle1999[[Category:Wikipedia_articles_needing_page_number_citations_from_February_2012]]&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;[[Wikipedia:Citing_sources|&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2012)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;]]&lt;/i&gt;&amp;#93;&lt;/sup&gt;-27">&#91;20&#93;</a></sup> and is also quoted in <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>'s <i><a href="/wiki/Consciousness_Explained" title="Consciousness Explained">Consciousness Explained</a></i>.<sup id="cite_ref-FOOTNOTEDennett1991435_28-0" class="reference"><a href="#cite_note-FOOTNOTEDennett1991435-28">&#91;21&#93;</a></sup> Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states."<sup id="cite_ref-FOOTNOTESearle19801_29-0" class="reference"><a href="#cite_note-FOOTNOTESearle19801-29">&#91;22&#93;</a></sup> Strong AI is defined similarly by <a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Peter Norvig</a>: "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis."<sup id="cite_ref-FOOTNOTERussellNorvig2003947_6-1" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003947-6">&#91;4&#93;</a></sup></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">Searle writes that "according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind."<sup id="cite_ref-FOOTNOTESearle20091_9-0" class="reference"><a href="#cite_note-FOOTNOTESearle20091-9">&#91;7&#93;</a></sup> He also writes:  "On the Strong AI view, the appropriately programmed computer does not just simulate having a mind; it literally has a mind."<sup id="cite_ref-FOOTNOTESearle200466_10-0" class="reference"><a href="#cite_note-FOOTNOTESearle200466-10">&#91;8&#93;</a></sup></span>
</li>
<li id="cite_note-Strong_AI_in_Searle_(1980)-12"><span class="mw-cite-backlink">^ <a href="#cite_ref-Strong_AI_in_Searle_(1980)_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Strong_AI_in_Searle_(1980)_12-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"> 
Searle writes:  "Partisans of strong AI claim that in this question and answer sequence the machine is not only simulating a human ability but also (1) that the machine can literally be said to <i>understand</i> the story and provide the answers to questions, and (2) that what the machine and its program <i>explains</i> the human ability to understand the story and answer questions about it."<sup id="cite_ref-FOOTNOTESearle19802_8-1" class="reference"><a href="#cite_note-FOOTNOTESearle19802-8">&#91;6&#93;</a></sup></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text">Note that Leibniz' was objecting to a "mechanical" theory of the mind (the philosophical position known as <a href="/wiki/Mechanism_(philosophy)" title="Mechanism (philosophy)">mechanism</a>.) Searle is objecting to an "information processing" view of the mind (the philosophical position known as "<a href="/wiki/Computationalism" class="mw-redirect" title="Computationalism">computationalism</a>"). Searle accepts mechanism and rejects computationalism.</span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Harnad</a> edited <i>BBS</i> during the years which saw the introduction and popularisation of the Chinese Room argument.</span>
</li>
<li id="cite_note-Computationalism-26"><span class="mw-cite-backlink">^ <a href="#cite_ref-Computationalism_26-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Computationalism_26-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a> holds that the Searle's argument is against the thesis that "has since come to be called 'computationalism,' according to which cognition is just computation, hence mental states are just computational states".<sup id="cite_ref-FOOTNOTEHarnad20051_24-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad20051-24">&#91;18&#93;</a></sup> David Cole agrees that "the argument also has broad implications for functionalist and computational theories of meaning and of mind".<sup id="cite_ref-FOOTNOTECole20041_25-0" class="reference"><a href="#cite_note-FOOTNOTECole20041-25">&#91;19&#93;</a></sup></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text">Simon, together with <a href="/wiki/Allen_Newell" title="Allen Newell">Allen Newell</a> and <a href="/wiki/Cliff_Shaw" title="Cliff Shaw">Cliff Shaw</a>, had just completed the first "AI" program, the <a href="/wiki/Logic_Theorist" title="Logic Theorist">Logic Theorist</a>.</span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text">Searle believes that "strong AI only makes sense given the dualistic assumption that, where the mind is concerned, the brain doesn't matter." <sup id="cite_ref-FOOTNOTESearle198013_34-0" class="reference"><a href="#cite_note-FOOTNOTESearle198013-34">&#91;26&#93;</a></sup> He writes elsewhere, "I thought the whole idea of strong AI was that we don't need to know how the brain works to know how the mind works." <sup id="cite_ref-FOOTNOTESearle19808_35-0" class="reference"><a href="#cite_note-FOOTNOTESearle19808-35">&#91;27&#93;</a></sup> This position owes its phrasing to Stevan Harnad.<sup id="cite_ref-FOOTNOTEHarnad2001_36-0" class="reference"><a href="#cite_note-FOOTNOTEHarnad2001-36">&#91;28&#93;</a></sup></span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-39">^</a></b></span> <span class="reference-text">"One of the points at issue," writes Searle, "is the adequacy of the Turing test."<sup id="cite_ref-FOOTNOTESearle19806_38-0" class="reference"><a href="#cite_note-FOOTNOTESearle19806-38">&#91;29&#93;</a></sup></span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text"><a href="/wiki/Computationalism" class="mw-redirect" title="Computationalism">Computationalism</a> is associated with <a href="/wiki/Jerry_Fodor" title="Jerry Fodor">Jerry Fodor</a> and <a href="/wiki/Hilary_Putnam" title="Hilary Putnam">Hilary Putnam</a>,<sup id="cite_ref-FOOTNOTEHorst20051_42-0" class="reference"><a href="#cite_note-FOOTNOTEHorst20051-42">&#91;32&#93;</a></sup> and is held by <a href="/wiki/Allen_Newell" title="Allen Newell">Allen Newell</a>,<sup id="cite_ref-FOOTNOTEHarnad2001_36-1" class="reference"><a href="#cite_note-FOOTNOTEHarnad2001-36">&#91;28&#93;</a></sup> <a href="/wiki/Zenon_Pylyshyn" title="Zenon Pylyshyn">Zenon Pylyshyn</a><sup id="cite_ref-FOOTNOTEHarnad2001_36-2" class="reference"><a href="#cite_note-FOOTNOTEHarnad2001-36">&#91;28&#93;</a></sup> and <a href="/wiki/Steven_Pinker" title="Steven Pinker">Steven Pinker</a>,<sup id="cite_ref-FOOTNOTEPinker1997_43-0" class="reference"><a href="#cite_note-FOOTNOTEPinker1997-43">&#91;33&#93;</a></sup> among others.</span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text">See the replies to Searle under <a href="#Other_minds_and_zombies:_meaninglessness">Meaninglessness</a>, below</span>
</li>
<li id="cite_note-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-51">^</a></b></span> <span class="reference-text">Larry Hauser writes that "biological naturalism is either confused (waffling between identity theory and dualism) or else it <i>just is</i> identity theory or dualism."<sup id="cite_ref-FOOTNOTEHauser20068_49-1" class="reference"><a href="#cite_note-FOOTNOTEHauser20068-49">&#91;37&#93;</a></sup></span>
</li>
<li id="cite_note-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-67">^</a></b></span> <span class="reference-text">The wording of each axiom and conclusion are from Searle's presentation in <i><a href="/wiki/Scientific_American" title="Scientific American">Scientific American</a></i>.<sup id="cite_ref-FOOTNOTESearle1990_47-1" class="reference"><a href="#cite_note-FOOTNOTESearle1990-47">&#91;36&#93;</a></sup><sup id="cite_ref-FOOTNOTEHauser20065_65-0" class="reference"><a href="#cite_note-FOOTNOTEHauser20065-65">&#91;52&#93;</a></sup> (A1-3) and (C1) are described as 1,2,3 and 4 in David Cole.<sup id="cite_ref-FOOTNOTECole20045_66-0" class="reference"><a href="#cite_note-FOOTNOTECole20045-66">&#91;53&#93;</a></sup></span>
</li>
<li id="cite_note-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-69">^</a></b></span> <span class="reference-text">Paul and Patricia Churchland write that the Chinese room thought experiment is intended to "shore up axiom 3".<sup id="cite_ref-FOOTNOTEChurchlandChurchland199034_68-0" class="reference"><a href="#cite_note-FOOTNOTEChurchlandChurchland199034-68">&#91;54&#93;</a></sup></span>
</li>
<li id="cite_note-71"><span class="mw-cite-backlink"><b><a href="#cite_ref-71">^</a></b></span> <span class="reference-text">David Cole combines the second and third categories, as well as the fourth and fifth.<sup id="cite_ref-FOOTNOTECole20045–6_70-0" class="reference"><a href="#cite_note-FOOTNOTECole20045–6-70">&#91;55&#93;</a></sup></span>
</li>
<li id="cite_note-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-74">^</a></b></span> <span class="reference-text">This position is held by  <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a>, <a href="/wiki/Jack_Copeland" title="Jack Copeland">Jack Copeland</a>, <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/wiki/Jerry_Fodor" title="Jerry Fodor">Jerry Fodor</a>, <a href="/wiki/John_Haugeland" title="John Haugeland">John Haugeland</a>, <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a>, and <a href="/wiki/Georges_Rey" title="Georges Rey">Georges Rey</a>, among others.<sup id="cite_ref-FOOTNOTECole20046_73-0" class="reference"><a href="#cite_note-FOOTNOTECole20046-73">&#91;57&#93;</a></sup></span>
</li>
<li id="cite_note-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-80">^</a></b></span> <span class="reference-text">The virtual mind reply is held by <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a>, <a href="/wiki/Tim_Maudlin" title="Tim Maudlin">Tim Maudlin</a>, <a href="/wiki/David_Chalmers" title="David Chalmers">David Chalmers</a> and David Cole.<sup id="cite_ref-FOOTNOTECole20047–9_77-0" class="reference"><a href="#cite_note-FOOTNOTECole20047–9-77">&#91;60&#93;</a></sup> The reply was introduced by <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a>.<sup id="cite_ref-FOOTNOTEMinsky1980440_78-0" class="reference"><a href="#cite_note-FOOTNOTEMinsky1980440-78">&#91;61&#93;</a></sup><sup id="cite_ref-FOOTNOTECole20047_79-0" class="reference"><a href="#cite_note-FOOTNOTECole20047-79">&#91;62&#93;</a></sup></span>
</li>
<li id="cite_note-85"><span class="mw-cite-backlink"><b><a href="#cite_ref-85">^</a></b></span> <span class="reference-text">David Cole writes "From the intuition that in the CR thought experiment he would not understand Chinese by running a program, Searle infers that there is no understanding created by running a program. Clearly, whether that inference is valid or not turns on a metaphysical question about the identity of persons and minds. If the person understanding is not identical with the room operator, then the inference is unsound."<sup id="cite_ref-FOOTNOTECole200421_84-0" class="reference"><a href="#cite_note-FOOTNOTECole200421-84">&#91;66&#93;</a></sup></span>
</li>
<li id="cite_note-89"><span class="mw-cite-backlink"><b><a href="#cite_ref-89">^</a></b></span> <span class="reference-text">This position is held by <a href="/wiki/Margaret_Boden" title="Margaret Boden">Margaret Boden</a>, <a href="/wiki/Tim_Crane" title="Tim Crane">Tim Crane</a>, <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/wiki/Jerry_Fodor" title="Jerry Fodor">Jerry Fodor</a>, <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a>, <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a>, and <a href="/wiki/Georges_Rey" title="Georges Rey">Georges Rey</a>, among others.<sup id="cite_ref-FOOTNOTECole20049_88-0" class="reference"><a href="#cite_note-FOOTNOTECole20049-88">&#91;69&#93;</a></sup></span>
</li>
<li id="cite_note-92"><span class="mw-cite-backlink"><b><a href="#cite_ref-92">^</a></b></span> <span class="reference-text"> David Cole calls this the "externalist" account of meaning.<sup id="cite_ref-FOOTNOTECole200418_91-0" class="reference"><a href="#cite_note-FOOTNOTECole200418-91">&#91;71&#93;</a></sup></span>
</li>
<li id="cite_note-95"><span class="mw-cite-backlink"><b><a href="#cite_ref-95">^</a></b></span> <span class="reference-text">The derived meaning reply is associated with <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> and others.</span>
</li>
<li id="cite_note-97"><span class="mw-cite-backlink"><b><a href="#cite_ref-97">^</a></b></span> <span class="reference-text">Searle distinguishes between "intrinsic" intentionality and "derived" intentionality. "Intrinsic" intentionality is the kind that involves "conscious understanding" like you would have in a human mind. <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> doesn't agree that there is a distinction. David Cole writes "derived intentionality is all there is, according to Dennett."<sup id="cite_ref-FOOTNOTECole200419_96-0" class="reference"><a href="#cite_note-FOOTNOTECole200419-96">&#91;74&#93;</a></sup></span>
</li>
<li id="cite_note-99"><span class="mw-cite-backlink"><b><a href="#cite_ref-99">^</a></b></span> <span class="reference-text">David Cole describes this as the "internalist" approach to meaning.<sup id="cite_ref-FOOTNOTECole200418_91-2" class="reference"><a href="#cite_note-FOOTNOTECole200418-91">&#91;71&#93;</a></sup> Proponents of this position include <a href="/wiki/Roger_Schank" title="Roger Schank">Roger Schank</a>, <a href="/wiki/Doug_Lenat" class="mw-redirect" title="Doug Lenat">Doug Lenat</a>, <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a> and (with reservations) <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, who writes "The fact is that any program [that passed a Turing test] would have to be an extraordinarily supple, sophisticated, and multilayered system, brimming with 'world knowledge' and meta-knowledge and meta-meta-knowledge." <sup id="cite_ref-FOOTNOTEDennett1991438_98-0" class="reference"><a href="#cite_note-FOOTNOTEDennett1991438-98">&#91;75&#93;</a></sup></span>
</li>
<li id="cite_note-103"><span class="mw-cite-backlink"><b><a href="#cite_ref-103">^</a></b></span> <span class="reference-text">Searle also writes "Formal symbols by themselves can never be enough for mental contents, because the symbols, by definition, have no meaning (or <a href="/wiki/Interpretation_(logic)" title="Interpretation (logic)">interpretation</a>, or semantics) except insofar as someone outside the system gives it to them."<sup id="cite_ref-FOOTNOTEMotzkinSearle198945_102-0" class="reference"><a href="#cite_note-FOOTNOTEMotzkinSearle198945-102">&#91;78&#93;</a></sup></span>
</li>
<li id="cite_note-106"><span class="mw-cite-backlink"><b><a href="#cite_ref-106">^</a></b></span> <span class="reference-text">The brain simulation reply has been made by <a href="/wiki/Paul_Churchland" title="Paul Churchland">Paul Churchland</a>, <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a> and <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a>.<sup id="cite_ref-FOOTNOTECole200412_105-0" class="reference"><a href="#cite_note-FOOTNOTECole200412-105">&#91;80&#93;</a></sup></span>
</li>
<li id="cite_note-109"><span class="mw-cite-backlink"><b><a href="#cite_ref-109">^</a></b></span> <span class="reference-text">Early versions of this argument were put forward in 1974 by <a href="/w/index.php?title=Lawrence_Davis_(scientist)&amp;action=edit&amp;redlink=1" class="new" title="Lawrence Davis (scientist) (page does not exist)">Lawrence Davis</a> and in 1978 by <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a>. Block's version used walkie talkies and was called the "Chinese Gym". Paul and Patricia Churchland described this scenario as well.<sup id="cite_ref-FOOTNOTEChurchlandChurchland1990_108-0" class="reference"><a href="#cite_note-FOOTNOTEChurchlandChurchland1990-108">&#91;82&#93;</a></sup></span>
</li>
<li id="cite_note-112"><span class="mw-cite-backlink"><b><a href="#cite_ref-112">^</a></b></span> <span class="reference-text">An early version of the brain replacement scenario was put forward by <a href="/wiki/Clark_Glymour" title="Clark Glymour">Clark Glymour</a> in the mid-70s and was touched on by <a href="/wiki/Zenon_Pylyshyn" title="Zenon Pylyshyn">Zenon Pylyshyn</a> in 1980. <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> presented a vivid version of it,<sup id="cite_ref-FOOTNOTEMoravec1988_111-0" class="reference"><a href="#cite_note-FOOTNOTEMoravec1988-111">&#91;84&#93;</a></sup> and it is now associated with <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a>'s version of <a href="/wiki/Transhumanism" title="Transhumanism">transhumanism</a>.</span>
</li>
<li id="cite_note-116"><span class="mw-cite-backlink"><b><a href="#cite_ref-116">^</a></b></span> <span class="reference-text">The connectionist reply is made by <a href="/wiki/Andy_Clark" title="Andy Clark">Andy Clark</a> and <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a>,<sup id="cite_ref-FOOTNOTECole200412_&amp;_17_114-0" class="reference"><a href="#cite_note-FOOTNOTECole200412_&amp;_17-114">&#91;86&#93;</a></sup> as well as <a href="/wiki/Paul_Churchland" title="Paul Churchland">Paul</a> and <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a>.<sup id="cite_ref-FOOTNOTEHauser20067_115-0" class="reference"><a href="#cite_note-FOOTNOTEHauser20067-115">&#91;87&#93;</a></sup></span>
</li>
<li id="cite_note-118"><span class="mw-cite-backlink"><b><a href="#cite_ref-118">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle2009">Searle (2009)</a> uses the name "Wait 'Til Next Year Reply".</span>
</li>
<li id="cite_note-119"><span class="mw-cite-backlink"><b><a href="#cite_ref-119">^</a></b></span> <span class="reference-text">Searle writes that the robot reply "tacitly concedes that cognition is not solely a matter of formal symbol manipulation." <sup id="cite_ref-FOOTNOTESearle19807_93-1" class="reference"><a href="#cite_note-FOOTNOTESearle19807-93">&#91;72&#93;</a></sup> Stevan Harnad makes the same point, writing: "Now just as it is no refutation (but rather an affirmation) of the CRA to deny that [the Turing test] is a strong enough test, or to deny that a computer could ever pass it, it is merely special pleading to try to save computationalism by stipulating ad hoc (in the face of the CRA) that implementational details do matter after all, and that the computer's is the 'right' kind of implementation, whereas Searle's is the 'wrong' kind."<sup id="cite_ref-FOOTNOTEHarnad200114_62-1" class="reference"><a href="#cite_note-FOOTNOTEHarnad200114-62">&#91;49&#93;</a></sup></span>
</li>
<li id="cite_note-121"><span class="mw-cite-backlink"><b><a href="#cite_ref-121">^</a></b></span> <span class="reference-text">That is, any program running on a machine with a finite amount memory.</span>
</li>
<li id="cite_note-127"><span class="mw-cite-backlink"><b><a href="#cite_ref-127">^</a></b></span> <span class="reference-text">Speed and complexity replies are made by <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/wiki/Tim_Maudlin" title="Tim Maudlin">Tim Maudlin</a>, <a href="/wiki/David_Chalmers" title="David Chalmers">David Chalmers</a>, <a href="/wiki/Steven_Pinker" title="Steven Pinker">Steven Pinker</a>, <a href="/wiki/Paul_Churchland" title="Paul Churchland">Paul Churchland</a>, <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a> and others.<sup id="cite_ref-FOOTNOTECole200414_126-0" class="reference"><a href="#cite_note-FOOTNOTECole200414-126">&#91;94&#93;</a></sup> Daniel Dennett points out the complexity of world knowledge.<sup id="cite_ref-FOOTNOTEDennett1991438_98-2" class="reference"><a href="#cite_note-FOOTNOTEDennett1991438-98">&#91;75&#93;</a></sup></span>
</li>
<li id="cite_note-132"><span class="mw-cite-backlink"><b><a href="#cite_ref-132">^</a></b></span> <span class="reference-text">Critics of the "phase transition" form of this argument include Stevan Harnad, <a href="/wiki/Tim_Maudlin" title="Tim Maudlin">Tim Maudlin</a>, <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> and David Cole.<sup id="cite_ref-FOOTNOTECole200414_126-1" class="reference"><a href="#cite_note-FOOTNOTECole200414-126">&#91;94&#93;</a></sup> This "phase transition" idea is a version of <a href="/wiki/Strong_emergentism" class="mw-redirect" title="Strong emergentism">strong emergentism</a> (what <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> derides as "Woo woo West Coast emergence"<sup id="cite_ref-FOOTNOTECrevier1993275_130-0" class="reference"><a href="#cite_note-FOOTNOTECrevier1993275-130">&#91;97&#93;</a></sup>). Harnad accuses <a href="/wiki/Paul_Churchland" title="Paul Churchland">Churchland</a> and <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a> of espousing strong emergentism. Ray Kurzweil also holds a form of strong emergentism.<sup id="cite_ref-FOOTNOTEKurzweil2005_131-0" class="reference"><a href="#cite_note-FOOTNOTEKurzweil2005-131">&#91;98&#93;</a></sup></span>
</li>
<li id="cite_note-136"><span class="mw-cite-backlink"><b><a href="#cite_ref-136">^</a></b></span> <span class="reference-text">The "other minds" reply has been offered by <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a> and <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a>, among others.<sup id="cite_ref-FOOTNOTECole200412–13_135-0" class="reference"><a href="#cite_note-FOOTNOTECole200412–13-135">&#91;101&#93;</a></sup></span>
</li>
<li id="cite_note-142"><span class="mw-cite-backlink"><b><a href="#cite_ref-142">^</a></b></span> <span class="reference-text">One of Turing's motivations for devising the <a href="/wiki/Turing_test" title="Turing test">Turing test</a> is to avoid precisely the kind of philosophical problems that Searle is interested in. He writes "I do not wish to give the impression that I think there is no mystery ... [but] I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper." <sup id="cite_ref-FOOTNOTETuring195012_140-0" class="reference"><a href="#cite_note-FOOTNOTETuring195012-140">&#91;105&#93;</a></sup> Although Turing is discussing consciousness (not the mind or understanding or intentionality), Stuart Russell and Peter Norvig argue that Turing's comments apply the Chinese room.<sup id="cite_ref-FOOTNOTERussellNorvig2003952–953_141-0" class="reference"><a href="#cite_note-FOOTNOTERussellNorvig2003952–953-141">&#91;106&#93;</a></sup></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="Citations">Citations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=37" title="Edit section: Citations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 20em; -webkit-column-width: 20em; column-width: 20em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-FOOTNOTEHarnad20011-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEHarnad20011_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHarnad20011_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, p.&#160;1.</span>
</li>
<li id="cite_note-Roberts-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-Roberts_3-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Roberts, Jacob (2016). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180819152455/https://www.sciencehistory.org/distillations/magazine/thinking-machines-the-search-for-artificial-intelligence">"Thinking Machines: The Search for Artificial Intelligence"</a>. <i>Distillations</i>. <b>2</b> (2): 14–23. Archived from <a rel="nofollow" class="external text" href="https://www.sciencehistory.org/distillations/magazine/thinking-machines-the-search-for-artificial-intelligence">the original</a> on 19 August 2018<span class="reference-accessdate">. Retrieved <span class="nowrap">22 March</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Distillations&amp;rft.atitle=Thinking+Machines%3A+The+Search+for+Artificial+Intelligence&amp;rft.volume=2&amp;rft.issue=2&amp;rft.pages=14-23&amp;rft.date=2016&amp;rft.aulast=Roberts&amp;rft.aufirst=Jacob&amp;rft_id=https%3A%2F%2Fwww.sciencehistory.org%2Fdistillations%2Fmagazine%2Fthinking-machines-the-search-for-artificial-intelligence&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-FOOTNOTESearle199244-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle199244_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle199244_4-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle199244_4-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1992">Searle 1992</a>, p.&#160;44.</span>
</li>
<li id="cite_note-FOOTNOTERussellNorvig2003947-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTERussellNorvig2003947_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTERussellNorvig2003947_6-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTERussellNorvig2003947_6-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTERussellNorvig2003947_6-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;947.</span>
</li>
<li id="cite_note-FOOTNOTESearle198011-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle198011_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle198011_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle198011_7-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;11.</span>
</li>
<li id="cite_note-FOOTNOTESearle19802-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle19802_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19802_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;2.</span>
</li>
<li id="cite_note-FOOTNOTESearle20091-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle20091_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle20091_9-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle2009">Searle 2009</a>, p.&#160;1.</span>
</li>
<li id="cite_note-FOOTNOTESearle200466-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle200466_10-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle2004">Searle 2004</a>, p.&#160;66.</span>
</li>
<li id="cite_note-FOOTNOTESearle19803-13"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle19803_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19803_13-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;3.</span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, 2.1, <a href="#CITEREFLeibniz1714">Leibniz 1714</a>, section 17</span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.hardproblem.ru/en/posts/Events/a-russian-chinese-room-story-antedating-searle-s-1980-discussion/">"A Russian Chinese Room story antedating Searle's 1980 discussion"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+Russian+Chinese+Room+story+antedating+Searle%27s+1980+discussion&amp;rft_id=http%3A%2F%2Fwww.hardproblem.ru%2Fen%2Fposts%2FEvents%2Fa-russian-chinese-room-story-antedating-searle-s-1980-discussion%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, 2.3</span>
</li>
<li id="cite_note-FOOTNOTESearle1980-18"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle1980_18-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle1980_18-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>.</span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;2; <a href="#CITEREFPrestonBishop2002">Preston &amp; Bishop 2002</a></span>
</li>
<li id="cite_note-FOOTNOTEHarnad20012-21"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEHarnad20012_21-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHarnad20012_21-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, p.&#160;2.</span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, p.&#160;1; <a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;2</span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation web"><a href="/wiki/Varol_Akman" title="Varol Akman">Akman, Varol</a> (1998). <a rel="nofollow" class="external text" href="http://cogprints.org/539/index.html">"Book Review — <i>John Haugeland (editor), Mind Design II: Philosophy, Psychology, and Artificial Intelligence</i> &#91;Journal (Paginated)&#93;"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2018-10-02</span></span> &#8211; via Cogprints.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Book+Review+%E2%80%94+John+Haugeland+%28editor%29%2C+Mind+Design+II%3A+Philosophy%2C+Psychology%2C+and+Artificial+Intelligence+%5BJournal+%28Paginated%29%5D&amp;rft.date=1998&amp;rft.aulast=Akman&amp;rft.aufirst=Varol&amp;rft_id=http%3A%2F%2Fcogprints.org%2F539%2Findex.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FOOTNOTEHarnad20051-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHarnad20051_24-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHarnad2005">Harnad 2005</a>, p.&#160;1.</span>
</li>
<li id="cite_note-FOOTNOTECole20041-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20041_25-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;1.</span>
</li>
<li id="cite_note-FOOTNOTESearle1999&#91;&#91;Category:Wikipedia_articles_needing_page_number_citations_from_February_2012&#93;&#93;&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;&#91;&#91;Wikipedia:Citing_sources&#124;&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2012)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;&#93;&#93;&lt;/i&gt;&amp;#93;&lt;/sup&gt;-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle1999[[Category:Wikipedia_articles_needing_page_number_citations_from_February_2012]]&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;[[Wikipedia:Citing_sources|&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2012)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;]]&lt;/i&gt;&amp;#93;&lt;/sup&gt;_27-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1999">Searle 1999</a>, p.&#160;<sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources"><span title="This citation requires a reference to the specific page or range of pages in which the material appears. (February 2012)">page&#160;needed</span></a></i>&#93;</sup>.</span>
</li>
<li id="cite_note-FOOTNOTEDennett1991435-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEDennett1991435_28-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFDennett1991">Dennett 1991</a>, p.&#160;435.</span>
</li>
<li id="cite_note-FOOTNOTESearle19801-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle19801_29-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;1.</span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text">Quoted in <a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;21.</span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text">Quoted in <a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;46 and <a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;17.</span>
</li>
<li id="cite_note-FOOTNOTEHaugeland19852-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHaugeland19852_33-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHaugeland1985">Haugeland 1985</a>, p.&#160;2(Italics his).</span>
</li>
<li id="cite_note-FOOTNOTESearle198013-34"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle198013_34-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle198013_34-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle198013_34-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;13.</span>
</li>
<li id="cite_note-FOOTNOTESearle19808-35"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle19808_35-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19808_35-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19808_35-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;8.</span>
</li>
<li id="cite_note-FOOTNOTEHarnad2001-36"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEHarnad2001_36-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHarnad2001_36-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHarnad2001_36-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHarnad2001_36-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>.</span>
</li>
<li id="cite_note-FOOTNOTESearle19806-38"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle19806_38-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19806_38-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19806_38-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19806_38-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19806_38-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19806_38-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19806_38-6"><sup><i><b>g</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;6.</span>
</li>
<li id="cite_note-FOOTNOTESearle200445-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle200445_40-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle2004">Searle 2004</a>, p.&#160;45.</span>
</li>
<li id="cite_note-FOOTNOTEHarnad2001p._3_(Italics_his)-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHarnad2001p._3_(Italics_his)_41-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, p. 3 (Italics his).</span>
</li>
<li id="cite_note-FOOTNOTEHorst20051-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHorst20051_42-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHorst2005">Horst 2005</a>, p.&#160;1.</span>
</li>
<li id="cite_note-FOOTNOTEPinker1997-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEPinker1997_43-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFPinker1997">Pinker 1997</a>.</span>
</li>
<li id="cite_note-FOOTNOTEHarnad20013–5-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHarnad20013–5_45-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, pp.&#160;3–5.</span>
</li>
<li id="cite_note-FOOTNOTESearle199029-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle199029_46-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1990">Searle 1990</a>, p.&#160;29.</span>
</li>
<li id="cite_note-FOOTNOTESearle1990-47"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle1990_47-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle1990_47-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle1990_47-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1990">Searle 1990</a>.</span>
</li>
<li id="cite_note-FOOTNOTEHauser20068-49"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEHauser20068_49-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHauser20068_49-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHauser20068_49-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;8.</span>
</li>
<li id="cite_note-FOOTNOTESearle1992chpt._5-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle1992chpt._5_50-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1992">Searle 1992</a>, chpt. 5.</span>
</li>
<li id="cite_note-FOOTNOTESearle2002-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle2002_52-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle2002">Searle 2002</a>.</span>
</li>
<li id="cite_note-FOOTNOTEChalmers1996322-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEChalmers1996322_53-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFChalmers1996">Chalmers 1996</a>, p.&#160;322.</span>
</li>
<li id="cite_note-FOOTNOTEMcGinn2000-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEMcGinn2000_54-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFMcGinn2000">McGinn 2000</a>.</span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55">^</a></b></span> <span class="reference-text"><cite class="citation journal">Hew, Patrick Chisan (September 2016). <a rel="nofollow" class="external text" href="https://philpapers.org/rec/HEWPAC">"Preserving a combat commander's moral agency: The Vincennes Incident as a Chinese Room"</a>. <i>Ethics and Information Technology</i>. <b>18</b> (3): 227–235. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs10676-016-9408-y">10.1007/s10676-016-9408-y</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Ethics+and+Information+Technology&amp;rft.atitle=Preserving+a+combat+commander%27s+moral+agency%3A+The+Vincennes+Incident+as+a+Chinese+Room&amp;rft.volume=18&amp;rft.issue=3&amp;rft.pages=227-235&amp;rft.date=2016-09&amp;rft_id=info%3Adoi%2F10.1007%2Fs10676-016-9408-y&amp;rft.aulast=Hew&amp;rft.aufirst=Patrick+Chisan&amp;rft_id=https%3A%2F%2Fphilpapers.org%2Frec%2FHEWPAC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FOOTNOTEKurzweil2005260-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEKurzweil2005260_56-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFKurzweil2005">Kurzweil 2005</a>, p.&#160;260.</span>
</li>
<li id="cite_note-FOOTNOTESaygin2000-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESaygin2000_57-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSaygin2000">Saygin 2000</a>.</span>
</li>
<li id="cite_note-FOOTNOTETuring1950-58"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTETuring1950_58-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTETuring1950_58-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFTuring1950">Turing 1950</a>.</span>
</li>
<li id="cite_note-FOOTNOTENewellSimon1976116-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTENewellSimon1976116_59-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFNewellSimon1976">Newell &amp; Simon 1976</a>, p.&#160;116.</span>
</li>
<li id="cite_note-FOOTNOTERussellNorvig200318-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTERussellNorvig200318_60-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;18.</span>
</li>
<li id="cite_note-FOOTNOTETuring1950442-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTETuring1950442_61-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFTuring1950">Turing 1950</a>, p.&#160;442.</span>
</li>
<li id="cite_note-FOOTNOTEHarnad200114-62"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEHarnad200114_62-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEHarnad200114_62-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, p.&#160;14.</span>
</li>
<li id="cite_note-FOOTNOTEBen-Yami1993-63"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEBen-Yami1993_63-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFBen-Yami1993">Ben-Yami 1993</a>.</span>
</li>
<li id="cite_note-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-64">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1984">Searle 1984</a>; <a href="#CITEREFSearle1990">Searle 1990</a>.</span>
</li>
<li id="cite_note-FOOTNOTEHauser20065-65"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHauser20065_65-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;5.</span>
</li>
<li id="cite_note-FOOTNOTECole20045-66"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20045_66-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;5.</span>
</li>
<li id="cite_note-FOOTNOTEChurchlandChurchland199034-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEChurchlandChurchland199034_68-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFChurchlandChurchland1990">Churchland &amp; Churchland 1990</a>, p.&#160;34.</span>
</li>
<li id="cite_note-FOOTNOTECole20045–6-70"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20045–6_70-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;5–6.</span>
</li>
<li id="cite_note-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-72">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, pp.&#160;5–6; <a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;6–7; <a href="#CITEREFHauser2006">Hauser 2006</a>, pp.&#160;2–3; <a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;959, <a href="#CITEREFDennett1991">Dennett 1991</a>, p.&#160;439; <a href="#CITEREFFearn2007">Fearn 2007</a>, p.&#160;44; <a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;269.</span>
</li>
<li id="cite_note-FOOTNOTECole20046-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20046_73-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;6.</span>
</li>
<li id="cite_note-FOOTNOTEYee199344-75"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEYee199344_75-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFYee1993">Yee 1993</a>, p.&#160;44.</span>
</li>
<li id="cite_note-FOOTNOTEYee199342–47-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEYee199342–47_76-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFYee1993">Yee 1993</a>, pp.&#160;42–47.</span>
</li>
<li id="cite_note-FOOTNOTECole20047–9-77"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20047–9_77-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;7–9.</span>
</li>
<li id="cite_note-FOOTNOTEMinsky1980440-78"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEMinsky1980440_78-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFMinsky1980">Minsky 1980</a>, p.&#160;440.</span>
</li>
<li id="cite_note-FOOTNOTECole20047-79"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20047_79-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;7.</span>
</li>
<li id="cite_note-FOOTNOTECole20048-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20048_81-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;8.</span>
</li>
<li id="cite_note-FOOTNOTESearle198012-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle198012_82-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;12.</span>
</li>
<li id="cite_note-FOOTNOTEFearn200747-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEFearn200747_83-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFFearn2007">Fearn 2007</a>, p.&#160;47.</span>
</li>
<li id="cite_note-FOOTNOTECole200421-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole200421_84-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;21.</span>
</li>
<li id="cite_note-FOOTNOTESearle200463-86"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle200463_86-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle2004">Searle 2004</a>, p.&#160;63.</span>
</li>
<li id="cite_note-87"><span class="mw-cite-backlink"><b><a href="#cite_ref-87">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;7; <a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;9–11; <a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;3; <a href="#CITEREFFearn2007">Fearn 2007</a>, p.&#160;44.</span>
</li>
<li id="cite_note-FOOTNOTECole20049-88"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole20049_88-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;9.</span>
</li>
<li id="cite_note-90"><span class="mw-cite-backlink"><b><a href="#cite_ref-90">^</a></b></span> <span class="reference-text">Quoted in <a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;272</span>
</li>
<li id="cite_note-FOOTNOTECole200418-91"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTECole200418_91-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTECole200418_91-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTECole200418_91-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;18.</span>
</li>
<li id="cite_note-FOOTNOTESearle19807-93"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTESearle19807_93-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19807_93-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTESearle19807_93-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;7.</span>
</li>
<li id="cite_note-94"><span class="mw-cite-backlink"><b><a href="#cite_ref-94">^</a></b></span> <span class="reference-text"><a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;11; <a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;19.</span>
</li>
<li id="cite_note-FOOTNOTECole200419-96"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole200419_96-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;19.</span>
</li>
<li id="cite_note-FOOTNOTEDennett1991438-98"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEDennett1991438_98-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEDennett1991438_98-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-FOOTNOTEDennett1991438_98-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFDennett1991">Dennett 1991</a>, p.&#160;438.</span>
</li>
<li id="cite_note-FOOTNOTEDreyfus1979&quot;The_&#91;&#91;epistemological&#93;&#93;_assumption&quot;-100"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEDreyfus1979&quot;The_[[epistemological]]_assumption&quot;_100-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFDreyfus1979">Dreyfus 1979</a>, "The <a href="/wiki/Epistemological" class="mw-redirect" title="Epistemological">epistemological</a> assumption".</span>
</li>
<li id="cite_note-FOOTNOTESearle1984-101"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle1984_101-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1984">Searle 1984</a>.</span>
</li>
<li id="cite_note-FOOTNOTEMotzkinSearle198945-102"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEMotzkinSearle198945_102-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFMotzkinSearle1989">Motzkin &amp; Searle 1989</a>, p.&#160;45.</span>
</li>
<li id="cite_note-104"><span class="mw-cite-backlink"><b><a href="#cite_ref-104">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, pp.&#160;7–8; <a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;12–13; <a href="#CITEREFHauser2006">Hauser 2006</a>, pp.&#160;3–4; <a href="#CITEREFChurchlandChurchland1990">Churchland &amp; Churchland 1990</a>.</span>
</li>
<li id="cite_note-FOOTNOTECole200412-105"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole200412_105-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;12.</span>
</li>
<li id="cite_note-107"><span class="mw-cite-backlink"><b><a href="#cite_ref-107">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;4; <a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;11.</span>
</li>
<li id="cite_note-FOOTNOTEChurchlandChurchland1990-108"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEChurchlandChurchland1990_108-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEChurchlandChurchland1990_108-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFChurchlandChurchland1990">Churchland &amp; Churchland 1990</a>.</span>
</li>
<li id="cite_note-110"><span class="mw-cite-backlink"><b><a href="#cite_ref-110">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, pp.&#160;956–8; <a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;20; <a href="#CITEREFMoravec1988">Moravec 1988</a>; <a href="#CITEREFKurzweil2005">Kurzweil 2005</a>, p.&#160;262; <a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;271 and 279.</span>
</li>
<li id="cite_note-FOOTNOTEMoravec1988-111"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEMoravec1988_111-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFMoravec1988">Moravec 1988</a>.</span>
</li>
<li id="cite_note-113"><span class="mw-cite-backlink"><b><a href="#cite_ref-113">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1992">Searle 1992</a> quoted in <a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, p.&#160;957.</span>
</li>
<li id="cite_note-FOOTNOTECole200412_&amp;_17-114"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole200412_&amp;_17_114-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;12 &amp; 17.</span>
</li>
<li id="cite_note-FOOTNOTEHauser20067-115"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHauser20067_115-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;7.</span>
</li>
<li id="cite_note-117"><span class="mw-cite-backlink"><b><a href="#cite_ref-117">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, pp.&#160;8–9; <a href="#CITEREFHauser2006">Hauser 2006</a>, p.&#160;11.</span>
</li>
<li id="cite_note-FOOTNOTEBlock1981-120"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEBlock1981_120-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFBlock1981">Block 1981</a>.</span>
</li>
<li id="cite_note-122"><span class="mw-cite-backlink"><b><a href="#cite_ref-122">^</a></b></span> <span class="reference-text">Quoted in <a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;13.</span>
</li>
<li id="cite_note-FOOTNOTEDennett1991437–440-123"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEDennett1991437–440_123-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEDennett1991437–440_123-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFDennett1991">Dennett 1991</a>, pp.&#160;437–440.</span>
</li>
<li id="cite_note-FOOTNOTECrevier1993269-124"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECrevier1993269_124-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;269.</span>
</li>
<li id="cite_note-125"><span class="mw-cite-backlink"><b><a href="#cite_ref-125">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;14–15; <a href="#CITEREFCrevier1993">Crevier 1993</a>, pp.&#160;269–270; <a href="#CITEREFPinker1997">Pinker 1997</a>, p.&#160;95.</span>
</li>
<li id="cite_note-FOOTNOTECole200414-126"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTECole200414_126-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTECole200414_126-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;14.</span>
</li>
<li id="cite_note-128"><span class="mw-cite-backlink"><b><a href="#cite_ref-128">^</a></b></span> <span class="reference-text"><a href="#CITEREFChurchlandChurchland1990">Churchland &amp; Churchland 1990</a>; <a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;12; <a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;270; <a href="#CITEREFFearn2007">Fearn 2007</a>, pp.&#160;45–46; <a href="#CITEREFPinker1997">Pinker 1997</a>, p.&#160;94.</span>
</li>
<li id="cite_note-FOOTNOTEHarnad20017-129"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEHarnad20017_129-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFHarnad2001">Harnad 2001</a>, p.&#160;7.</span>
</li>
<li id="cite_note-FOOTNOTECrevier1993275-130"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECrevier1993275_130-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;275.</span>
</li>
<li id="cite_note-FOOTNOTEKurzweil2005-131"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEKurzweil2005_131-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFKurzweil2005">Kurzweil 2005</a>.</span>
</li>
<li id="cite_note-FOOTNOTESearle198010-133"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTESearle198010_133-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;10.</span>
</li>
<li id="cite_note-134"><span class="mw-cite-backlink"><b><a href="#cite_ref-134">^</a></b></span> <span class="reference-text"><a href="#CITEREFSearle1980">Searle 1980</a>, p.&#160;9; <a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;13; <a href="#CITEREFHauser2006">Hauser 2006</a>, pp.&#160;4–5; <a href="#CITEREFNilsson1984">Nilsson 1984</a>.</span>
</li>
<li id="cite_note-FOOTNOTECole200412–13-135"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTECole200412–13_135-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, pp.&#160;12–13.</span>
</li>
<li id="cite_note-FOOTNOTENilsson1984-137"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTENilsson1984_137-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFNilsson1984">Nilsson 1984</a>.</span>
</li>
<li id="cite_note-FOOTNOTETuring195011–12-138"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTETuring195011–12_138-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFTuring1950">Turing 1950</a>, pp.&#160;11–12.</span>
</li>
<li id="cite_note-FOOTNOTETuring195011-139"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTETuring195011_139-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFTuring1950">Turing 1950</a>, p.&#160;11.</span>
</li>
<li id="cite_note-FOOTNOTETuring195012-140"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTETuring195012_140-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFTuring1950">Turing 1950</a>, p.&#160;12.</span>
</li>
<li id="cite_note-FOOTNOTERussellNorvig2003952–953-141"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTERussellNorvig2003952–953_141-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>, pp.&#160;952–953.</span>
</li>
<li id="cite_note-FOOTNOTEDennett1991&#91;&#91;Category:Wikipedia_articles_needing_page_number_citations_from_February_2011&#93;&#93;&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;&#91;&#91;Wikipedia:Citing_sources&#124;&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2011)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;&#93;&#93;&lt;/i&gt;&amp;#93;&lt;/sup&gt;-143"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEDennett1991[[Category:Wikipedia_articles_needing_page_number_citations_from_February_2011]]&lt;sup_class=&quot;noprint_Inline-Template_&quot;_style=&quot;white-space:nowrap;&quot;&gt;&amp;#91;&lt;i&gt;[[Wikipedia:Citing_sources|&lt;span_title=&quot;This_citation_requires_a_reference_to_the_specific_page_or_range_of_pages_in_which_the_material_appears.&amp;#32;(February_2011)&quot;&gt;page&amp;nbsp;needed&lt;/span&gt;]]&lt;/i&gt;&amp;#93;&lt;/sup&gt;_143-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFDennett1991">Dennett 1991</a>,<sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources"><span title="This citation requires a reference to the specific page or range of pages in which the material appears. (February 2011)">page&#160;needed</span></a></i>&#93;</sup>.</span>
</li>
<li id="cite_note-144"><span class="mw-cite-backlink"><b><a href="#cite_ref-144">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://plato.stanford.edu/entries/materialism-eliminative/">"Eliminative Materialism"</a>. <i>Stanford Encyclopedia of Philosophy</i>. Mar 11, 2019.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Stanford+Encyclopedia+of+Philosophy&amp;rft.atitle=Eliminative+Materialism&amp;rft.date=2019-03-11&amp;rft_id=https%3A%2F%2Fplato.stanford.edu%2Fentries%2Fmaterialism-eliminative%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FOOTNOTERussellNorvig2003-145"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTERussellNorvig2003_145-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFRussellNorvig2003">Russell &amp; Norvig 2003</a>.</span>
</li>
<li id="cite_note-146"><span class="mw-cite-backlink"><b><a href="#cite_ref-146">^</a></b></span> <span class="reference-text"><a href="#CITEREFCole2004">Cole 2004</a>, p.&#160;22; <a href="#CITEREFCrevier1993">Crevier 1993</a>, p.&#160;271; <a href="#CITEREFHarnad2005">Harnad 2005</a>, p.&#160;4.</span>
</li>
<li id="cite_note-FOOTNOTEAlder2004-147"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTEAlder2004_147-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFAlder2004">Alder 2004</a>.</span>
</li>
<li id="cite_note-148"><span class="mw-cite-backlink"><b><a href="#cite_ref-148">^</a></b></span> <span class="reference-text">Patrick Whitmarsh. (2016). “Imagine You're a Machine”: Narrative Systems in Peter Watts's Blindsight and Echopraxia. Science Fiction Studies, 43(2), 237-259. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.5621%2Fsciefictstud.43.2.0237">10.5621/sciefictstud.43.2.0237</a></span>
</li>
<li id="cite_note-149"><span class="mw-cite-backlink"><b><a href="#cite_ref-149">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.thechineseroom.co.uk/">"Home"</a>. <i>The Chinese Room</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2018-04-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Chinese+Room&amp;rft.atitle=Home&amp;rft_id=http%3A%2F%2Fwww.thechineseroom.co.uk%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=38" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r886047268">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class="refbegin reflist" style="">
<ul><li><cite id="CITEREFAlder2004" class="citation journal">Alder, Mike (2004). <a rel="nofollow" class="external text" href="http://www.philosophynow.org/issues/46/Newtons_Flaming_Laser_Sword">"Newton's Flaming Laser Sword"</a>. <i><a href="/wiki/Philosophy_Now" title="Philosophy Now">Philosophy Now</a></i>. <b>46</b>: 29–33. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180326114344/http://www.philosophynow.org/issues/46/Newtons_Flaming_Laser_Sword">Archived</a> from the original on 2018-03-26.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophy+Now&amp;rft.atitle=Newton%27s+Flaming+Laser+Sword&amp;rft.volume=46&amp;rft.pages=29-33&amp;rft.date=2004&amp;rft.aulast=Alder&amp;rft.aufirst=Mike&amp;rft_id=http%3A%2F%2Fwww.philosophynow.org%2Fissues%2F46%2FNewtons_Flaming_Laser_Sword&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/> Also available at <cite class="citation web"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20111114041242/http://school.maths.uwa.edu.au/~mike/Newtons%20Flaming%20Laser%20Sword.pdf">"Newton's Flaming Laser Sword"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://school.maths.uwa.edu.au/~mike/Newtons%20Flaming%20Laser%20Sword.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 14 November 2011.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Newton%27s+Flaming+Laser+Sword&amp;rft_id=http%3A%2F%2Fschool.maths.uwa.edu.au%2F~mike%2FNewtons%2520Flaming%2520Laser%2520Sword.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFBen-Yami1993" class="citation">Ben-Yami, Hanoch (1993), "A Note on the Chinese Room", <i>Synthese</i>, <b>95</b> (2): 169–72, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fbf01064586">10.1007/bf01064586</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Synthese&amp;rft.atitle=A+Note+on+the+Chinese+Room&amp;rft.volume=95&amp;rft.issue=2&amp;rft.pages=169-72&amp;rft.date=1993&amp;rft_id=info%3Adoi%2F10.1007%2Fbf01064586&amp;rft.aulast=Ben-Yami&amp;rft.aufirst=Hanoch&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFBlock1981" class="citation"><a href="/wiki/Ned_Block" title="Ned Block">Block, Ned</a> (1981), <a rel="nofollow" class="external text" href="http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Psychologism.htm">"Psychologism and Behaviourism"</a>, <i>The Philosophical Review</i>, <b>90</b> (1): 5–43, <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.5828">10.1.1.4.5828</a></span>, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F2184371">10.2307/2184371</a>, <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/2184371">2184371</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Philosophical+Review&amp;rft.atitle=Psychologism+and+Behaviourism&amp;rft.volume=90&amp;rft.issue=1&amp;rft.pages=5-43&amp;rft.date=1981&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.4.5828&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2184371&amp;rft_id=info%3Adoi%2F10.2307%2F2184371&amp;rft.aulast=Block&amp;rft.aufirst=Ned&amp;rft_id=http%3A%2F%2Fwww.nyu.edu%2Fgsas%2Fdept%2Fphilo%2Ffaculty%2Fblock%2Fpapers%2FPsychologism.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFChalmers1996" class="citation"><a href="/wiki/David_Chalmers" title="David Chalmers">Chalmers, David</a> (30 March 1996), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=XtgiH-feUyIC"><i>The Conscious Mind: In Search of a Fundamental Theory</i></a>, Oxford University Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-19-983935-3" title="Special:BookSources/978-0-19-983935-3"><bdi>978-0-19-983935-3</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Conscious+Mind%3A+In+Search+of+a+Fundamental+Theory&amp;rft.pub=Oxford+University+Press&amp;rft.date=1996-03-30&amp;rft.isbn=978-0-19-983935-3&amp;rft.aulast=Chalmers&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DXtgiH-feUyIC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFChurchlandChurchland1990" class="citation"><a href="/wiki/Paul_Churchland" title="Paul Churchland">Churchland, Paul</a>; <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Churchland, Patricia</a> (January 1990), "Could a machine think?", <i>Scientific American</i>, <b>262</b> (1): 32–39, <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/1990SciAm.262a..32C">1990SciAm.262a..32C</a>, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fscientificamerican0190-32">10.1038/scientificamerican0190-32</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/2294584">2294584</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Could+a+machine+think%3F&amp;rft.volume=262&amp;rft.issue=1&amp;rft.pages=32-39&amp;rft.date=1990-01&amp;rft_id=info%3Apmid%2F2294584&amp;rft_id=info%3Adoi%2F10.1038%2Fscientificamerican0190-32&amp;rft_id=info%3Abibcode%2F1990SciAm.262a..32C&amp;rft.aulast=Churchland&amp;rft.aufirst=Paul&amp;rft.au=Churchland%2C+Patricia&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFCole2004" class="citation">Cole, David (Fall 2004), "The Chinese Room Argument",  in Zalta, Edward N. (ed.), <a rel="nofollow" class="external text" href="http://plato.stanford.edu/archives/fall2004/entries/chinese-room/"><i>The Stanford Encyclopedia of Philosophy</i></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=The+Chinese+Room+Argument&amp;rft.btitle=The+Stanford+Encyclopedia+of+Philosophy&amp;rft.date=2004&amp;rft.aulast=Cole&amp;rft.aufirst=David&amp;rft_id=http%3A%2F%2Fplato.stanford.edu%2Farchives%2Ffall2004%2Fentries%2Fchinese-room%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>
<dl><dd><i>Page numbers above refer to a standard <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article.</i></dd></dl></li>
<li><cite id="CITEREFCrevier1993" class="citation"><a href="/wiki/Daniel_Crevier" title="Daniel Crevier">Crevier, Daniel</a> (1993), <i>AI: The Tumultuous Search for Artificial Intelligence</i>, New York, NY: BasicBooks, <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-465-02997-3" title="Special:BookSources/0-465-02997-3">0-465-02997-3</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=AI%3A+The+Tumultuous+Search+for+Artificial+Intelligence&amp;rft.place=New+York%2C+NY&amp;rft.pub=BasicBooks&amp;rft.date=1993&amp;rft.aulast=Crevier&amp;rft.aufirst=Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFDennett1991" class="citation"><a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Dennett, Daniel</a> (1991), <a href="/wiki/Consciousness_Explained" title="Consciousness Explained"><i>Consciousness Explained</i></a>, The Penguin Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7139-9037-9" title="Special:BookSources/978-0-7139-9037-9"><bdi>978-0-7139-9037-9</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Consciousness+Explained&amp;rft.pub=The+Penguin+Press&amp;rft.date=1991&amp;rft.isbn=978-0-7139-9037-9&amp;rft.aulast=Dennett&amp;rft.aufirst=Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFDreyfus1979" class="citation"><a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Dreyfus, Hubert</a> (1979), <i>What Computers </i>Still<i> Can't Do</i>, New York: MIT Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-262-04134-8" title="Special:BookSources/978-0-262-04134-8"><bdi>978-0-262-04134-8</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=What+Computers+Still+Can%27t+Do&amp;rft.place=New+York&amp;rft.pub=MIT+Press&amp;rft.date=1979&amp;rft.isbn=978-0-262-04134-8&amp;rft.aulast=Dreyfus&amp;rft.aufirst=Hubert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFFearn2007" class="citation">Fearn, Nicholas (2007), <i>The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers</i>, New York: Grove Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Latest+Answers+to+the+Oldest+Questions%3A+A+Philosophical+Adventure+with+the+World%27s+Greatest+Thinkers&amp;rft.place=New+York&amp;rft.pub=Grove+Press&amp;rft.date=2007&amp;rft.aulast=Fearn&amp;rft.aufirst=Nicholas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFHarnad2001" class="citation"><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Harnad, Stevan</a> (2001), "What's Wrong and Right About Searle's Chinese Room Argument",  in M.; Preston, J. (eds.), <a rel="nofollow" class="external text" href="http://cogprints.org/4023/"><i>Views into the Chinese Room: New Essays on Searle and Artificial Intelligence</i></a>, Oxford University Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=What%27s+Wrong+and+Right+About+Searle%27s+Chinese+Room+Argument&amp;rft.btitle=Views+into+the+Chinese+Room%3A+New+Essays+on+Searle+and+Artificial+Intelligence&amp;rft.pub=Oxford+University+Press&amp;rft.date=2001&amp;rft.aulast=Harnad&amp;rft.aufirst=Stevan&amp;rft_id=http%3A%2F%2Fcogprints.org%2F4023%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<dl><dd><i>Page numbers above refer to a standard <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article.</i></dd></dl>
<ul><li><cite id="CITEREFHarnad2005" class="citation"><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Harnad, Stevan</a> (2005), "Searle's Chinese Room Argument", <a rel="nofollow" class="external text" href="http://eprints.ecs.soton.ac.uk/10424/01/chineseroom.html"><i>Encyclopedia of Philosophy</i></a>, Macmillan</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Searle%27s+Chinese+Room+Argument&amp;rft.btitle=Encyclopedia+of+Philosophy&amp;rft.pub=Macmillan&amp;rft.date=2005&amp;rft.aulast=Harnad&amp;rft.aufirst=Stevan&amp;rft_id=http%3A%2F%2Feprints.ecs.soton.ac.uk%2F10424%2F01%2Fchineseroom.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<dl><dd><i>Page numbers above refer to a standard <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article.</i></dd></dl>
<ul><li><cite id="CITEREFHaugeland1985" class="citation"><a href="/wiki/John_Haugeland" title="John Haugeland">Haugeland, John</a> (1985), <i>Artificial Intelligence: The Very Idea</i>, Cambridge, Mass.: MIT Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-262-08153-5" title="Special:BookSources/978-0-262-08153-5"><bdi>978-0-262-08153-5</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+The+Very+Idea&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pub=MIT+Press&amp;rft.date=1985&amp;rft.isbn=978-0-262-08153-5&amp;rft.aulast=Haugeland&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFHaugeland1981" class="citation"><a href="/wiki/John_Haugeland" title="John Haugeland">Haugeland, John</a> (1981), <span class="cs1-lock-registration" title="Free registration required"><a rel="nofollow" class="external text" href="https://archive.org/details/minddesignphilos00haug"><i>Mind Design</i></a></span>, Cambridge, Mass.: MIT Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-262-08110-8" title="Special:BookSources/978-0-262-08110-8"><bdi>978-0-262-08110-8</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind+Design&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pub=MIT+Press&amp;rft.date=1981&amp;rft.isbn=978-0-262-08110-8&amp;rft.aulast=Haugeland&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fminddesignphilos00haug&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFHauser2006" class="citation"><a href="/w/index.php?title=Larry_Hauser&amp;action=edit&amp;redlink=1" class="new" title="Larry Hauser (page does not exist)">Hauser, Larry</a> (2006), "Searle's Chinese Room", <a rel="nofollow" class="external text" href="http://www.iep.utm.edu/c/chineser.htm"><i>Internet Encyclopedia of Philosophy</i></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Searle%27s+Chinese+Room&amp;rft.btitle=Internet+Encyclopedia+of+Philosophy&amp;rft.date=2006&amp;rft.aulast=Hauser&amp;rft.aufirst=Larry&amp;rft_id=http%3A%2F%2Fwww.iep.utm.edu%2Fc%2Fchineser.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<dl><dd><i>Page numbers above refer to a standard <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article.</i></dd></dl>
<ul><li><cite id="CITEREFKurzweil2005" class="citation"><a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Kurzweil, Ray</a> (2005), <a href="/wiki/The_Singularity_is_Near" class="mw-redirect" title="The Singularity is Near"><i>The Singularity is Near</i></a>, Viking Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Singularity+is+Near&amp;rft.pub=Viking+Press&amp;rft.date=2005&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFHorst2005" class="citation">Horst, Steven (Fall 2005), "The Computational Theory of Mind",  in Zalta, Edward N. (ed.), <a rel="nofollow" class="external text" href="http://plato.stanford.edu/archives/fall2005/entries/computational-mind/"><i>The Stanford Encyclopedia of Philosophy</i></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=The+Computational+Theory+of+Mind&amp;rft.btitle=The+Stanford+Encyclopedia+of+Philosophy&amp;rft.date=2005&amp;rft.aulast=Horst&amp;rft.aufirst=Steven&amp;rft_id=http%3A%2F%2Fplato.stanford.edu%2Farchives%2Ffall2005%2Fentries%2Fcomputational-mind%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFLeibniz1714" class="citation"><a href="/wiki/Gottfried_Leibniz" class="mw-redirect" title="Gottfried Leibniz">Leibniz, Gottfried</a> (1714), <a rel="nofollow" class="external text" href="https://web.archive.org/web/20110703072430/http://www.philosophy.leeds.ac.uk/GMR/moneth/monadology.html"><i>Monadology</i></a>, George MacDonald Ross (trans.), archived from <a rel="nofollow" class="external text" href="http://www.philosophy.leeds.ac.uk/GMR/moneth/monadology.html">the original</a> on July 3, 2011</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Monadology&amp;rft.date=1714&amp;rft.aulast=Leibniz&amp;rft.aufirst=Gottfried&amp;rft_id=http%3A%2F%2Fwww.philosophy.leeds.ac.uk%2FGMR%2Fmoneth%2Fmonadology.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMoravec1988" class="citation"><a href="/wiki/Hans_Moravec" title="Hans Moravec">Moravec, Hans</a> (1988), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=56mb7XuSx3QC"><i>Mind Children: The Future of Robot and Human Intelligence</i></a>, Harvard University Press</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind+Children%3A+The+Future+of+Robot+and+Human+Intelligence&amp;rft.pub=Harvard+University+Press&amp;rft.date=1988&amp;rft.aulast=Moravec&amp;rft.aufirst=Hans&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D56mb7XuSx3QC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<ul><li><cite id="CITEREFMinsky1980" class="citation"><a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Minsky, Marvin</a> (1980), "Decentralized Minds", <i><a href="/wiki/Behavioral_and_Brain_Sciences" title="Behavioral and Brain Sciences">Behavioral and Brain Sciences</a></i>, <b>3</b> (3): 439–40, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1017%2FS0140525X00005914">10.1017/S0140525X00005914</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.atitle=Decentralized+Minds&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=439-40&amp;rft.date=1980&amp;rft_id=info%3Adoi%2F10.1017%2FS0140525X00005914&amp;rft.aulast=Minsky&amp;rft.aufirst=Marvin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMcGinn2000" class="citation">McGinn, Collin (2000), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=qB0lg0u3BEkC&amp;pg=PA194"><i>The Mysterious Flame: Conscious Minds In A Material World</i></a>, Basic Books, p.&#160;194, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0786725168" title="Special:BookSources/978-0786725168"><bdi>978-0786725168</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Mysterious+Flame%3A+Conscious+Minds+In+A+Material+World&amp;rft.pages=194&amp;rft.pub=Basic+Books&amp;rft.date=2000&amp;rft.isbn=978-0786725168&amp;rft.aulast=McGinn&amp;rft.aufirst=Collin&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DqB0lg0u3BEkC%26pg%3DPA194&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFMoor2003" class="citation">Moor, James, ed. (2003), <i>The Turing Test: The Elusive Standard of Artificial Intelligence</i>, Dordrecht: Kluwer Academic Publishers, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4020-1205-1" title="Special:BookSources/978-1-4020-1205-1"><bdi>978-1-4020-1205-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Turing+Test%3A+The+Elusive+Standard+of+Artificial+Intelligence&amp;rft.place=Dordrecht&amp;rft.pub=Kluwer+Academic+Publishers&amp;rft.date=2003&amp;rft.isbn=978-1-4020-1205-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<ul><li><cite id="CITEREFMotzkinSearle1989" class="citation">Motzkin, Elhanan; <a href="/wiki/John_Searle" title="John Searle">Searle, John</a> (February 16, 1989), <a rel="nofollow" class="external text" href="http://www.nybooks.com/articles/archives/1989/feb/16/artificial-intelligence-and-the-chinese-room-an-ex/?pagination=false"><i>Artificial Intelligence and the Chinese Room: An Exchange</i></a>, New York Review of Books</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence+and+the+Chinese+Room%3A+An+Exchange&amp;rft.pub=New+York+Review+of+Books&amp;rft.date=1989-02-16&amp;rft.aulast=Motzkin&amp;rft.aufirst=Elhanan&amp;rft.au=Searle%2C+John&amp;rft_id=http%3A%2F%2Fwww.nybooks.com%2Farticles%2Farchives%2F1989%2Ffeb%2F16%2Fartificial-intelligence-and-the-chinese-room-an-ex%2F%3Fpagination%3Dfalse&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNewellSimon1976" class="citation"><a href="/wiki/Allen_Newell" title="Allen Newell">Newell, Allen</a>; <a href="/wiki/Herbert_A._Simon" title="Herbert A. Simon">Simon, H. A.</a> (1976), "Computer Science as Empirical Inquiry: Symbols and Search", <i>Communications of the ACM</i>, <b>19</b> (3): 113–126, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F360018.360022">10.1145/360018.360022</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Computer+Science+as+Empirical+Inquiry%3A+Symbols+and+Search&amp;rft.volume=19&amp;rft.issue=3&amp;rft.pages=113-126&amp;rft.date=1976&amp;rft_id=info%3Adoi%2F10.1145%2F360018.360022&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Simon%2C+H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNikolić2015" class="citation">Nikolić, Danko (2015), "Practopoiesis: Or how life fosters a mind", <i>Journal of Theoretical Biology</i>, <b>373</b>: 40–61, <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1402.5332">1402.5332</a></span>, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.jtbi.2015.03.003">10.1016/j.jtbi.2015.03.003</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/25791287">25791287</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Theoretical+Biology&amp;rft.atitle=Practopoiesis%3A+Or+how+life+fosters+a+mind&amp;rft.volume=373&amp;rft.pages=40-61&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1402.5332&amp;rft_id=info%3Apmid%2F25791287&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jtbi.2015.03.003&amp;rft.aulast=Nikoli%C4%87&amp;rft.aufirst=Danko&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFNilsson1984" class="citation"><a href="/wiki/Nils_Nilsson_(researcher)" class="mw-redirect" title="Nils Nilsson (researcher)">Nilsson, Nils</a> (1984), <a rel="nofollow" class="external text" href="https://ai.stanford.edu/%7Enilsson/OnlinePubs-Nils/General%20Essays/OtherEssays-Nils/searle.pdf"><i>A Short Rebuttal to Searle</i></a> <span class="cs1-format">(PDF)</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+Short+Rebuttal+to+Searle&amp;rft.date=1984&amp;rft.aulast=Nilsson&amp;rft.aufirst=Nils&amp;rft_id=https%3A%2F%2Fai.stanford.edu%2F%257Enilsson%2FOnlinePubs-Nils%2FGeneral%2520Essays%2FOtherEssays-Nils%2Fsearle.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFRussellNorvig2003" class="citation"><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell, Stuart J.</a>; <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig, Peter</a> (2003), <a rel="nofollow" class="external text" href="http://aima.cs.berkeley.edu/"><i>Artificial Intelligence: A Modern Approach</i></a> (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-13-790395-2" title="Special:BookSources/0-13-790395-2"><bdi>0-13-790395-2</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.place=Upper+Saddle+River%2C+New+Jersey&amp;rft.edition=2nd&amp;rft.pub=Prentice+Hall&amp;rft.date=2003&amp;rft.isbn=0-13-790395-2&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart+J.&amp;rft.au=Norvig%2C+Peter&amp;rft_id=http%3A%2F%2Faima.cs.berkeley.edu%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFPinker1997" class="citation"><a href="/wiki/Steven_Pinker" title="Steven Pinker">Pinker, Steven</a> (1997), <a href="/wiki/How_the_Mind_Works" title="How the Mind Works"><i>How the Mind Works</i></a>, New York, NY: W. W. Norton &amp; Company, Inc., <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-393-31848-7" title="Special:BookSources/978-0-393-31848-7"><bdi>978-0-393-31848-7</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=How+the+Mind+Works&amp;rft.place=New+York%2C+NY&amp;rft.pub=W.+W.+Norton+%26+Company%2C+Inc.&amp;rft.date=1997&amp;rft.isbn=978-0-393-31848-7&amp;rft.aulast=Pinker&amp;rft.aufirst=Steven&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<ul><li><cite id="CITEREFPrestonBishop2002" class="citation">Preston, John; Bishop, Mark, eds. (2002), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=N7msQgAACAAJ"><i>Views into the Chinese Room: New Essays on Searle and Artificial Intelligence</i></a>, Oxford University Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-19-825057-9" title="Special:BookSources/978-0-19-825057-9"><bdi>978-0-19-825057-9</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Views+into+the+Chinese+Room%3A+New+Essays+on+Searle+and+Artificial+Intelligence&amp;rft.pub=Oxford+University+Press&amp;rft.date=2002&amp;rft.isbn=978-0-19-825057-9&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DN7msQgAACAAJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<ul><li><cite id="CITEREFSaygin2000" class="citation">Saygin, A. P.; Cicekli, I.; Akman, V. (2000), <a rel="nofollow" class="external text" href="http://crl.ucsd.edu/~saygin/papers/MMTT.pdf">"Turing Test: 50 Years Later"</a> <span class="cs1-format">(PDF)</span>, <i>Minds and Machines</i>, <b>10</b> (4): 463–518, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1023%2FA%3A1011288000451">10.1023/A:1011288000451</a>, <a href="/wiki/Handle_System" title="Handle System">hdl</a>:<a rel="nofollow" class="external text" href="//hdl.handle.net/11693%2F24987">11693/24987</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Minds+and+Machines&amp;rft.atitle=Turing+Test%3A+50+Years+Later&amp;rft.volume=10&amp;rft.issue=4&amp;rft.pages=463-518&amp;rft.date=2000&amp;rft_id=info%3Ahdl%2F11693%2F24987&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1011288000451&amp;rft.aulast=Saygin&amp;rft.aufirst=A.+P.&amp;rft.au=Cicekli%2C+I.&amp;rft.au=Akman%2C+V.&amp;rft_id=http%3A%2F%2Fcrl.ucsd.edu%2F~saygin%2Fpapers%2FMMTT.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>. Reprinted in <a href="#CITEREFMoor2003">Moor (2003</a>, pp.&#160;23–78).</li>
<li><cite id="CITEREFSearle1980" class="citation"><a href="/wiki/John_Searle" title="John Searle">Searle, John</a> (1980), <a rel="nofollow" class="external text" href="https://web.archive.org/web/20071210043312/http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html">"Minds, Brains and Programs"</a>, <i><a href="/wiki/Behavioral_and_Brain_Sciences" title="Behavioral and Brain Sciences">Behavioral and Brain Sciences</a></i>, <b>3</b> (3): 417–457, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1017%2FS0140525X00005756">10.1017/S0140525X00005756</a><span class="reference-accessdate">, retrieved <span class="nowrap">May 13,</span> 2009</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.atitle=Minds%2C+Brains+and+Programs&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=417-457&amp;rft.date=1980&amp;rft_id=info%3Adoi%2F10.1017%2FS0140525X00005756&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fweb.archive.org%2Fweb%2F20071210043312%2Fhttp%3A%2F%2Fmembers.aol.com%2FNeoNoetics%2FMindsBrainsPrograms.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<dl><dd><i>Page numbers above refer to a standard <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article. See also Searle's <a rel="nofollow" class="external text" href="https://web.archive.org/web/20010221025515/http://www.bbsonline.org/Preprints/OldArchive/bbs.searle2.html">original draft</a>.</i></dd></dl>
<ul><li><cite class="citation">Searle, John (1983), "Can Computers Think?",  in <a href="/wiki/David_Chalmers" title="David Chalmers">Chalmers, David</a> (ed.), <i>Philosophy of Mind: Classical and Contemporary Readings</i>, Oxford: Oxford University Press, pp.&#160;669–675, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-19-514581-6" title="Special:BookSources/978-0-19-514581-6"><bdi>978-0-19-514581-6</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Can+Computers+Think%3F&amp;rft.btitle=Philosophy+of+Mind%3A+Classical+and+Contemporary+Readings&amp;rft.place=Oxford&amp;rft.pages=669-675&amp;rft.pub=Oxford+University+Press&amp;rft.date=1983&amp;rft.isbn=978-0-19-514581-6&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle1984" class="citation">Searle, John (1984), <span class="cs1-lock-registration" title="Free registration required"><a rel="nofollow" class="external text" href="https://archive.org/details/mindsbrainsscien0000sear"><i>Minds, Brains and Science: The 1984 Reith Lectures</i></a></span>, Harvard University Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-674-57631-5" title="Special:BookSources/978-0-674-57631-5"><bdi>978-0-674-57631-5</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Minds%2C+Brains+and+Science%3A+The+1984+Reith+Lectures&amp;rft.pub=Harvard+University+Press&amp;rft.date=1984&amp;rft.isbn=978-0-674-57631-5&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fmindsbrainsscien0000sear&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/> paperback: <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-674-57633-0" title="Special:BookSources/0-674-57633-0">0-674-57633-0</a>.</li>
<li><cite id="CITEREFSearle1990" class="citation">Searle, John (January 1990), "Is the Brain's Mind a Computer Program?", <i>Scientific American</i>, vol.&#160;262 no.&#160;1, pp.&#160;26–31, <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/1990SciAm.262a..26S">1990SciAm.262a..26S</a>, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fscientificamerican0190-26">10.1038/scientificamerican0190-26</a>, <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/2294583">2294583</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Is+the+Brain%27s+Mind+a+Computer+Program%3F&amp;rft.volume=262&amp;rft.issue=1&amp;rft.pages=26-31&amp;rft.date=1990-01&amp;rft_id=info%3Apmid%2F2294583&amp;rft_id=info%3Adoi%2F10.1038%2Fscientificamerican0190-26&amp;rft_id=info%3Abibcode%2F1990SciAm.262a..26S&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle1990" class="citation">Searle, John (1990), <a rel="nofollow" class="external text" href="https://web.archive.org/web/20121114093932/https://mywebspace.wisc.edu/lshapiro/web/Phil554_files/SEARLE-BDC.HTM">"Is the Brain a Digital Computer?"</a>, <i>Proceedings and Addresses of the American Philosophical Association</i>, <b>64</b> (November): 21–37, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F3130074">10.2307/3130074</a>, <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/3130074">3130074</a>, archived from <a rel="nofollow" class="external text" href="https://mywebspace.wisc.edu/lshapiro/web/Phil554_files/SEARLE-BDC.HTM">the original</a> on 2012-11-14</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+and+Addresses+of+the+American+Philosophical+Association&amp;rft.atitle=Is+the+Brain+a+Digital+Computer%3F&amp;rft.volume=64&amp;rft.issue=November&amp;rft.pages=21-37&amp;rft.date=1990&amp;rft_id=info%3Adoi%2F10.2307%2F3130074&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F3130074&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fmywebspace.wisc.edu%2Flshapiro%2Fweb%2FPhil554_files%2FSEARLE-BDC.HTM&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle1992" class="citation">Searle, John (1992), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=eoh8e52wo_oC"><i>The Rediscovery of the Mind</i></a>, Cambridge, Massachusetts: M.I.T. Press, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-262-26113-5" title="Special:BookSources/978-0-262-26113-5"><bdi>978-0-262-26113-5</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Rediscovery+of+the+Mind&amp;rft.place=Cambridge%2C+Massachusetts&amp;rft.pub=M.I.T.+Press&amp;rft.date=1992&amp;rft.isbn=978-0-262-26113-5&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Deoh8e52wo_oC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle1999" class="citation">Searle, John (1999), <a rel="nofollow" class="external text" href="https://archive.org/details/mindlanguagesoci00sear"><i>Mind, language and society</i></a>, New York, NY: Basic Books, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-465-04521-1" title="Special:BookSources/978-0-465-04521-1"><bdi>978-0-465-04521-1</bdi></a>, <a href="/wiki/OCLC" title="OCLC">OCLC</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/oclc/231867665">231867665</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind%2C+language+and+society&amp;rft.place=New+York%2C+NY&amp;rft.pub=Basic+Books&amp;rft.date=1999&amp;rft_id=info%3Aoclcnum%2F231867665&amp;rft.isbn=978-0-465-04521-1&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fmindlanguagesoci00sear&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle2004" class="citation">Searle, John (1 November 2004), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=oSm8JUHJXqcC"><i>Mind: a brief introduction</i></a>, Oxford University Press, Inc., <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-19-515733-8" title="Special:BookSources/978-0-19-515733-8"><bdi>978-0-19-515733-8</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind%3A+a+brief+introduction&amp;rft.pub=Oxford+University+Press%2C+Inc.&amp;rft.date=2004-11-01&amp;rft.isbn=978-0-19-515733-8&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DoSm8JUHJXqcC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle2002" class="citation">Searle, John (2002), <a rel="nofollow" class="external text" href="https://books.google.com/books?id=bvxhV-1Duz8C&amp;pg=PA16"><i>Consciousness and Language</i></a>, Cambridge University Press, p.&#160;16, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0521597449" title="Special:BookSources/978-0521597449"><bdi>978-0521597449</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Consciousness+and+Language&amp;rft.pages=16&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2002&amp;rft.isbn=978-0521597449&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DbvxhV-1Duz8C%26pg%3DPA16&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFSearle2009" class="citation">Searle, John (2009), "Chinese room argument", <i>Scholarpedia</i>, <b>4</b> (8): 3100, <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2009SchpJ...4.3100S">2009SchpJ...4.3100S</a>, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.4249%2Fscholarpedia.3100">10.4249/scholarpedia.3100</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scholarpedia&amp;rft.atitle=Chinese+room+argument&amp;rft.volume=4&amp;rft.issue=8&amp;rft.pages=3100&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.4249%2Fscholarpedia.3100&amp;rft_id=info%3Abibcode%2F2009SchpJ...4.3100S&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite id="CITEREFTuring1950" class="citation"><a href="/wiki/Alan_Turing" title="Alan Turing">Turing, Alan</a> (October 1950), "Computing Machinery and Intelligence", <i><a href="/wiki/Mind_(journal)" title="Mind (journal)">Mind</a></i>, <b>LIX</b> (236): 433–460, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Fmind%2FLIX.236.433">10.1093/mind/LIX.236.433</a>, <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0026-4423">0026-4423</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Mind&amp;rft.atitle=Computing+Machinery+and+Intelligence&amp;rft.volume=LIX&amp;rft.issue=236&amp;rft.pages=433-460&amp;rft.date=1950-10&amp;rft_id=info%3Adoi%2F10.1093%2Fmind%2FLIX.236.433&amp;rft.issn=0026-4423&amp;rft.aulast=Turing&amp;rft.aufirst=Alan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<dl><dd><i>Page numbers above refer to a standard <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article.</i></dd></dl>
<ul><li><cite id="CITEREFYee1993" class="citation">Yee, Richard (1993), <a rel="nofollow" class="external text" href="http://lyceumphilosophy.com/Lyceum-5-1.pdf">"Turing Machines And Semantic Symbol Processing: Why Real Computers Don't Mind Chinese Emperors"</a> <span class="cs1-format">(PDF)</span>, <i>Lyceum</i>, <b>5</b> (1): 37–59</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Lyceum&amp;rft.atitle=Turing+Machines+And+Semantic+Symbol+Processing%3A+Why+Real+Computers+Don%27t+Mind+Chinese+Emperors&amp;rft.volume=5&amp;rft.issue=1&amp;rft.pages=37-59&amp;rft.date=1993&amp;rft.aulast=Yee&amp;rft.aufirst=Richard&amp;rft_id=http%3A%2F%2Flyceumphilosophy.com%2FLyceum-5-1.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<dl><dd><i>Page numbers above and diagram contents refer to the Lyceum <a href="/wiki/Pdf" class="mw-redirect" title="Pdf">pdf</a> print of the article.</i></dd></dl>
</div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Chinese_room&amp;action=edit&amp;section=39" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table role="presentation" class="mbox-small plainlinks sistersitebox" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/40px-Wikibooks-logo-en-noslogan.svg.png" decoding="async" width="40" height="40" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/60px-Wikibooks-logo-en-noslogan.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/80px-Wikibooks-logo-en-noslogan.svg.png 2x" data-file-width="400" data-file-height="400" /></td>
<td class="mbox-text plainlist">Wikibooks has a book on the topic of: <i><b><a href="https://en.wikibooks.org/wiki/Consciousness_Studies" class="extiw" title="wikibooks:Consciousness Studies">Consciousness Studies</a></b></i></td></tr>
</tbody></table>
<ul><li>General presentations of the argument&#160;:
<ul><li><cite class="citation encyclopaedia"><a rel="nofollow" class="external text" href="http://www.iep.utm.edu/chineser">"Chinese Room Argument"</a>. <i><a href="/wiki/Internet_Encyclopedia_of_Philosophy" title="Internet Encyclopedia of Philosophy">Internet Encyclopedia of Philosophy</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chinese+Room+Argument&amp;rft.btitle=Internet+Encyclopedia+of+Philosophy&amp;rft_id=http%3A%2F%2Fwww.iep.utm.edu%2Fchineser&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><a rel="nofollow" class="external text" href="https://plato.stanford.edu/entries/chinese-room/">The Chinese Room Argument</a>. <i><a href="/wiki/Stanford_Encyclopedia_of_Philosophy" title="Stanford Encyclopedia of Philosophy">Stanford Encyclopedia of Philosophy</a></i></li>
<li><a rel="nofollow" class="external text" href="http://www.zompist.com/searle.html">Understanding the Chinese Room</a>, <a href="/wiki/Mark_Rosenfelder" class="mw-redirect" title="Mark Rosenfelder">Mark Rosenfelder</a></li></ul></li></ul>
<ul><li>Sources involving John Searle&#160;:
<ul><li><a rel="nofollow" class="external text" href="http://www.scholarpedia.org/article/Chinese_room_argument">Chinese room argument</a> by John Searle on <a href="/wiki/Scholarpedia" title="Scholarpedia">Scholarpedia</a></li>
<li><a rel="nofollow" class="external text" href="http://globetrotter.berkeley.edu/people/Searle/searle-con4.html">The Chinese Room Argument</a>, part 4 of the September 2, 1999 interview with Searle <a rel="nofollow" class="external text" href="http://globetrotter.berkeley.edu/people/Searle/searle-con0.html">Philosophy and the Habits of Critical Thinking</a> in the <a href="/w/index.php?title=Conversations_With_History&amp;action=edit&amp;redlink=1" class="new" title="Conversations With History (page does not exist)">Conversations With History</a> series</li>
<li><a href="/wiki/John_R._Searle" class="mw-redirect" title="John R. Searle">John R. Searle</a>, “What Your Computer Can’t Know” (review of <a href="/wiki/Luciano_Floridi" title="Luciano Floridi">Luciano Floridi</a>, <i>The Fourth Revolution:  How the Infosphere Is Reshaping Human Reality</i>, Oxford University Press, 2014; and <a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a>, <i>Superintelligence:  Paths, Dangers, Strategies</i>, Oxford University Press, 2014), <i><a href="/wiki/The_New_York_Review_of_Books" title="The New York Review of Books">The New York Review of Books</a></i>, vol. LXI, no. 15 (October 9, 2014), pp.&#160;52–55.</li></ul></li></ul>
<ul><li>Criticism of the argument&#160;:
<ul><li><a rel="nofollow" class="external text" href="http://www.anti-state.com/article.php?article_id=247">A Refutation of John Searle's "Chinese Room Argument"</a>, by <a href="/wiki/Robert_P._Murphy" title="Robert P. Murphy">Bob Murphy</a></li>
<li><cite class="citation journal">Kugel, P. (2004). <a rel="nofollow" class="external text" href="https://semanticscholar.org/paper/7e021606d38860d4c2aeb75fe5cc8b2565870157">"The Chinese room is a trick"</a>. <i>Behavioral and Brain Sciences</i>. <b>27</b>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1017%2FS0140525X04210044">10.1017/S0140525X04210044</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.atitle=The+Chinese+room+is+a+trick&amp;rft.volume=27&amp;rft.date=2004&amp;rft_id=info%3Adoi%2F10.1017%2FS0140525X04210044&amp;rft.aulast=Kugel&amp;rft.aufirst=P.&amp;rft_id=https%3A%2F%2Fsemanticscholar.org%2Fpaper%2F7e021606d38860d4c2aeb75fe5cc8b2565870157&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>, <a rel="nofollow" class="external text" href="http://www.cs.bc.edu/~kugel/Publications/Searle%206.pdf">PDF at author's homepage</a>, critical paper based on the assumption that the CR cannot use its inputs (which are in Chinese) to change its program (which is in English).</li>
<li><cite class="citation arxiv">Wolfram Schmied (2004). "Demolishing Searle's Chinese Room". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/cs.AI/0403009">cs.AI/0403009</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Demolishing+Searle%27s+Chinese+Room&amp;rft.date=2004&amp;rft_id=info%3Aarxiv%2Fcs.AI%2F0403009&amp;rft.au=Wolfram+Schmied&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChinese+room" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li>John Preston and Mark Bishop, "Views into the Chinese Room", Oxford University Press, 2002. Includes chapters by <a href="/wiki/John_Searle" title="John Searle">John Searle</a>, <a href="/wiki/Roger_Penrose" title="Roger Penrose">Roger Penrose</a>, <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a> and <a href="/wiki/Kevin_Warwick" title="Kevin Warwick">Kevin Warwick</a>.</li>
<li><a href="/wiki/Margaret_Boden" title="Margaret Boden">Margaret Boden</a>, "Escaping from the Chinese room", Cognitive Science Research Papers No. CSRP 092, University of Sussex, School of Cognitive Sciences, 1987, <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/OCLC" title="OCLC">OCLC</a>&#160;<a rel="nofollow" class="external text" href="https://www.worldcat.org/oclc/19297071">19297071</a>, <a rel="nofollow" class="external text" href="http://doi.library.cmu.edu/10.1184/OCLC/19297071">online PDF</a>, "an excerpt from a chapter" in the then unpublished "Computer Models of Mind:&#160;: Computational Approaches in Theoretical Psychology", <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-521-24868-X" title="Special:BookSources/0-521-24868-X">0-521-24868-X</a> (1988); reprinted in Boden (ed.) "The Philosophy of Artificial Intelligence" <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-19-824854-7" title="Special:BookSources/0-19-824854-7">0-19-824854-7</a> (1989) and <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-19-824855-5" title="Special:BookSources/0-19-824855-5">0-19-824855-5</a> (1990); Boden "Artificial Intelligence in Psychology: Interdisciplinary Essays" <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-262-02285-0" title="Special:BookSources/0-262-02285-0">0-262-02285-0</a>, MIT Press, 1989, chapter 6; reprinted in Heil, pp.&#160;253–266 (1988) (possibly abridged); J. Heil (ed.) "Philosophy of Mind: A Guide and Anthology", Oxford University Press, 2004, pages 253–266 (same version as in "Artificial Intelligence in Psychology")</li></ul></li></ul>
<div role="navigation" class="navbox" aria-labelledby="Philosophy_of_mind" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Philosophy_of_mind" title="Template:Philosophy of mind"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Philosophy_of_mind" title="Template talk:Philosophy of mind"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Philosophy_of_mind&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Philosophy_of_mind" style="font-size:114%;margin:0 4em"><a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">Philosophy of mind</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%">Theories</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Behaviorism" title="Behaviorism">Behaviorism</a> (<a href="/wiki/Radical_behaviorism" title="Radical behaviorism">Radical</a>)</li>
<li><a href="/wiki/Biological_naturalism" title="Biological naturalism">Biological naturalism</a></li>
<li><a href="/wiki/Cognitive_psychology" title="Cognitive psychology">Cognitive psychology</a></li>
<li><a href="/wiki/Computationalism" class="mw-redirect" title="Computationalism">Computationalism</a></li>
<li><a href="/wiki/Mind%E2%80%93body_dualism" title="Mind–body dualism">Mind–body dualism</a></li>
<li><a href="/wiki/Eliminative_materialism" title="Eliminative materialism">Eliminative materialism</a></li>
<li><a href="/wiki/Emergent_materialism" title="Emergent materialism">Emergent materialism</a></li>
<li><a href="/wiki/Emergentism" title="Emergentism">Emergentism</a></li>
<li><a href="/wiki/Epiphenomenalism" title="Epiphenomenalism">Epiphenomenalism</a></li>
<li><a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">Functionalism</a></li>
<li><a href="/wiki/Idealism" title="Idealism">Idealism</a></li>
<li><a href="/wiki/Interactionism_(philosophy_of_mind)" title="Interactionism (philosophy of mind)">Interactionism</a></li>
<li><a href="/wiki/Materialism" title="Materialism">Materialism</a></li>
<li><a href="/wiki/Monism" title="Monism">Monism</a></li>
<li><a href="/wiki/Na%C3%AFve_realism" title="Naïve realism">Naïve realism</a>
<ul><li><a href="/wiki/Neurophenomenology" title="Neurophenomenology">Neurophenomenology</a></li></ul></li>
<li><a href="/wiki/Neutral_monism" title="Neutral monism">Neutral monism</a></li>
<li><a href="/wiki/Occasionalism" title="Occasionalism">Occasionalism</a></li>
<li><a href="/wiki/Panpsychism" title="Panpsychism">Panpsychism</a></li>
<li><a href="/wiki/Psychoanalysis" title="Psychoanalysis">Psychoanalysis</a></li>
<li><a href="/wiki/Psychophysical_parallelism" title="Psychophysical parallelism">Parallelism</a></li>
<li><a href="/wiki/Phenomenalism" title="Phenomenalism">Phenomenalism</a></li>
<li><a href="/wiki/Phenomenology_(philosophy)" title="Phenomenology (philosophy)">Phenomenology</a></li>
<li><a href="/wiki/Physicalism" title="Physicalism">Physicalism</a>
<ul><li><a href="/wiki/Type_physicalism" title="Type physicalism">identity theory</a></li></ul></li>
<li><a href="/wiki/Property_dualism" title="Property dualism">Property dualism</a></li>
<li><a href="/wiki/Mental_representation" title="Mental representation">Representational</a></li>
<li><a href="/wiki/Solipsism" title="Solipsism">Solipsism</a></li>
<li><a href="/wiki/Substance_dualism" class="mw-redirect" title="Substance dualism">Substance dualism</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Concepts</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Abstract_and_concrete" title="Abstract and concrete">Abstract object</a></li>
<li><a href="/wiki/Artificial_intelligence" title="Artificial intelligence">Artificial intelligence</a></li>
<li><a class="mw-selflink selflink">Chinese room</a></li>
<li><a href="/wiki/Cognition" title="Cognition">Cognition</a></li>
<li><a href="/wiki/Cognitive_closure_(philosophy)" title="Cognitive closure (philosophy)">Cognitive closure</a></li>
<li><a href="/wiki/Concept" title="Concept">Concept</a></li>
<li><a href="/wiki/Concept_and_object" title="Concept and object">Concept and object</a></li>
<li><a href="/wiki/Consciousness" title="Consciousness">Consciousness</a></li>
<li><a href="/wiki/Hard_problem_of_consciousness" title="Hard problem of consciousness">Hard problem of consciousness</a></li>
<li><a href="/wiki/Hypostatic_abstraction" title="Hypostatic abstraction">Hypostatic abstraction</a></li>
<li><a href="/wiki/Idea" title="Idea">Idea</a></li>
<li><a href="/wiki/Identity_(philosophy)" title="Identity (philosophy)">Identity</a></li>
<li><a href="/wiki/Ingenuity" title="Ingenuity">Ingenuity</a></li>
<li><a href="/wiki/Intelligence" title="Intelligence">Intelligence</a></li>
<li><a href="/wiki/Intentionality" title="Intentionality">Intentionality</a></li>
<li><a href="/wiki/Introspection" title="Introspection">Introspection</a></li>
<li><a href="/wiki/Intuition" title="Intuition">Intuition</a></li>
<li><a href="/wiki/Language_of_thought_hypothesis" title="Language of thought hypothesis">Language of thought</a></li>
<li><a href="/wiki/Materialism" title="Materialism">Materialism</a></li>
<li><a href="/wiki/Mental_event" title="Mental event">Mental event</a></li>
<li><a href="/wiki/Mental_image" title="Mental image">Mental image</a></li>
<li><a href="/wiki/Mental_property" title="Mental property">Mental property</a></li>
<li><a href="/wiki/Mental_representation" title="Mental representation">Mental representation</a></li>
<li><a href="/wiki/Mind" title="Mind">Mind</a></li>
<li><a href="/wiki/Mind%E2%80%93body_problem" title="Mind–body problem">Mind–body problem</a>
<ul><li><a href="/wiki/Non-physical_entity" title="Non-physical entity">Non-physical entity</a></li></ul></li>
<li><a href="/wiki/New_mysterianism" title="New mysterianism">New mysterianism</a></li>
<li><a href="/wiki/Pain_(philosophy)" title="Pain (philosophy)">Pain</a></li>
<li><a href="/wiki/Privileged_access" title="Privileged access">Privileged access</a></li>
<li><a href="/wiki/Problem_of_other_minds" title="Problem of other minds">Problem of other minds</a></li>
<li><a href="/wiki/Propositional_attitude" title="Propositional attitude">Propositional attitude</a></li>
<li><a href="/wiki/Qualia" title="Qualia">Qualia</a></li>
<li><a href="/wiki/Tabula_rasa" title="Tabula rasa">Tabula rasa</a></li>
<li><a href="/wiki/Understanding" title="Understanding">Understanding</a></li>
<li><a href="/wiki/Philosophical_zombie" title="Philosophical zombie">Zombie</a></li>
<li><i><a href="/wiki/Index_of_philosophy_of_mind_articles" title="Index of philosophy of mind articles">more...</a></i></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Related topics</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Metaphysics" title="Metaphysics">Metaphysics</a></li>
<li><a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy of artificial intelligence</a>&#160;/&#32;<a href="/wiki/Philosophy_of_information" title="Philosophy of information">information</a>&#160;/&#32;<a href="/wiki/Philosophy_of_perception" title="Philosophy of perception">perception</a>&#160;/&#32;<a href="/wiki/Philosophy_of_self" title="Philosophy of self">self</a></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><a href="/wiki/Category:Philosophy_of_mind" title="Category:Philosophy of mind">Category</a></li>
<li><a href="/wiki/Category:Philosophers_of_mind" title="Category:Philosophers of mind">Philosophers category</a></li>
<li><a href="/wiki/Wikipedia:WikiProject_Philosophy" title="Wikipedia:WikiProject Philosophy">Project</a></li>
<li><a href="/wiki/Wikipedia:WikiProject_Philosophy/Mind" title="Wikipedia:WikiProject Philosophy/Mind">Task Force</a></li>
<li><a href="/wiki/File:Socrates.png" class="image"><img alt="Socrates.png" src="//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/18px-Socrates.png" decoding="async" width="18" height="28" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/27px-Socrates.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/36px-Socrates.png 2x" data-file-width="326" data-file-height="500" /></a> <a href="/wiki/Portal:Philosophy" title="Portal:Philosophy">Philosophy&#32;portal</a></li></ul>
</div></td></tr></tbody></table></div>
<div role="navigation" class="navbox authority-control" aria-labelledby="Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q304726&amp;#124;Edit_this_at_Wikidata" style="padding:3px"><table class="nowraplinks hlist navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th id="Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q304726&amp;#124;Edit_this_at_Wikidata" scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Help:Authority_control" title="Help:Authority control">Authority control</a> <a href="https://www.wikidata.org/wiki/Q304726" title="Edit this at Wikidata"><img alt="Edit this at Wikidata" src="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png" decoding="async" width="10" height="10" style="vertical-align: text-top" srcset="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x" data-file-width="20" data-file-height="20" /></a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><span class="nowrap"><a href="/wiki/Integrated_Authority_File" title="Integrated Authority File">GND</a>: <span class="uid"><a rel="nofollow" class="external text" href="https://d-nb.info/gnd/4730171-5">4730171-5</a></span></span></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1308
Cached time: 20200218233723
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 1.396 seconds
Real time usage: 1.701 seconds
Preprocessor visited node count: 9343/1000000
Post‐expand include size: 160625/2097152 bytes
Template argument size: 21289/2097152 bytes
Highest expansion depth: 18/40
Expensive parser function count: 15/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 200870/5000000 bytes
Number of Wikibase entities loaded: 9/400
Lua time usage: 0.763/10.000 seconds
Lua memory usage: 7.51 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1457.395      1 -total
 26.63%  388.104     41 Template:Citation
 20.78%  302.789      2 Template:Reflist
 20.67%  301.272    126 Template:Sfn
 12.89%  187.794     42 Template:Efn
  8.81%  128.384      4 Template:Cite_journal
  6.43%   93.654      7 Template:Fix
  5.26%   76.656      6 Template:ISBN
  4.98%   72.580      3 Template:Page_needed
  4.81%   70.121      3 Template:Quote
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:6216-0!canonical and timestamp 20200218233723 and revision id 937552112
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Chinese_room&amp;oldid=937552112#Strong_AI">https://en.wikipedia.org/w/index.php?title=Chinese_room&amp;oldid=937552112#Strong_AI</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Philosophy_of_technology" title="Category:Philosophy of technology">Philosophy of technology</a></li><li><a href="/wiki/Category:Philosophy_of_artificial_intelligence" title="Category:Philosophy of artificial intelligence">Philosophy of artificial intelligence</a></li><li><a href="/wiki/Category:Philosophical_arguments" title="Category:Philosophical arguments">Philosophical arguments</a></li><li><a href="/wiki/Category:Thought_experiments_in_philosophy_of_mind" title="Category:Thought experiments in philosophy of mind">Thought experiments in philosophy of mind</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:Wikipedia_articles_needing_page_number_citations_from_February_2012" title="Category:Wikipedia articles needing page number citations from February 2012">Wikipedia articles needing page number citations from February 2012</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_page_number_citations_from_February_2011" title="Category:Wikipedia articles needing page number citations from February 2011">Wikipedia articles needing page number citations from February 2011</a></li><li><a href="/wiki/Category:All_articles_with_specifically_marked_weasel-worded_phrases" title="Category:All articles with specifically marked weasel-worded phrases">All articles with specifically marked weasel-worded phrases</a></li><li><a href="/wiki/Category:Articles_with_specifically_marked_weasel-worded_phrases_from_March_2011" title="Category:Articles with specifically marked weasel-worded phrases from March 2011">Articles with specifically marked weasel-worded phrases from March 2011</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_page_number_citations_from_January_2019" title="Category:Wikipedia articles needing page number citations from January 2019">Wikipedia articles needing page number citations from January 2019</a></li><li><a href="/wiki/Category:Pages_using_quote_template_with_unknown_parameters" title="Category:Pages using quote template with unknown parameters">Pages using quote template with unknown parameters</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_October_2018" title="Category:Articles with unsourced statements from October 2018">Articles with unsourced statements from October 2018</a></li><li><a href="/wiki/Category:Articles_with_Internet_Encyclopedia_of_Philosophy_links" title="Category:Articles with Internet Encyclopedia of Philosophy links">Articles with Internet Encyclopedia of Philosophy links</a></li><li><a href="/wiki/Category:Wikipedia_articles_with_GND_identifiers" title="Category:Wikipedia articles with GND identifiers">Wikipedia articles with GND identifiers</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
    <h2>Navigation menu</h2>
    <div id="mw-head">
        
<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
	<h3 id="p-personal-label">Personal tools</h3>
	<ul >
		
		<li id="pt-anonuserpage">Not logged in</li>
		<li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Chinese+room" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Chinese+room" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>
	</ul>
</div>

        <div id="left-navigation">
            <div id="p-namespaces" role="navigation" class="vectorTabs " aria-labelledby="p-namespaces-label">
	<h3 id="p-namespaces-label">Namespaces</h3>
	<ul >
		<li id="ca-nstab-main" class="selected"><a href="/wiki/Chinese_room" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Chinese_room" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>
	</ul>
</div>
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
	<h3 id="p-variants-label">
		<span>Variants</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>

        </div>
        <div id="right-navigation">
            <div id="p-views" role="navigation" class="vectorTabs " aria-labelledby="p-views-label">
	<h3 id="p-views-label">Views</h3>
	<ul >
		<li id="ca-view" class="collapsible selected"><a href="/wiki/Chinese_room">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Chinese_room&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Chinese_room&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>
	</ul>
</div>
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
	<h3 id="p-cactions-label">
		<span>More</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>
<div id="p-search" role="search">
	<h3 >
		<label for="searchInput">Search</label>
	</h3>
	<form action="/w/index.php" id="searchform">
		<div id="simpleSearch">
			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
			<input type="hidden" value="Special:Search" name="title"/>
			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
		</div>
	</form>
</div>

        </div>
    </div>
    <div id="mw-panel">
        <div id="p-logo" role="banner">
            <a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
        </div>
        
<div class="portal" role="navigation" id="p-navigation"  aria-labelledby="p-navigation-label">
	<h3  id="p-navigation-label">
		Navigation
	</h3>
	<div class="body">
		<ul><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-interaction"  aria-labelledby="p-interaction-label">
	<h3  id="p-interaction-label">
		Interaction
	</h3>
	<div class="body">
		<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-tb"  aria-labelledby="p-tb-label">
	<h3  id="p-tb-label">
		Tools
	</h3>
	<div class="body">
		<ul><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Chinese_room" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Chinese_room" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Chinese_room&amp;oldid=937552112" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Chinese_room&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q304726" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Chinese_room&amp;id=937552112" title="Information on how to cite this page">Cite this page</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-coll-print_export"  aria-labelledby="p-coll-print_export-label">
	<h3  id="p-coll-print_export-label">
		Print/export
	</h3>
	<div class="body">
		<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Chinese+room">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Chinese+room&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Chinese_room&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-lang"  aria-labelledby="p-lang-label">
	<h3  id="p-lang-label">
		Languages
	</h3>
	<div class="body">
		<ul><li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D8%A7%D9%84%D8%BA%D8%B1%D9%81%D8%A9_%D8%A7%D9%84%D8%B5%D9%8A%D9%86%D9%8A%D8%A9" title="الغرفة الصينية – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-be-x-old"><a href="https://be-x-old.wikipedia.org/wiki/%D0%9A%D1%96%D1%82%D0%B0%D0%B9%D1%81%D0%BA%D1%96_%D0%BF%D0%B0%D0%BA%D0%BE%D0%B9" title="Кітайскі пакой – Belarusian (Taraškievica orthography)" lang="be-tarask" hreflang="be-tarask" class="interlanguage-link-target">Беларуская (тарашкевіца)‎</a></li><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Habitaci%C3%B3_xinesa" title="Habitació xinesa – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/Argument_%C4%8D%C3%ADnsk%C3%A9ho_pokoje" title="Argument čínského pokoje – Czech" lang="cs" hreflang="cs" class="interlanguage-link-target">Čeština</a></li><li class="interlanguage-link interwiki-da"><a href="https://da.wikipedia.org/wiki/Det_kinesiske_rum" title="Det kinesiske rum – Danish" lang="da" hreflang="da" class="interlanguage-link-target">Dansk</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Chinesisches_Zimmer" title="Chinesisches Zimmer – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-et"><a href="https://et.wikipedia.org/wiki/Hiina_tuba" title="Hiina tuba – Estonian" lang="et" hreflang="et" class="interlanguage-link-target">Eesti</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Habitaci%C3%B3n_china" title="Habitación china – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%A7%D8%AA%D8%A7%D9%82_%DA%86%DB%8C%D9%86%DB%8C" title="اتاق چینی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Chambre_chinoise" title="Chambre chinoise – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-gl"><a href="https://gl.wikipedia.org/wiki/Sala_chinesa" title="Sala chinesa – Galician" lang="gl" hreflang="gl" class="interlanguage-link-target">Galego</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%A4%91%EA%B5%AD%EC%96%B4_%EB%B0%A9" title="중국어 방 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Ruangan_Tionghoa" title="Ruangan Tionghoa – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-is"><a href="https://is.wikipedia.org/wiki/K%C3%ADnverska_herbergi%C3%B0" title="Kínverska herbergið – Icelandic" lang="is" hreflang="is" class="interlanguage-link-target">Íslenska</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Stanza_cinese" title="Stanza cinese – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%94%D7%97%D7%93%D7%A8_%D7%94%D7%A1%D7%99%D7%A0%D7%99" title="החדר הסיני – Hebrew" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-ka"><a href="https://ka.wikipedia.org/wiki/%E1%83%A9%E1%83%98%E1%83%9C%E1%83%A3%E1%83%A0%E1%83%98_%E1%83%9D%E1%83%97%E1%83%90%E1%83%AE%E1%83%98" title="ჩინური ოთახი – Georgian" lang="ka" hreflang="ka" class="interlanguage-link-target">ქართული</a></li><li class="interlanguage-link interwiki-la"><a href="https://la.wikipedia.org/wiki/Conclave_Sinense" title="Conclave Sinense – Latin" lang="la" hreflang="la" class="interlanguage-link-target">Latina</a></li><li class="interlanguage-link interwiki-lt"><a href="https://lt.wikipedia.org/wiki/Kin%C5%B3_kambarys" title="Kinų kambarys – Lithuanian" lang="lt" hreflang="lt" class="interlanguage-link-target">Lietuvių</a></li><li class="interlanguage-link interwiki-nl"><a href="https://nl.wikipedia.org/wiki/Chinese_kamer" title="Chinese kamer – Dutch" lang="nl" hreflang="nl" class="interlanguage-link-target">Nederlands</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E4%B8%AD%E5%9B%BD%E8%AA%9E%E3%81%AE%E9%83%A8%E5%B1%8B" title="中国語の部屋 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Chi%C5%84ski_pok%C3%B3j" title="Chiński pokój – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-pt"><a href="https://pt.wikipedia.org/wiki/Quarto_chin%C3%AAs" title="Quarto chinês – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ru badge-Q17559452 badge-recommendedarticle" title="recommended article"><a href="https://ru.wikipedia.org/wiki/%D0%9A%D0%B8%D1%82%D0%B0%D0%B9%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BE%D0%BC%D0%BD%D0%B0%D1%82%D0%B0" title="Китайская комната – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-sr"><a href="https://sr.wikipedia.org/wiki/%D0%9A%D0%B8%D0%BD%D0%B5%D1%81%D0%BA%D0%B0_%D1%81%D0%BE%D0%B1%D0%B0" title="Кинеска соба – Serbian" lang="sr" hreflang="sr" class="interlanguage-link-target">Српски / srpski</a></li><li class="interlanguage-link interwiki-fi"><a href="https://fi.wikipedia.org/wiki/Kiinalaisen_huoneen_argumentti" title="Kiinalaisen huoneen argumentti – Finnish" lang="fi" hreflang="fi" class="interlanguage-link-target">Suomi</a></li><li class="interlanguage-link interwiki-sv"><a href="https://sv.wikipedia.org/wiki/Det_kinesiska_rummet" title="Det kinesiska rummet – Swedish" lang="sv" hreflang="sv" class="interlanguage-link-target">Svenska</a></li><li class="interlanguage-link interwiki-th"><a href="https://th.wikipedia.org/wiki/%E0%B8%AB%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%AD%E0%B8%B1%E0%B8%81%E0%B8%A9%E0%B8%A3%E0%B8%88%E0%B8%B5%E0%B8%99" title="ห้องอักษรจีน – Thai" lang="th" hreflang="th" class="interlanguage-link-target">ไทย</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9A%D0%B8%D1%82%D0%B0%D0%B9%D1%81%D1%8C%D0%BA%D0%B0_%D0%BA%D1%96%D0%BC%D0%BD%D0%B0%D1%82%D0%B0" title="Китайська кімната – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-vi"><a href="https://vi.wikipedia.org/wiki/C%C4%83n_ph%C3%B2ng_ti%E1%BA%BFng_Trung_Qu%E1%BB%91c" title="Căn phòng tiếng Trung Quốc – Vietnamese" lang="vi" hreflang="vi" class="interlanguage-link-target">Tiếng Việt</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4" title="中文房间 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>
		<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q304726#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
	</div>
</div>

    </div>
</div>


<div id="footer" role="contentinfo" >
	<ul id="footer-info" class="">
		<li id="footer-info-lastmod"> This page was last edited on 25 January 2020, at 19:18<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" class="">
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/v2/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Chinese_room&amp;mobileaction=toggle_view_mobile#Strong_AI" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</div>


<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"1.396","walltime":"1.701","ppvisitednodes":{"value":9343,"limit":1000000},"postexpandincludesize":{"value":160625,"limit":2097152},"templateargumentsize":{"value":21289,"limit":2097152},"expansiondepth":{"value":18,"limit":40},"expensivefunctioncount":{"value":15,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":200870,"limit":5000000},"entityaccesscount":{"value":9,"limit":400},"timingprofile":["100.00% 1457.395      1 -total"," 26.63%  388.104     41 Template:Citation"," 20.78%  302.789      2 Template:Reflist"," 20.67%  301.272    126 Template:Sfn"," 12.89%  187.794     42 Template:Efn","  8.81%  128.384      4 Template:Cite_journal","  6.43%   93.654      7 Template:Fix","  5.26%   76.656      6 Template:ISBN","  4.98%   72.580      3 Template:Page_needed","  4.81%   70.121      3 Template:Quote"]},"scribunto":{"limitreport-timeusage":{"value":"0.763","limit":"10.000"},"limitreport-memusage":{"value":7877287,"limit":52428800},"limitreport-logs":"table#1 {\n}\n"},"cachereport":{"origin":"mw1308","timestamp":"20200218233723","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Chinese room","url":"https:\/\/en.wikipedia.org\/wiki\/Chinese_room#Strong_AI","sameAs":"http:\/\/www.wikidata.org\/entity\/Q304726","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q304726","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2001-08-28T04:17:13Z","dateModified":"2020-01-25T19:18:58Z","headline":"thought experiment arguing that a computer cannot exhibit \"understanding\""}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":104,"wgHostname":"mw1352"});});</script></body></html>
