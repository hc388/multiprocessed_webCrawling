<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Feedforward neural network - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRequestId":"XkWUGQpAMFkAAHAB0JoAAABX","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Feedforward_neural_network","wgTitle":"Feedforward neural network","wgCurRevisionId":940631411,"wgRevisionId":940631411,"wgArticleId":1706332,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 German-language sources (de)","Articles needing additional references from September 2011","All articles needing additional references","Artificial neural networks"],
"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Feedforward_neural_network","wgRelevantArticleId":1706332,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q5441227","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":
"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface",
"ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.18"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/en/5/54/Feed_forward_neural_net.gif"/>
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Feedforward_neural_network"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Feedforward_neural_network&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Feedforward_neural_network&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Feedforward_neural_network"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Feedforward_neural_network rootpage-Feedforward_neural_network skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Feedforward neural network</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="box-More_citations_needed plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><a href="/wiki/File:Question_book-new.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" decoding="async" width="50" height="39" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x" data-file-width="512" data-file-height="399" /></a></div></td><td class="mbox-text"><div class="mbox-text-span">This article <b>needs additional citations for <a href="/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability">verification</a></b>.<span class="hide-when-compact"> Please help <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Feedforward_neural_network&amp;action=edit">improve this article</a> by <a href="/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1" title="Help:Introduction to referencing with Wiki Markup/1">adding citations to reliable sources</a>. Unsourced material may be challenged and removed.<br /><small><span class="plainlinks"><i>Find sources:</i>&#160;<a rel="nofollow" class="external text" href="//www.google.com/search?as_eq=wikipedia&amp;q=%22Feedforward+neural+network%22">"Feedforward neural network"</a>&#160;–&#160;<a rel="nofollow" class="external text" href="//www.google.com/search?tbm=nws&amp;q=%22Feedforward+neural+network%22+-wikipedia">news</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="//www.google.com/search?&amp;q=%22Feedforward+neural+network%22+site:news.google.com/newspapers&amp;source=newspapers">newspapers</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="//www.google.com/search?tbs=bks:1&amp;q=%22Feedforward+neural+network%22+-wikipedia">books</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="//scholar.google.com/scholar?q=%22Feedforward+neural+network%22">scholar</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="https://www.jstor.org/action/doBasicSearch?Query=%22Feedforward+neural+network%22&amp;acc=on&amp;wc=on">JSTOR</a></span></small></span>  <small class="date-container"><i>(<span class="date">September 2011</span>)</i></small><small class="hide-when-compact"><i> (<a href="/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>
<div class="thumb tright"><div class="thumbinner" style="width:382px;"><a href="/wiki/File:Feed_forward_neural_net.gif" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/en/5/54/Feed_forward_neural_net.gif" decoding="async" width="380" height="440" class="thumbimage" data-file-width="380" data-file-height="440" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Feed_forward_neural_net.gif" class="internal" title="Enlarge"></a></div>In a feed forward network information always moves one direction; it never goes backwards.</div></div></div>
<p>A <b>feedforward neural network</b> is an artificial neural network wherein connections between the nodes do <i>not</i> form a cycle.<sup id="cite_ref-Zell1994p73_1-0" class="reference"><a href="#cite_note-Zell1994p73-1">&#91;1&#93;</a></sup> As such, it is different from its  descendant: <a href="/wiki/Recurrent_neural_networks" class="mw-redirect" title="Recurrent neural networks">recurrent neural networks</a>.
</p><p>The feedforward neural network was the first and simplest type of artificial neural network devised.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup> In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.<sup id="cite_ref-Zell1994p73_1-1" class="reference"><a href="#cite_note-Zell1994p73-1">&#91;1&#93;</a></sup>
</p>
<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Single-layer_perceptron"><span class="tocnumber">1</span> <span class="toctext">Single-layer perceptron</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Multi-layer_perceptron"><span class="tocnumber">2</span> <span class="toctext">Multi-layer perceptron</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Other_feedforward_networks"><span class="tocnumber">3</span> <span class="toctext">Other feedforward networks</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#See_also"><span class="tocnumber">4</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#References"><span class="tocnumber">5</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#External_links"><span class="tocnumber">6</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Single-layer_perceptron">Single-layer perceptron</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit&amp;section=1" title="Edit section: Single-layer perceptron">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></div>
<p>The simplest kind of neural network is a <i>single-layer perceptron</i> network, which consists of a single layer of output nodes; the inputs are fed directly to the outputs via a series of weights. The sum of the products of the weights and the inputs is calculated in each node, and if the value is above some threshold (typically 0) the neuron fires and takes the activated value (typically 1); otherwise it takes the deactivated value (typically -1). Neurons with this kind of <a href="/wiki/Activation_function" title="Activation function">activation function</a> are also called <i><a href="/wiki/Artificial_neurons" class="mw-redirect" title="Artificial neurons">artificial neurons</a></i> or <i>linear threshold units</i>. In the literature the term <i><a href="/wiki/Perceptron" title="Perceptron">perceptron</a></i> often refers to networks consisting of just one of these units. A similar neuron was described by <a href="/wiki/Warren_McCulloch" class="mw-redirect" title="Warren McCulloch">Warren McCulloch</a> and <a href="/wiki/Walter_Pitts" title="Walter Pitts">Walter Pitts</a> in the 1940s.
</p><p>A perceptron can be created using any values for the activated and deactivated states as long as the threshold value lies between the two.
</p><p>Perceptrons can be trained by a simple learning algorithm that is usually called the <i><a href="/wiki/Delta_rule" title="Delta rule">delta rule</a></i>. It calculates the errors between calculated output and sample output data, and uses this to create an adjustment to the weights, thus implementing a form of <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a>.
</p><p>Single-layer perceptrons are only capable of learning <a href="/wiki/Linearly_separable" class="mw-redirect" title="Linearly separable">linearly separable</a> patterns; in 1969 in a famous <a href="/wiki/Monograph" title="Monograph">monograph</a> entitled <i><a href="/wiki/Perceptrons_(book)" title="Perceptrons (book)">Perceptrons</a></i>, <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a> and <a href="/wiki/Seymour_Papert" title="Seymour Papert">Seymour Papert</a> showed that it was impossible for a single-layer perceptron network to learn an <a href="/wiki/Exclusive_or" title="Exclusive or">XOR function</a> (nonetheless, it was known that multi-layer perceptrons are capable of producing any possible boolean function).
</p><p>Although a single threshold unit is quite limited in its computational power, it has been shown that networks of parallel threshold units can <a href="/wiki/Universal_approximation_theorem" title="Universal approximation theorem">approximate any continuous function</a> from a compact interval of the real numbers into the interval [-1,1]. This result can be found in Peter Auer, <a href="/w/index.php?title=Harald_Burgsteiner&amp;action=edit&amp;redlink=1" class="new" title="Harald Burgsteiner (page does not exist)">Harald Burgsteiner</a> and <a href="/w/index.php?title=Wolfgang_Maass&amp;action=edit&amp;redlink=1" class="new" title="Wolfgang Maass (page does not exist)">Wolfgang Maass</a> "A learning rule for very simple universal approximators consisting of a single layer of perceptrons".<sup id="cite_ref-Auer2008_3-0" class="reference"><a href="#cite_note-Auer2008-3">&#91;3&#93;</a></sup>
</p><p>A single-layer neural network can compute a continuous output instead of a <a href="/wiki/Step_function" title="Step function">step function</a>. A common choice is the so-called <a href="/wiki/Logistic_function" title="Logistic function">logistic function</a>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f(x)={\frac {1}{1+e^{-x}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mrow>
              <mn>1</mn>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(x)={\frac {1}{1+e^{-x}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/faaa0c014ae28ac67db5c49b3f3e8b08415a3f2b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:15.89ex; height:5.509ex;" alt="{\displaystyle f(x)={\frac {1}{1+e^{-x}}}}"/></span></dd></dl>
<p>With this choice, the single-layer network is identical to the <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a> model, widely used in <a href="/wiki/Statistical_model" title="Statistical model">statistical modeling</a>. The <a href="/wiki/Logistic_function" title="Logistic function">logistic function</a> is also known as the <a href="/wiki/Sigmoid_function" title="Sigmoid function">sigmoid function</a>. It has a continuous derivative, which allows it to be used in <a href="/wiki/Backpropagation" title="Backpropagation">backpropagation</a>. This function is also preferred because its derivative is easily calculated:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f'(x)=f(x)(1-f(x))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>f</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f'(x)=f(x)(1-f(x))}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/50a861269c68b1f1b973155fa40531d83c54c562" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:22.89ex; height:3.009ex;" alt="{\displaystyle f&#039;(x)=f(x)(1-f(x))}"/></span>.</dd></dl>
<p>(The fact that f satisfies the differential equation above can easily be shown by applying the <a href="/wiki/Chain_Rule" class="mw-redirect" title="Chain Rule">Chain Rule</a>.)
</p><p>If singe-layer neural network activation function is Mod1 then this network can solve XOR problem with exactly ONE neuron.
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f(x)=xmod1;f'(x)=1;}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>x</mi>
        <mi>m</mi>
        <mi>o</mi>
        <mi>d</mi>
        <mn>1</mn>
        <mo>;</mo>
        <msup>
          <mi>f</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mo>;</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(x)=xmod1;f'(x)=1;}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/04bafac5a2815e28f825b9bc379af8011c24b90d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:25.478ex; height:3.009ex;" alt="{\displaystyle f(x)=xmod1;f&#039;(x)=1;}"/></span>.</dd></dl>
<h2><span class="mw-headline" id="Multi-layer_perceptron">Multi-layer perceptron</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit&amp;section=2" title="Edit section: Multi-layer perceptron">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></div>
<div class="thumb tright"><div class="thumbinner" style="width:252px;"><a href="/wiki/File:XOR_perceptron_net.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/7b/XOR_perceptron_net.png/250px-XOR_perceptron_net.png" decoding="async" width="250" height="248" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/7/7b/XOR_perceptron_net.png 1.5x" data-file-width="279" data-file-height="277" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:XOR_perceptron_net.png" class="internal" title="Enlarge"></a></div>A two-layer neural network capable of calculating XOR. The numbers within the neurons represent each neuron's explicit threshold (which can be factored out so that all neurons have the same threshold, usually 1). The numbers that annotate arrows represent the weight of the inputs. This net assumes that if the threshold is not reached, zero (not -1) is output. Note that the bottom layer of inputs is not always considered a real neural network layer</div></div></div>
<p>This class of networks consists of multiple layers of computational units, usually interconnected in a feed-forward way. Each neuron in one layer has directed connections to the neurons of the subsequent layer. In many applications the units of these networks apply a <i><a href="/wiki/Sigmoid_function" title="Sigmoid function">sigmoid function</a></i> as an activation function.
</p><p>The <i><a href="/wiki/Universal_approximation_theorem" title="Universal approximation theorem">universal approximation theorem</a></i> for neural networks states that every continuous function that maps intervals of real numbers to some output interval of real numbers can be approximated arbitrarily closely by a multi-layer perceptron with just one hidden layer. This result holds for a wide range of activation functions, e.g. for the sigmoidal functions.
</p><p>Multi-layer networks use a variety of learning techniques, the most popular being <i><a href="/wiki/Back-propagation" class="mw-redirect" title="Back-propagation">back-propagation</a></i>. Here, the output values are compared with the correct answer to compute the value of some predefined error-function. By various techniques, the error is then fed back through the network. Using this information, the algorithm adjusts the weights of each connection in order to reduce the value of the error function by some small amount. After repeating this process for a sufficiently large number of training cycles, the network will usually converge to some state where the error of the calculations is small. In this case, one would say that the network has <i>learned</i> a certain target function. To adjust weights properly, one applies a general method for non-linear <a href="/wiki/Optimization_(mathematics)" class="mw-redirect" title="Optimization (mathematics)">optimization</a> that is called <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a>. For this, the network calculates the derivative of the error function with respect to the network weights, and changes the weights such that the error decreases (thus going downhill on the surface of the error function). For this reason, back-propagation can only be applied on networks with differentiable activation functions.
</p><p>In general, the problem of teaching a network to perform well, even on samples that were not used as training samples, is a quite subtle issue that requires additional techniques. This is especially important for cases where only very limited numbers of training samples are available.<sup id="cite_ref-Balabin_2007_4-0" class="reference"><a href="#cite_note-Balabin_2007-4">&#91;4&#93;</a></sup> The danger is that the network <a href="/wiki/Overfitting" title="Overfitting">overfits</a> the training data and fails to capture the true statistical process generating the data.  <a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a> is concerned with training classifiers on a limited amount of data.  In the context of neural networks a simple <a href="/wiki/Heuristic" title="Heuristic">heuristic</a>, called <a href="/wiki/Early_stopping" title="Early stopping">early stopping</a>, often ensures that the network will generalize well to examples not in the training set.
</p><p>Other typical problems of the back-propagation algorithm are the speed of convergence and the possibility of ending up in a <a href="/wiki/Local_minimum" class="mw-redirect" title="Local minimum">local minimum</a> of the error function. Today there are practical methods that make back-propagation in multi-layer perceptrons the tool of choice for many <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> tasks.
</p><p>One also can use a series of independent neural networks moderated by some intermediary, a similar behavior that happens in brain. These neurons can perform separably and handle a large task, and the results can be finally combined.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Other_feedforward_networks">Other feedforward networks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit&amp;section=3" title="Edit section: Other feedforward networks">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>More generally, any <a href="/wiki/Directed_acyclic_graph" title="Directed acyclic graph">directed acyclic graph</a> may be used for a feedforward network, with some nodes (with no parents) designated as inputs, and some nodes (with no children) designated as outputs. These can be viewed as multilayer networks where some edges skip layers, either counting layers backwards from the outputs or forwards from the inputs. Various activation functions can be used, and there can be relations between weights, as in <a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">convolutional neural networks</a>.
</p><p>Examples of other feedforward networks include <a href="/wiki/Radial_basis_function_network" title="Radial basis function network">radial basis function networks</a>, which use a different activation function.
</p><p>Sometimes <i>multi-layer perceptron</i> is used loosely to refer to any feedforward neural network, while in other cases it is restricted to specific ones (e.g., with specific activation functions, or with fully connected layers, or trained by the perceptron algorithm).
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit&amp;section=4" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Hopfield_network" title="Hopfield network">Hopfield network</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a></li>
<li><a href="/wiki/Feed_forward_(control)" title="Feed forward (control)">Feed-forward</a></li>
<li><a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a></li>
<li><a href="/wiki/Rprop" title="Rprop">Rprop</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit&amp;section=5" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap"><ol class="references">
<li id="cite_note-Zell1994p73-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-Zell1994p73_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Zell1994p73_1-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Zell, Andreas (1994). <i>Simulation Neuronaler Netze</i> &#91;<i>Simulation of Neural Networks</i>&#93; (in German) (1st ed.). Addison-Wesley. p.&#160;73. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/3-89319-554-8" title="Special:BookSources/3-89319-554-8"><bdi>3-89319-554-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Simulation+Neuronaler+Netze&amp;rft.pages=73&amp;rft.edition=1st&amp;rft.pub=Addison-Wesley&amp;rft.date=1994&amp;rft.isbn=3-89319-554-8&amp;rft.aulast=Zell&amp;rft.aufirst=Andreas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFeedforward+neural+network" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation journal">Schmidhuber, Jürgen (2015-01-01). "Deep learning in neural networks: An overview". <i>Neural Networks</i>. <b>61</b>: 85–117. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1404.7828">1404.7828</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.neunet.2014.09.003">10.1016/j.neunet.2014.09.003</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0893-6080">0893-6080</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/25462637">25462637</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Deep+learning+in+neural+networks%3A+An+overview&amp;rft.volume=61&amp;rft.pages=85-117&amp;rft.date=2015-01-01&amp;rft_id=info%3Aarxiv%2F1404.7828&amp;rft.issn=0893-6080&amp;rft_id=info%3Apmid%2F25462637&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2014.09.003&amp;rft.aulast=Schmidhuber&amp;rft.aufirst=J%C3%BCrgen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFeedforward+neural+network" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Auer2008-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-Auer2008_3-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Auer, Peter; Harald Burgsteiner; Wolfgang Maass (2008). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20110706095227/http://www.igi.tugraz.at/harry/psfiles/biopdelta-07.pdf">"A learning rule for very simple universal approximators consisting of a single layer of perceptrons"</a> <span class="cs1-format">(PDF)</span>. <i>Neural Networks</i>. <b>21</b> (5): 786–795. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.neunet.2007.12.036">10.1016/j.neunet.2007.12.036</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/18249524">18249524</a>. Archived from <a rel="nofollow" class="external text" href="http://www.igi.tugraz.at/harry/psfiles/biopdelta-07.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2011-07-06<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=A+learning+rule+for+very+simple+universal+approximators+consisting+of+a+single+layer+of+perceptrons&amp;rft.volume=21&amp;rft.issue=5&amp;rft.pages=786-795&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2007.12.036&amp;rft_id=info%3Apmid%2F18249524&amp;rft.aulast=Auer&amp;rft.aufirst=Peter&amp;rft.au=Harald+Burgsteiner&amp;rft.au=Wolfgang+Maass&amp;rft_id=http%3A%2F%2Fwww.igi.tugraz.at%2Fharry%2Fpsfiles%2Fbiopdelta-07.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFeedforward+neural+network" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Balabin_2007-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-Balabin_2007_4-0">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a href="/w/index.php?title=Roman_Balabin&amp;action=edit&amp;redlink=1" class="new" title="Roman Balabin (page does not exist)">Roman M. Balabin</a>; Ravilya Z. Safieva; Ekaterina I. Lomakina (2007). "Comparison of linear and nonlinear calibration models based on near infrared (NIR) spectroscopy data for gasoline properties prediction". <i><a href="/wiki/Chemometrics_and_intelligent_laboratory_systems" class="mw-redirect" title="Chemometrics and intelligent laboratory systems">Chemometr Intell Lab</a></i>. <b>88</b> (2): 183–188. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.chemolab.2007.04.006">10.1016/j.chemolab.2007.04.006</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Chemometr+Intell+Lab&amp;rft.atitle=Comparison+of+linear+and+nonlinear+calibration+models+based+on+near+infrared+%28NIR%29+spectroscopy+data+for+gasoline+properties+prediction&amp;rft.volume=88&amp;rft.issue=2&amp;rft.pages=183-188&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1016%2Fj.chemolab.2007.04.006&amp;rft.au=Roman+M.+Balabin&amp;rft.au=Ravilya+Z.+Safieva&amp;rft.au=Ekaterina+I.+Lomakina&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFeedforward+neural+network" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation journal">Tahmasebi, Pejman; Hezarkhani, Ardeshir (21 January 2011). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/225535280">"Application of a Modular Feedforward Neural Network for Grade Estimation"</a>. <i>Natural Resources Research</i>. <b>20</b> (1): 25–32. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs11053-011-9135-3">10.1007/s11053-011-9135-3</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Natural+Resources+Research&amp;rft.atitle=Application+of+a+Modular+Feedforward+Neural+Network+for+Grade+Estimation&amp;rft.volume=20&amp;rft.issue=1&amp;rft.pages=25-32&amp;rft.date=2011-01-21&amp;rft_id=info%3Adoi%2F10.1007%2Fs11053-011-9135-3&amp;rft.aulast=Tahmasebi&amp;rft.aufirst=Pejman&amp;rft.au=Hezarkhani%2C+Ardeshir&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F225535280&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFeedforward+neural+network" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit&amp;section=6" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20090507210502/http://www.emilstefanov.net/Projects/NeuralNetworks.aspx">Feedforward neural networks tutorial</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20090923121811/http://wiki.syncleus.com/index.php/DANN%3ABackprop_Feedforward_Neural_Network">Feedforward Neural Network: Example</a></li>
<li><a rel="nofollow" class="external text" href="http://media.wiley.com/product_data/excerpt/19/04713491/0471349119.pdf">Feedforward Neural Networks: An Introduction</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1290
Cached time: 20200213182249
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.256 seconds
Real time usage: 0.399 seconds
Preprocessor visited node count: 470/1000000
Post‐expand include size: 20010/2097152 bytes
Template argument size: 104/2097152 bytes
Highest expansion depth: 8/40
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 17787/5000000 bytes
Number of Wikibase entities loaded: 3/400
Lua time usage: 0.163/10.000 seconds
Lua memory usage: 4.15 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  344.730      1 -total
 60.97%  210.197      1 Template:Reflist
 33.50%  115.490      1 Template:More_citations_needed
 29.19%  100.629      1 Template:Cite_book
 26.16%   90.184      4 Template:Cite_journal
 23.00%   79.299      1 Template:Ambox
  9.55%   32.933      1 Template:Find_sources_mainspace
  3.53%   12.157      2 Template:Main
  0.92%    3.158      1 Template:Main_other
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1706332-0!canonical!math=5 and timestamp 20200213182249 and revision id 940631411
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Feedforward_neural_network&amp;oldid=940631411">https://en.wikipedia.org/w/index.php?title=Feedforward_neural_network&amp;oldid=940631411</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Artificial_neural_networks" title="Category:Artificial neural networks">Artificial neural networks</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_German-language_sources_(de)" title="Category:CS1 German-language sources (de)">CS1 German-language sources (de)</a></li><li><a href="/wiki/Category:Articles_needing_additional_references_from_September_2011" title="Category:Articles needing additional references from September 2011">Articles needing additional references from September 2011</a></li><li><a href="/wiki/Category:All_articles_needing_additional_references" title="Category:All articles needing additional references">All articles needing additional references</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
    <h2>Navigation menu</h2>
    <div id="mw-head">
        
<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
	<h3 id="p-personal-label">Personal tools</h3>
	<ul >
		
		<li id="pt-anonuserpage">Not logged in</li>
		<li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Feedforward+neural+network" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Feedforward+neural+network" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>
	</ul>
</div>

        <div id="left-navigation">
            <div id="p-namespaces" role="navigation" class="vectorTabs " aria-labelledby="p-namespaces-label">
	<h3 id="p-namespaces-label">Namespaces</h3>
	<ul >
		<li id="ca-nstab-main" class="selected"><a href="/wiki/Feedforward_neural_network" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Feedforward_neural_network" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>
	</ul>
</div>
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
	<h3 id="p-variants-label">
		<span>Variants</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>

        </div>
        <div id="right-navigation">
            <div id="p-views" role="navigation" class="vectorTabs " aria-labelledby="p-views-label">
	<h3 id="p-views-label">Views</h3>
	<ul >
		<li id="ca-view" class="collapsible selected"><a href="/wiki/Feedforward_neural_network">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Feedforward_neural_network&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Feedforward_neural_network&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>
	</ul>
</div>
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
	<h3 id="p-cactions-label">
		<span>More</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>
<div id="p-search" role="search">
	<h3 >
		<label for="searchInput">Search</label>
	</h3>
	<form action="/w/index.php" id="searchform">
		<div id="simpleSearch">
			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
			<input type="hidden" value="Special:Search" name="title"/>
			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
		</div>
	</form>
</div>

        </div>
    </div>
    <div id="mw-panel">
        <div id="p-logo" role="banner">
            <a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
        </div>
        
<div class="portal" role="navigation" id="p-navigation"  aria-labelledby="p-navigation-label">
	<h3  id="p-navigation-label">
		Navigation
	</h3>
	<div class="body">
		<ul><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-interaction"  aria-labelledby="p-interaction-label">
	<h3  id="p-interaction-label">
		Interaction
	</h3>
	<div class="body">
		<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-tb"  aria-labelledby="p-tb-label">
	<h3  id="p-tb-label">
		Tools
	</h3>
	<div class="body">
		<ul><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Feedforward_neural_network" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Feedforward_neural_network" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Feedforward_neural_network&amp;oldid=940631411" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Feedforward_neural_network&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q5441227" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Feedforward_neural_network&amp;id=940631411" title="Information on how to cite this page">Cite this page</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-coll-print_export"  aria-labelledby="p-coll-print_export-label">
	<h3  id="p-coll-print_export-label">
		Print/export
	</h3>
	<div class="body">
		<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Feedforward+neural+network">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Feedforward+neural+network&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Feedforward_neural_network&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
		
	</div>
</div>

<div class="portal" role="navigation" id="p-lang"  aria-labelledby="p-lang-label">
	<h3  id="p-lang-label">
		Languages
	</h3>
	<div class="body">
		<ul><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Xarxa_neuronal_directa" title="Xarxa neuronal directa – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Red_neuronal_prealimentada" title="Red neuronal prealimentada – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%B4%D8%A8%DA%A9%D9%87_%D8%B9%D8%B5%D8%A8%DB%8C_%D9%BE%DB%8C%D8%B4%D8%AE%D9%88%D8%B1" title="شبکه عصبی پیشخور – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_%C3%A0_propagation_avant" title="Réseau de neurones à propagation avant – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%88%9C%EB%B0%A9%ED%96%A5_%EC%8B%A0%EA%B2%BD%EB%A7%9D" title="순방향 신경망 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Rete_neurale_feed-forward" title="Rete neurale feed-forward – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%A8%D7%A9%D7%AA_%D7%96%D7%A8%D7%99%D7%9E%D7%94_%D7%A7%D7%93%D7%99%D7%9E%D7%94" title="רשת זרימה קדימה – Hebrew" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C_%D1%81_%D0%BF%D1%80%D1%8F%D0%BC%D0%BE%D0%B9_%D1%81%D0%B2%D1%8F%D0%B7%D1%8C%D1%8E" title="Нейронная сеть с прямой связью – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0_%D0%BF%D1%80%D1%8F%D0%BC%D0%BE%D0%B3%D0%BE_%D0%BF%D0%BE%D1%88%D0%B8%D1%80%D0%B5%D0%BD%D0%BD%D1%8F" title="Нейронна мережа прямого поширення – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh-yue"><a href="https://zh-yue.wikipedia.org/wiki/%E5%89%8D%E9%A5%8B%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1" title="前饋神經網絡 – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target">粵語</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" title="前馈神经网络 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>
		<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q5441227#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
	</div>
</div>

    </div>
</div>


<div id="footer" role="contentinfo" >
	<ul id="footer-info" class="">
		<li id="footer-info-lastmod"> This page was last edited on 13 February 2020, at 18:22<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" class="">
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/v2/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Feedforward_neural_network&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</div>


<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.256","walltime":"0.399","ppvisitednodes":{"value":470,"limit":1000000},"postexpandincludesize":{"value":20010,"limit":2097152},"templateargumentsize":{"value":104,"limit":2097152},"expansiondepth":{"value":8,"limit":40},"expensivefunctioncount":{"value":4,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":17787,"limit":5000000},"entityaccesscount":{"value":3,"limit":400},"timingprofile":["100.00%  344.730      1 -total"," 60.97%  210.197      1 Template:Reflist"," 33.50%  115.490      1 Template:More_citations_needed"," 29.19%  100.629      1 Template:Cite_book"," 26.16%   90.184      4 Template:Cite_journal"," 23.00%   79.299      1 Template:Ambox","  9.55%   32.933      1 Template:Find_sources_mainspace","  3.53%   12.157      2 Template:Main","  0.92%    3.158      1 Template:Main_other"]},"scribunto":{"limitreport-timeusage":{"value":"0.163","limit":"10.000"},"limitreport-memusage":{"value":4347912,"limit":52428800}},"cachereport":{"origin":"mw1290","timestamp":"20200213182249","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Feedforward neural network","url":"https:\/\/en.wikipedia.org\/wiki\/Feedforward_neural_network","sameAs":"http:\/\/www.wikidata.org\/entity\/Q5441227","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q5441227","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2005-04-07T20:54:03Z","dateModified":"2020-02-13T18:22:45Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/en\/5\/54\/Feed_forward_neural_net.gif","headline":"artificial neural network wherein connections between the nodes do not form a cycle"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":117,"wgHostname":"mw1254"});});</script></body></html>
